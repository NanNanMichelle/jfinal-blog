/*
 Navicat Premium Data Transfer

 Source Server         : 47.104.222.156
 Source Server Type    : MySQL
 Source Server Version : 80029
 Source Host           : 47.104.222.156:3306
 Source Schema         : jfinal_blog

 Target Server Type    : MySQL
 Target Server Version : 80029
 File Encoding         : 65001

 Date: 29/07/2023 13:09:32
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for account
-- ----------------------------
DROP TABLE IF EXISTS `account`;
CREATE TABLE `account`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `nickName` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `userName` varchar(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `password` varchar(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `salt` varchar(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `state` int NOT NULL,
  `avatar` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '' COMMENT '头像',
  `created` datetime NOT NULL COMMENT '创建时间',
  `updated` datetime NOT NULL COMMENT '最后更新时间',
  `del` varchar(1) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '0',
  `display` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `home` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `lable` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 5 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of account
-- ----------------------------
INSERT INTO `account` VALUES (1, '楠楠', 'snn', '4742f1c5617bfeeaa2abab1179bd3d50069c7a9ccf1fc2e6bb5667c7e73622f5', 'Rq7kFiYhvPunaqgeRZw8H7MroNkJ68kP', 1, '/blog/202207/2_20220718121440.png', '2022-07-21 18:34:53', '2023-03-08 11:56:59', '0', '楠', '/blog/84', 'aaa');
INSERT INTO `account` VALUES (2, '亚会', 'yahui', '755bd27e5ad94577f1023a7f0dec939fa7937ba25abf4b89f9ca0e8341bf8be5', 'UZWRJFtIs2y7NE80gtIyl3COJvNE03SB', 1, '/blog/202207/1_20220719050413.png', '2022-07-19 04:53:14', '2022-07-19 04:53:14', '0', '亚会', NULL, NULL);

-- ----------------------------
-- Table structure for blog
-- ----------------------------
DROP TABLE IF EXISTS `blog`;
CREATE TABLE `blog`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `state` int NOT NULL COMMENT '0为草稿，1为发布',
  `status` varchar(2) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '01',
  `accountId` int NOT NULL,
  `title` varchar(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `content` text CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `pic` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '' COMMENT '文章配图',
  `seoKeywords` int NULL DEFAULT NULL,
  `seoDescription` int NULL DEFAULT NULL,
  `viewCount` int NOT NULL DEFAULT 0 COMMENT '浏览量',
  `created` datetime NOT NULL COMMENT '创建时间',
  `updated` datetime NOT NULL COMMENT '最后更新时间',
  `del` int NOT NULL DEFAULT 0,
  `lable` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `pk_state_status_aid`(`state`, `status`, `accountId`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 162 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog
-- ----------------------------
INSERT INTO `blog` VALUES (1, 1, '01', 1, '一、基于SpringCloud Alibaba的微服务电商---环境准备', '<p><strong>使用版本</strong></p>\r\n\r\n<p><strong>框架、组件</strong></p>\r\n\r\n<p style=\"margin-left:40px\">SpringCloud Alibaba：2.2.6.RELEASE<br />\r\nSpringCloud: Hoxton.SR9<br />\r\nSpring Boot:&nbsp;2.3.2.RELEASE<br />\r\nJDK： 1.8<br />\r\nNacos： 1.4.2<br />\r\nSentinel:&nbsp;1.8.1<br />\r\nRocketMQ: 4.4.0<br />\r\nDubbo: 2.7.8<br />\r\nSeata: 1.3.0</p>\r\n\r\n<p style=\"margin-left:40px\"><a href=\"https://github.com/alibaba/spring-cloud-alibaba/wiki\">https://github.com/alibaba/spring-cloud-alibaba/wiki</a></p>\r\n\r\n<p style=\"margin-left:40px\">版本选择与兼容性：<a href=\"https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E\">https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E</a></p>\r\n\r\n<p><strong>Netflix与SpringCloud&nbsp;Alibaba对比</strong></p>\r\n\r\n<pre>\r\n<code>SpringCloud解决方案之Netflix\r\n服务注册与发现:Eureka\r\n熔断限流:hystrix\r\nREST Client: Feign\r\n客户端负载均衡:Ribbon\r\n微服务网关:zuul\r\n\r\nSpringCloud解决方案之Alibaba\r\n服务注册与发现:Nacos\r\n熔断限流:Sentienl\r\n分布式消息中间件:RocketMQ\r\n分布式事务中间件:Seata\r\nRPC服务框架:Dubbo</code></pre>\r\n\r\n<table cellspacing=\"0\" style=\"border-collapse:collapse; width:491px\">\r\n	<tbody>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:1px solid black; height:21px; vertical-align:middle; white-space:nowrap; width:71px\"><span style=\"font-size:8px\"><strong><span style=\"font-family:等线\">Netflix&nbsp;</span></strong></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:1px solid black; vertical-align:middle; white-space:nowrap; width:220px\"><span style=\"font-size:8px\"><strong><span style=\"font-family:等线\">推荐替代品&nbsp;</span></strong></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:1px solid black; vertical-align:middle; white-space:nowrap; width:200px\"><span style=\"font-size:8px\"><strong><span style=\"font-family:等线\">&nbsp;说明</span></strong></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Hystrix</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Sentinel&nbsp;</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">来自SpringCloud Alibaba</span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Eureka</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Nacos&nbsp;</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">来自SpringCloud Alibaba</span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Ribbon</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Spring Cloud Loadbalancer</span></span></td>\r\n			<td rowspan=\"2\" style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; text-align:center; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Spring</span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Zuul</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Spring Cloud Gateway</span></span></td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p>1、Netflix：&nbsp;Eureka、Hystrix、Zuul停更不停用</p>\r\n\r\n<p>2、<span style=\"color:#e74c3c\">SpringCloud Alibaba成为业界主流的微服务解决方案</span></p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-06-07 22:59:33', '2023-02-08 19:58:25', 0, 'SpringCloud');
INSERT INTO `blog` VALUES (6, 1, '01', 1, '二、电商行业模式与技术架构', '<ul>\r\n	<li>电商行业的技术特性</li>\r\n	<li>电商行业的模式介绍</li>\r\n</ul>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/2_20220718170212.png\" style=\"height:358px; width:600px\" /></p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/2_20220718170438.jpeg\" style=\"height:463px; width:771px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-06-09 23:34:52', '2022-06-09 23:34:52', 0, 'SpringCloud');
INSERT INTO `blog` VALUES (7, 0, '01', 1, 'SpringCloud解决方案（一）', '<p>&nbsp;</p>\r\n\r\n<ul>\r\n	<li><strong><a href=\"#one\">SpringCloud介绍，Netflix与Alibaba的对比</a></strong></li>\r\n	<li>基于SpringCloud Alibaba的电商微服务技术架构</li>\r\n	<li>电商业务微服务拆分</li>\r\n	<li>分布式服务注册中心 Nacos整合</li>\r\n</ul>\r\n\r\n<h3><a id=\"one\" name=\"one\">一、SpringCloud介绍，Netflix与Alibaba的对比</a></h3>\r\n\r\n<p>简单来说，SpringCloud提供了一些可以让开发者快速构建微服务应用的工具，比如配置管理、服务发现、熔断、智能路由等，这些服务可以在任何分布式环境下很好的工作。</p>\r\n', '', NULL, NULL, 0, '2022-07-18 13:54:44', '2022-07-18 13:54:44', 1, NULL);
INSERT INTO `blog` VALUES (8, 1, '01', 1, '三、微服务的设计和拆分原则', '<ul>\r\n	<li><span style=\"font-size:16px\"><strong>微服务拆分原则</strong></span></li>\r\n	<li><span style=\"font-size:16px\"><strong>前后端分离原则</strong></span></li>\r\n	<li><span style=\"font-size:16px\"><strong>Restful通信风格</strong></span></li>\r\n</ul>\r\n\r\n<p><span style=\"font-size:16px\"><strong>微服务拆分原则 </strong></span>（AKF扩展拆分要点）：</p>\r\n\r\n<ul>\r\n	<li>低耦合、高内聚：一个服务完成一个独立功能</li>\r\n	<li>按团队结构：小规模团队维护，快速迭代</li>\r\n</ul>\r\n\r\n<p><strong>x轴---水平复制</strong>：绝对平等的复制服务和数据，单体的系统运行多个实例</p>\r\n\r\n<p><strong>y轴---按服务功能拆分：</strong>用户管理服务、商品管理服务、订单管理服务。。。。。。</p>\r\n\r\n<p><strong>z轴---数据分区：</strong>基于用户独特的特性进行划分，例如：将订单管理服务进行划分（秒杀订单、优惠订单等）、将不同地区的用户进行划分（北京、上海、、、、）</p>\r\n\r\n<p><span style=\"font-size:16px\"><strong>前后端分离原则</strong></span></p>\r\n\r\n<p>不分离：后端要疯</p>\r\n\r\n<p>部分分离：重复js，数据加载慢，浪费资源等</p>\r\n\r\n<p>完全分离：各忙各的，各司其职</p>\r\n\r\n<pre>\r\n<code>无服务状态\r\n\r\n状态：如果一个数据需要被多个数据共享才能完成一笔交易，这个数据就是有状态。</code></pre>\r\n\r\n<p><img alt=\"\" src=\"http://47.104.222.156/blog/202207/2_20220718172026.jpeg\" style=\"height:232px; width:710px\" /></p>\r\n\r\n<p><span style=\"font-size:16px\"><strong>Restful通信风格</strong></span></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-06-10 22:15:11', '2022-06-10 22:15:11', 0, 'SpringCloud');
INSERT INTO `blog` VALUES (9, 1, '01', 1, '四、电商微服务划分', '<p><strong>用户进行一次购买流程</strong></p>\r\n\r\n<ul>\r\n	<li>登录</li>\r\n	<li>用户服务</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<ul>\r\n	<li>商品服务</li>\r\n	<li>搜索服务</li>\r\n	<li>购物车服务</li>\r\n	<li><span style=\"color:#e74c3c\">订单服务</span></li>\r\n	<li>秒杀服务（等）</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<ul>\r\n	<li><span style=\"color:#e74c3c\">库存服务</span></li>\r\n	<li><span style=\"color:#e74c3c\">积分服务(等其它会员类服务：京东京豆)</span></li>\r\n</ul>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/2_20220718172956.jpeg\" style=\"height:248px; width:468px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-06-11 21:27:23', '2022-06-11 21:27:23', 0, 'SpringCloud');
INSERT INTO `blog` VALUES (10, 1, '01', 1, '五、Nacos（一）安装部署', '<h1><strong><span style=\"font-size:16px\">概念</span></strong></h1>\r\n\r\n<p>1、Nacos 的缩写 (Dynamic Naming Configueration Service)，Na 为 naming/nameServer 即注册中心，co 为 configuration 即配置中心，service 是指该注册/配置中心都是以服务为核心。<br />\r\n2、Nacos 是什么？【<span style=\"color:#e74c3c\">Nacos = Eureka + Config +Bus</span>】：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。Nacos 就是<span style=\"color:#e74c3c\">注册中心 + 配置中心</span>的组合。<br />\r\n3、Nacos 能干嘛？<br />\r\n（1）替代 Eureka 做服务注册中心。<br />\r\n（2）替代 Config 做服务配置中心。</p>\r\n\r\n<p><span style=\"font-size:16px\"><strong>特性</strong></span></p>\r\n\r\n<ul>\r\n	<li>\r\n	<h4>服务发现：收集所有要管理的服务</h4>\r\n	</li>\r\n	<li>\r\n	<h4>服务健康监测：实时健康检查，能够阻止请求发送到不健康主机或服务实例</h4>\r\n	</li>\r\n	<li>\r\n	<h4>动态配置服务：消除了配置变更时重新部署应用和服务的需要，让配置管理变得更加高效、敏捷；配置中心化管理让实现无状态服务变得更简单，让服务按需弹性扩展变得更容易</h4>\r\n	</li>\r\n	<li>\r\n	<h4>动态 DNS 服务：实现负载均衡、流量控制以及数据中心内网的简单 DNS 解析服务</h4>\r\n	</li>\r\n	<li>\r\n	<h4>服务及其元数据管理</h4>\r\n	</li>\r\n</ul>\r\n\r\n<p><span style=\"font-size:16px\"><strong>部署方式</strong></span></p>\r\n\r\n<ul>\r\n	<li>单机模式 - 用于测试和单机试用。</li>\r\n	<li>集群模式 - 用于生产环境，确保高可用。</li>\r\n	<li>多集群模式 - 用于多数据中心场景。</li>\r\n</ul>\r\n\r\n<h1><span style=\"font-size:16px\"><strong>环境准备</strong></span></h1>\r\n\r\n<ul>\r\n	<li>安装好 JDK，需要 1.8 及其以上版本</li>\r\n	<li>建议: 2核 CPU / 4G 内存 及其以上</li>\r\n	<li>建议: 生产环境 3 个节点 及其以上</li>\r\n</ul>\r\n\r\n<p><span style=\"font-size:16px\"><strong>下载安装</strong></span></p>\r\n\r\n<h3>从 Github 上下载源码方式</h3>\r\n\r\n<pre>\r\n<code>git clone https://github.com/alibaba/nacos.git\r\ncd nacos/\r\nmvn -Prelease-nacos -Dmaven.test.skip=true clean install -U  \r\nls -al distribution/target/\r\n\r\n// change the $version to your actual path\r\ncd distribution/target/nacos-server-$version/nacos/bin\r\n</code></pre>\r\n\r\n<h3>下载编译后压缩包方式</h3>\r\n\r\n<p>从&nbsp;<a href=\"https://github.com/alibaba/nacos/releases\">https://github.com/alibaba/nacos/releases</a> 上下载最新版本</p>\r\n\r\n<pre>\r\n<code>  unzip nacos-server-$version.zip 或者 tar -xvf nacos-server-$version.tar.gz\r\n  cd nacos/bin</code></pre>\r\n\r\n<p><span style=\"font-size:16px\"><strong>启动</strong></span></p>\r\n\r\n<h3>Linux/Unix/Mac</h3>\r\n\r\n<p>启动命令(standalone代表着单机模式运行，非集群模式):</p>\r\n\r\n<pre>\r\n<code>sh startup.sh -m standalone</code></pre>\r\n\r\n<p>如果您使用的是ubuntu系统，或者运行脚本报错提示[[符号找不到，可尝试如下运行：</p>\r\n\r\n<pre>\r\n<code>bash startup.sh -m standalone</code></pre>\r\n\r\n<p><span style=\"font-size:16px\"><strong>关闭</strong></span></p>\r\n\r\n<h3>Linux/Unix/Mac</h3>\r\n\r\n<pre>\r\n<code>sh shutdown.sh</code></pre>\r\n\r\n<p><span style=\"font-size:16px\"><strong>服务注册&amp;发现和配置管理</strong></span></p>\r\n\r\n<h3>服务注册</h3>\r\n\r\n<pre>\r\n<code>curl -X POST \'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&amp;ip=20.18.7.10&amp;port=8080\'</code></pre>\r\n\r\n<h3>服务发现</h3>\r\n\r\n<pre>\r\n<code>curl -X GET \'http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName\'</code></pre>\r\n\r\n<h3>发布配置</h3>\r\n\r\n<pre>\r\n<code>curl -X POST \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=HelloWorld\"</code></pre>\r\n\r\n<h3>获取配置</h3>\r\n\r\n<pre>\r\n<code>curl -X GET \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test\"</code></pre>\r\n\r\n<p>https://nacos.io/zh-cn/docs/what-is-nacos.html</p>\r\n\r\n<p>本地路径：/Users/nn/git/nacos/bin</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h1><span style=\"font-size:9px\">Nacos架构&amp;原理:&nbsp;</span></h1>\r\n', '', NULL, NULL, 0, '2022-06-12 21:42:44', '2022-06-12 21:42:44', 0, 'Nacos');
INSERT INTO `blog` VALUES (11, 1, '01', 1, '六、Nacos（二）电商微服务搭建', '<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p><strong>以往多服务部署</strong></p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/2_20220718180942.jpeg\" style=\"height:254px; width:300px\" /></p>\r\n\r\n<p><strong>Nacos部署</strong></p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/2_20220718180950.jpeg\" style=\"height:226px; width:387px\" /></p>\r\n\r\n<ol>\r\n	<li>添加依赖：</li>\r\n</ol>\r\n\r\n<pre>\r\n<code>&lt;dependency&gt;\r\n    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\r\n    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\r\n    &lt;version&gt;${latest.version}&lt;/version&gt;\r\n&lt;/dependency&gt;</code></pre>\r\n\r\n<p>2. 配置服务提供者</p>\r\n\r\n<p>（1）在&nbsp;<code>application.properties</code>&nbsp;中配置 Nacos server 的地址</p>\r\n\r\n<pre>\r\n<code>server.port=8070 //服务端口\r\nspring.application.name=service-provider //服务名称\r\nspring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 //nacos地址</code></pre>\r\n\r\n<p>（2）通过 Spring Cloud 原生注解&nbsp;<span style=\"color:#e74c3c\"><code>@EnableDiscoveryClient</code></span>&nbsp;开启服务注册发现功能：</p>\r\n\r\n<pre>\r\n<code>@SpringBootApplication\r\n@EnableDiscoveryClient\r\npublic class NacosProviderApplication {\r\n\r\n	public static void main(String[] args) {\r\n		SpringApplication.run(NacosProviderApplication.class, args);\r\n	}\r\n}</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>（3）创建controller</p>\r\n\r\n<pre>\r\n<code>@RestController\r\n	class EchoController {\r\n		@RequestMapping(value = \"/echo/{string}\", method = RequestMethod.GET)\r\n		public String echo(@PathVariable String string) {\r\n			return \"Hello Nacos Discovery \" + string;\r\n		}\r\n	}</code></pre>\r\n\r\n<p>3.配置服务消费者，从而服务消费者可以通过 Nacos 的服务注册发现功能从 Nacos server 上获取到它要调用的服务。</p>\r\n\r\n<p>（1）在&nbsp;<code>application.properties</code>&nbsp;中配置 Nacos server 的地址</p>\r\n\r\n<pre>\r\n<code>server.port=8080\r\nspring.application.name=service-consumer\r\nspring.cloud.nacos.discovery.server-addr=127.0.0.1:8848\r\n#消费者将要去访问的微服务名称（注册成功进nacos的微服务提供者）\r\nserver-url.nacos-user-service= http://service-provider</code></pre>\r\n\r\n<p>（2）通过 Spring Cloud 原生注解&nbsp;<span style=\"color:#e74c3c\"><code>@EnableDiscoveryClient</code></span>&nbsp;开启服务注册发现功能</p>\r\n\r\n<pre>\r\n<code>@SpringBootApplication\r\n@EnableDiscoveryClient\r\npublic class NacosConsumerApplication {\r\n    public static void main(String[] args) {\r\n        SpringApplication.run(NacosConsumerApplication.class, args);\r\n    }\r\n}</code></pre>\r\n\r\n<p>（3）给&nbsp;<a href=\"https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-resttemplate.html\">RestTemplate</a>&nbsp;实例化，开启&nbsp;<code>@LoadBalanced</code>&nbsp;与&nbsp;<a href=\"https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-ribbon.html\">Ribbon</a>&nbsp;的集成</p>\r\n\r\n<pre>\r\n<code>@Configuration\r\npublic class AppliationContextConfig {\r\n	@Bean\r\n	@LoadBalanced // 赋予RestTemplate负载均衡的能力\r\n	public RestTemplate getRestTemplate() {\r\n		return new RestTemplate();\r\n	}\r\n}</code></pre>\r\n\r\n<p>（4）创建controller</p>\r\n\r\n<pre>\r\n<code>@RestController\r\npublic class TestController {\r\n	@Resource\r\n	private RestTemplate restTemplate;\r\n\r\n    /*服务提供者配置文件中的地址*/\r\n	@Value(\"${server-url.nacos-user-service}\")\r\n	private String serverURL;\r\n\r\n	@RequestMapping(value = \"/echo/{str}\", method = RequestMethod.GET)\r\n    public String echo(@PathVariable String str) {\r\n            return restTemplate.getForObject(serverURL+\"/echo/\" + str, String.class);\r\n    }\r\n}\r\n</code></pre>\r\n\r\n<ol start=\"4\">\r\n	<li>启动&nbsp;<code>ProviderApplication</code>&nbsp;和&nbsp;<code>ConsumerApplication</code>&nbsp;，</li>\r\n	<li>调用&nbsp;<code>http://localhost:8080/echo/2018</code>，返回内容为&nbsp;<code>Hello Nacos Discovery 2018</code>。</li>\r\n</ol>\r\n', '', NULL, NULL, 0, '2022-06-14 21:06:37', '2022-06-14 21:06:37', 0, 'Nacos');
INSERT INTO `blog` VALUES (12, 0, '01', 1, '服务响应速度较慢', '<pre>\r\n<code>#将gzip打开\r\n gzip  on;\r\n# 压缩级别 级别越高,压的越小,越浪费CPU计算资源\r\n gzip_comp_level 6;\r\n#对哪些类型的文件用压缩\r\n gzip_types application/json  text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png;\r\n# 开始压缩的最小长度 我这边是1000k 不建议调到很小\r\n gzip_min_length 200;\r\n#缓冲\r\n gzip_buffers 16 64k;\r\n#开始压缩的http协议版本\r\n gzip_http_version 1.1;</code></pre>\r\n\r\n<p>缺点：耗费CPU</p>\r\n', '', NULL, NULL, 0, '2022-07-19 12:50:00', '2022-07-19 12:50:00', 1, NULL);
INSERT INTO `blog` VALUES (13, 1, '02', 1, '基于SpringCloud Alibaba的微服务电商解决方案', '<p><a href=\"http://47.104.222.156:8082/blog/1\">一、环境准备</a></p>\r\n\r\n<p>二、<a href=\"http://47.104.222.156:8082/blog/6\" target=\"_blank\">电商行业模式与技术架构</a></p>\r\n\r\n<p>三、<a href=\"http://47.104.222.156:8082/blog/8\" target=\"_blank\">微服务的设计和拆分原则</a></p>\r\n\r\n<p>四、<a href=\"http://47.104.222.156:8082/blog/9\" target=\"_blank\">电商微服务划分</a></p>\r\n\r\n<p>五、<a href=\"http://47.104.222.156:8082/blog/10\" target=\"_blank\">Nacos（一）安装部署</a></p>\r\n\r\n<p>六、<a href=\"http://47.104.222.156/blog/11\" target=\"_blank\">Nacos（二）电商微服务搭建</a></p>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/33\" target=\"_blank\">七、Nacos Config-实现多环境切换</a></p>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/34\" target=\"_blank\">八、Nacos Config 动态刷新原理</a></p>\r\n', '', NULL, NULL, 0, '2022-06-07 14:35:38', '2023-02-08 19:59:49', 0, 'SpringCloud');
INSERT INTO `blog` VALUES (14, 1, '02', 1, 'Nginx', '<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/15\" target=\"_blank\">Nginx基本配置</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/140\" target=\"_blank\">Nginx-服务响应速度较慢</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/141\" target=\"_blank\">Nginx-本地上传文件正常、服务器上异常413Request Entity Too Large 错误</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/142\" target=\"_blank\">Nginx-访问时如果找不到页面，希望不报404，进行重定向</a></li>\r\n	<li>\r\n	<a href=\"http://sunnannan.com/blog/148\" target=\"_blank\">Nginx-nginx: [error] open() &quot;/run/nginx.pid&quot; failed (2: No such file or directory)</a>\r\n	</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2020-08-19 14:51:14', '2023-02-10 12:37:52', 0, '中间件、Nginx');
INSERT INTO `blog` VALUES (15, 1, '01', 1, 'Nginx基本配置', '<p><strong><span style=\"font-size:16px\">一、root和alias区别</span></strong></p>\r\n\r\n<p style=\"margin-left:40px\"><strong>例如：请求&nbsp;<code>http://xxx/i/top.gif&nbsp;</code></strong></p>\r\n\r\n<pre>\r\n<code>location /i/ {\r\n  root /data/w3;\r\n}\r\n\r\n真正的资源是 /data/w3/i/top.gif文件</code></pre>\r\n\r\n<p style=\"margin-left:40px\">而 alias 正如其名，alias指定的路径是location的别名，不管location的值怎么写，资源的&nbsp;<strong>真实路径都是 alias 指定的路径</strong>&nbsp;</p>\r\n\r\n<pre>\r\n<code>location /i/ {\r\n  alias /data/w3/;\r\n}\r\n\r\n查找的资源路径是： /data/w3/top.gif</code></pre>\r\n\r\n<p style=\"margin-left:40px\"><strong>其他区别：</strong></p>\r\n\r\n<p style=\"margin-left:40px\">&nbsp;&nbsp;&nbsp;&nbsp;1、 alias 只能作用在location中，而root可以存在server、http和location中。</p>\r\n\r\n<p style=\"margin-left:40px\">&nbsp;&nbsp;&nbsp;&nbsp; 2、alias 后面<span style=\"color:#e74c3c\">必须</span>要用 &ldquo;/&rdquo; 结束，否则会找不到文件，而 root 则对 &rdquo;/&rdquo; <span style=\"color:#e74c3c\">可有可无</span>。</p>\r\n\r\n<p><strong><span style=\"font-size:16px\">二、配置静态服务配置</span></strong></p>\r\n\r\n<pre>\r\n<code>location ~* \\.(jpg|jpeg|png|pdf)$ {\r\n    root /data/img;\r\n}</code></pre>\r\n\r\n<p><strong><span style=\"font-size:16px\">三、客户端请求的真实地址</span></strong></p>\r\n\r\n<pre>\r\n<code>location / {\r\n        proxy_pass http://localhost:8082;\r\n        proxy_set_header Host $host:$server_port;\r\n        proxy_set_header   X-Real-IP          $remote_addr;\r\n        proxy_set_header   X-Forwarded-For    $proxy_add_x_forwarded_for;\r\n        proxy_set_header X-Forwarded-Proto   $scheme;\r\n}</code></pre>\r\n\r\n<p><strong><span style=\"font-size:16px\">四、开启SSL</span></strong></p>\r\n\r\n<pre>\r\n<code>ssl on;\r\nssl_certificate      cert/6759483__allmsi.com.pem;\r\nssl_certificate_key  cert/6759483__allmsi.com.key;\r\nssl_session_cache    shared:SSL:1m;\r\nssl_session_timeout  5m;\r\nssl_prefer_server_ciphers  on;\r\nssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;\r\nssl_protocols TLSv1 TLSv1.1 TLSv1.2;</code></pre>\r\n', '', NULL, NULL, 0, '2022-08-19 20:47:10', '2023-02-08 20:13:25', 0, 'Nginx');
INSERT INTO `blog` VALUES (16, 0, '01', 1, 'html 一些样式', '<p>固定导航栏</p>\r\n\r\n<pre>\r\n<code class=\"language-html\">\r\n&lt;div style=\"width: 100%\"&gt;\r\n&lt;ul style=\" position: fixed;width: 50px;\r\n            z-index: 999;\r\n            background-color: white;\r\n            margin-left: -200px;\r\n            font-size: 15px;list-style: upper-roman;\r\n        float:left;background:rgb(39 44 49 / 1%);\"&gt;\r\n    &lt;li&gt;&lt;a href=\"http://47.104.222.156/blog/15\"&gt;基本配置&lt;/a&gt;&lt;/li&gt;\r\n    &lt;li&gt;&lt;a href=\"#one\"&gt;服务响应速度较慢&lt;/a&gt;&lt;/li&gt;\r\n    &lt;li style=\"width:150px\"&gt;&lt;a href=\"#two\"&gt;上传文件 413 错误&lt;/a&gt;&lt;/li&gt;\r\n    &lt;li style=\"width:150px\"&gt;&lt;a href=\"#three\"&gt;访问时找不到页面，希望不报404&lt;/a&gt;&lt;/li&gt;\r\n&lt;/ul&gt;</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-19 19:08:23', '2022-07-19 19:08:23', 1, NULL);
INSERT INTO `blog` VALUES (17, 0, '01', 1, '21212', '<p>&nbsp;</p>\r\n\r\n<div style=\"width:100%\">\r\n<ul style=\"margin-left:-200px\">\r\n	<li><a href=\"http://47.104.222.156/blog/15\">基本配置</a></li>\r\n	<li><a href=\"#one\">服务响应速度较慢</a></li>\r\n	<li><a href=\"#two\">上传文件 413 错误</a></li>\r\n	<li><a href=\"#three\">访问时找不到页面，希望不报404</a></li>\r\n</ul>\r\n</div>\r\n', '', NULL, NULL, 0, '2022-07-20 19:39:04', '2022-07-20 19:39:04', 1, NULL);
INSERT INTO `blog` VALUES (18, 0, '02', 1, '技术管理', '<p>也许是现在，也许是未来，总有那么一天，你会操心自己的职业发展</p>\r\n\r\n<p>工程师发展方向</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-20 20:06:06', '2022-07-20 20:06:06', 1, NULL);
INSERT INTO `blog` VALUES (19, 0, '01', 1, '工程师发展方向', '<p><strong>技术类、管理类、创业类和顾问类</strong></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<table cellspacing=\"0\" style=\"border-collapse:collapse; width:630px\">\r\n	<tbody>\r\n		<tr>\r\n			<td style=\"background-color:#4472c4; border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:1px solid black; height:21px; text-align:center; vertical-align:middle; white-space:nowrap; width:51px\"><span style=\"font-size:13px\"><strong><span style=\"color:black\"><span style=\"font-family:等线\">4大类</span></span></strong></span></td>\r\n			<td style=\"background-color:#4472c4; border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:1px solid black; text-align:center; vertical-align:middle; white-space:nowrap; width:125px\"><span style=\"font-size:13px\"><strong><span style=\"color:black\"><span style=\"font-family:等线\">&nbsp;8大方向</span></span></strong></span></td>\r\n			<td style=\"background-color:#4472c4; border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:1px solid black; text-align:center; vertical-align:middle; white-space:normal; width:410px\"><span style=\"font-size:13px\"><strong><span style=\"color:black\"><span style=\"font-family:等线\">技能清单</span></span></strong></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td rowspan=\"2\" style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:42px; text-align:center; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">技术</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">架构师</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:normal; width:410px\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">技术实操、架构能力、业务理解、培养梯队、沟通</span></span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">技术专家、科学家</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:normal; width:410px\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">技术实操、专业研究、业务理解、培养梯队、沟通</span></span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td rowspan=\"2\" style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:42px; text-align:center; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">管理</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">技术管理者</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:normal; width:410px\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">业务理解、技术判断、目标规划、团队建设、任务执行、沟通</span></span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">职业经理人</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:normal; width:410px\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">行业洞察、商业判断、资本运作、目标规划、公司经营、沟通</span></span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td rowspan=\"2\" style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:42px; text-align:center; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">创业</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">创始人</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:normal; width:410px\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">行业洞察、目标规划、 、商业判断、资本运作、公司经营、沟通</span></span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">技术合伙人</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:normal; width:410px\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">业务理解、技术判断、目标规划、团队建设、任务执行、沟通</span></span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td rowspan=\"2\" style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:42px; text-align:center; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">顾问</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">投资人</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:normal; width:410px\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">行业洞察、商业判断、资本运作、经营管理、沟通</span></span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">管理咨询师、教练</span></span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:normal; width:410px\"><span style=\"font-size:13px\"><span style=\"color:black\"><span style=\"font-family:等线\">管理经验、管理理论、教练咨询、课程研发、沟通</span></span></span></td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h2>一、技术类</h2>\r\n\r\n<p><strong>技术类</strong>主要包含两个大方向。</p>\r\n\r\n<p><strong>一个方向侧重于&ldquo;广&rdquo;</strong>，着眼技术的整体性、架构性和业务解决方案，我们姑且称为&ldquo;<strong>架构师</strong>&rdquo;或&ldquo;首席架构师&rdquo;。 他们往往是一个产品或服务的技术方案的&ldquo;总设计师&rdquo;，他们常见的作品包括社区类服务架构、云服务架构、搜索架构、电商服务架构、O2O 服务架构、数据平台架构等等，每一个产品背后都有一位或几位技术架构师。</p>\r\n\r\n<p><strong>另外一个方向侧重于&ldquo;专&rdquo;</strong>，着眼于某个专项技术的深度、专业度和精细度，我们姑且称为&ldquo;某领域技术专家&rdquo;或&ldquo;<strong>科学家</strong>&rdquo;，比如图像技术、语音技术、机器学习、推荐算法等等。他们往往是一个专业领域里的&ldquo;武林高手&rdquo;，他们的作品被广泛应用在每一个专业领域。</p>\r\n\r\n<h2>二、管理类</h2>\r\n\r\n<p><strong>管理类</strong>也有两个不同的方向，即<strong>技术管理者</strong>和<strong>职业经理人</strong>。你可以认为职业经理人是技术管理者的更成熟阶段，但我更倾向于认为这是两个不同的选择。</p>\r\n\r\n<p><strong>技术管理者</strong>，这个方向很自然，就是从工程师到技术团队的一线经理，再慢慢做到部门经理等二线经理，然后是某个大技术体系或整个技术部的技术副总裁，如果还包括产品、设计等所有&ldquo;产品交付&rdquo;类团队，就成为了一个常规意义上的 CTO，但总体上，都是技术管理者。</p>\r\n\r\n<p>另外一个方向是<strong>职业经理人</strong>。之所以叫职业经理人，是他不限于管理技术类团队，往往负责的是一个完整的业务，很像是这个业务的 CEO，有些公司也会叫 GM（general manager）。这个角色并不限定在具体一个业务，还可以根据公司需要去负责一个新业务，迁移性比较强，比较接近我们常说的&ldquo;职业经理人&rdquo;。这样的管理者会关心一个业务经营的方方面面，但本质还是公司高管，在公司整体框架下工作。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h2>三、创业类</h2>\r\n\r\n<p><strong>创业类</strong>对于技术人来说，也有两个方向。</p>\r\n\r\n<p>一个方向是作为<strong>创始人</strong>牵头创业，做领头羊</p>\r\n\r\n<p>另一个方向是作为<strong>技术合伙人</strong>或<strong>技术高管</strong>全盘负责公司的技术</p>\r\n\r\n<h2>四、顾问类</h2>\r\n\r\n<p><strong>顾问类</strong>的两个方向离得有点远。</p>\r\n\r\n<p>一个方向是投资顾问，也就是做<strong>投资人</strong>，有做投前的，也有做投后的，基于对一个创业团队和项目的完整判断，从外围以资本运作和投后服务来支持创业公司发展。他们在做投资人之前，往往都有着相当丰富的企业经营管理经验、宽广的视野和敏锐的洞察力。比如百度风投的齐玉杰、清流资本的王梦秋和陈韫敏，之前都是百度的高管，都曾经直接或间接管理过百度知道团队，他们也都曾经是百度的工程师，典型的技术人。</p>\r\n\r\n<p>另外一个方向是<strong>管理顾问</strong>，也就是提供培训、咨询服务，偏人力发展和团队建设。这个方向是通过支持管理者和 HR 来支持公司的发展，往往以多年的管理经验、管理理论、教练技术和培训经验为依托。目前，这个方向的人是最少的。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-20 21:08:16', '2022-07-20 21:08:16', 1, NULL);
INSERT INTO `blog` VALUES (20, 0, '01', 1, '外驱让我们可以做好本职工作，而内驱才能让我们成就卓越', '<p>技术人常见的职业发展方向，不难看出，在做了几年技术之后，大部分技术人会把&ldquo;做管理&rdquo;作为一个重要选项来考虑。</p>\r\n\r\n<p>以下四类是最为常见的：</p>\r\n\r\n<p><strong>第一类：不得已的选择</strong>。典型说法有：</p>\r\n\r\n<ul>\r\n	<li>&ldquo;我对技术没有热情，也没有技术特长，所以只能做管理。&rdquo;</li>\r\n	<li>&ldquo;做技术又不能做一辈子，很多前辈都转管理了，我也要转。&rdquo;</li>\r\n	<li>&ldquo;没有办法，公司发展太快了，老板要求我带团队。&rdquo;</li>\r\n</ul>\r\n\r\n<p><strong>第二类：别人眼里的成功</strong>。典型说法有：</p>\r\n\r\n<ul>\r\n	<li>&ldquo;如果能做到公司高管，别人都会认为我是一个优秀和成功的人。&rdquo;</li>\r\n	<li>&ldquo;能够做管理带团队，这样在家人眼中会很风光。&rdquo;</li>\r\n</ul>\r\n\r\n<p><strong>第三类：不辜负组织的期待</strong>。典型说法有：</p>\r\n\r\n<ul>\r\n	<li>&ldquo;上级说我适合做管理，我不能辜负他对我的期望。&rdquo;</li>\r\n	<li>&ldquo;公司需要我带团队，这是公司对我的信任，我一定得做好。&rdquo;</li>\r\n</ul>\r\n\r\n<p><strong>第四类：对做管理的主观遐想</strong>。典型说法有：</p>\r\n\r\n<ul>\r\n	<li>&ldquo;不用凡事亲力亲为，安排下级去做就好了，应该会轻松些。&rdquo;</li>\r\n	<li>&ldquo;做管理越晋升越轻松，你看高管都不坐班。&rdquo;</li>\r\n</ul>\r\n\r\n<p><span style=\"color:#e74c3c\">无论是上述四类中的哪一类，都很难让你在管理之路上走很远。因为上面的四类说法都属于&ldquo;外驱力&rdquo;范畴。如果你因为这样的&ldquo;外驱力&rdquo;而选择了管理，时间一长你就会觉得管理工作越来越烦人，而且并不如自己所期待的那样风光，甚至会怀疑自己当初是否选错了路。其实，你并不见得是选错了路，只不过之前的选择都是基于外部的推力和诱惑所进行的决策，而外力很多时候并不是你能掌控的。</span></p>\r\n\r\n<p>该考虑自己的<strong>内在动力和真正诉求</strong></p>\r\n\r\n<p><strong>你的初衷、你的投入、你的成长</strong>以及<strong>你的回报</strong>之间的逻辑</p>\r\n\r\n<p>下面，我通过以下<strong>三个重要问题</strong>，来帮你做个判断。</p>\r\n\r\n<p><strong>第一个重要问题</strong>是关于&ldquo;管理的价值观&rdquo;的，即<strong>你是否认同管理的价值呢</strong>？你可能会疑惑，这会成为一个问题吗？我很肯定地告诉你，会。很多新经理的上级会跟我诉苦，说他们的新经理不认同管理的价值，常常会跟他们抱怨，主要表现是：</p>\r\n\r\n<ul>\r\n	<li>认为招聘面试、辅导员工、向上汇报、开会沟通、流程梳理、资源协调、进度推动、绩效评估等大部分管理工作，都是琐碎的&ldquo;杂事&rdquo;，很难从这些工作中获得价值感和成就感，甚至还对于这些工作挤占了写代码的时间而不满。</li>\r\n	<li>认为经理是给高工和架构师打下手的，职责就是支持好架构师的工作，所以比较郁闷。</li>\r\n	<li>认为管理的工作不如技术工作有价值，通过技术手段来解决问题才是最酷的事情。</li>\r\n</ul>\r\n\r\n<p>你是否也会这么认为呢？</p>\r\n\r\n<p>即使有很多人都认为你适合做管理，而如果你自己不认为管理是有价值的，你是不会开心地长久做下去的。</p>\r\n\r\n<p><strong>第二个重要的问题</strong>是，<strong>你是否对管理充满热情，并享受这些工作呢</strong>？你可能会问：&ldquo;我还没有做过经理啊，怎么知道有没有热情呢？&rdquo;而事实上，做很多管理工作并不需要经理的头衔，下面的这些问题供你参考：</p>\r\n\r\n<ul>\r\n	<li>你是否主动地向自己的上级了解过团队的工作目标呢？</li>\r\n	<li>你是否主动关心过新同事该怎么培养，以及如何更好地帮助他们成长呢？</li>\r\n	<li>你是否享受去负责一个大项目的协调和推进？它的成功发布是否会给你带来强烈的成就感呢？</li>\r\n	<li>你是否思考过什么样的流程和机制可以应对团队工作中的那些疏漏呢？</li>\r\n</ul>\r\n\r\n<p>如果你的答案都是&ldquo;否&rdquo;，也没有关系，重要的是，你看到这些问题，是饶有兴趣，还是非常抵触呢？如果还是&ldquo;否&rdquo;，那你可能此时还不适合做管理。</p>\r\n\r\n<p><strong>第三个重要问题</strong>是，<strong>你是否看重在管理方面的成长呢</strong>？每位管理者，都是从技术骨干或业务骨干开始起步的，在此之前并没有太多管理方面的学习和积累，这意味着你有很好的管理可塑性，同时也意味着你有太多的东西需要学习和训练。</p>\r\n\r\n<p>做管理要扩充的认知和能力很多，以至于我们整个专栏都会探讨这些问题。这里我先列举几个基本的认知：</p>\r\n\r\n<p><strong>1. 更大的责任</strong>。很多人会把晋升到管理职位，理解成更大的权力和更高的地位，认为经理对于员工是处于掌控和支配地位的。也许过去在某些领域的管理者的确如此，但在互联网公司里的管理者，这样的管理哲学会遇到很多困境。在互联网领域，管理者带一个团队，更多是意味着要承担更大的期待和责任。即便有时看上去有一定权力，但归根结底，还是为了更好地实现团队目标，基本体会不到行使权力的快感。这是不是如你所期待呢？</p>\r\n\r\n<p><strong>2. 更立体的视角</strong>。在做工程师的时候，只要做好上级交代的任务就好了。而一旦做管理，为了带好整个团队，就需要考虑上级、下级、平级的期待和诉求，而且不能只是关心&ldquo;眼前&rdquo;，还得关心&ldquo;从前&rdquo;和&ldquo;以后&rdquo;，提升看待问题的系统性。这是你喜欢的能力吗？</p>\r\n\r\n<p><strong>3. 更灵活的思维方式</strong>。多年的技术工作训练，你一定有很强的确定性的思维方式，讲究界限清晰、对错分明、言出必行、不出差错，往往靠谱就是你的代名词；而很多管理工作却是充满着不确定性的，有些工作的执行边界也是模糊的，甚至是非对错都很难界定清楚。在各种不确定因素中，却要去追求一个明确的目标，这对于很多新的技术管理者来说，思维方式会受到很大冲击。你想扩展你的思维方式吗？</p>\r\n\r\n<p>读到这里，你也许会问：&ldquo;看上去都是挑战和要求，那我能得到什么呢？&rdquo;</p>\r\n\r\n<p>事物都是具有两面性的，上述的挑战和要求也会给你带来成长与收获。接下来，我和你说说能收获什么。</p>\r\n\r\n<p>首先，你到了一个更大的平台上，你的能力和视野将得到大幅度提升。这会给你带来明显的<strong>成长感</strong>。</p>\r\n\r\n<p>其次，你不但能力变强了，你还有团队了，你能搞定更大、更复杂的事情，做出更大的成绩。这会带给你更强的<strong>成就感</strong>。</p>\r\n\r\n<p>再次，你可以带着团队做出越来越多的成就，你的团队也越来越优秀，团队成员都得到了成长，你甚至还会影响到合作团队。你的<strong>影响力</strong>&nbsp;显著提升了。</p>\r\n\r\n<p>最后，你的能力、成绩、影响力全面提升，你得到了更多的精神和物质的回报。你所有的付出、成长和积累，都将或早或晚地换回等值的回馈。你的<strong>获得感</strong>也将得到满足</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-21 19:30:07', '2022-07-21 19:30:07', 1, NULL);
INSERT INTO `blog` VALUES (21, 0, '01', 1, '天时地利人和', '<p><strong>哪些人比较容易走上管理岗位？</strong></p>\r\n\r\n<h2><span style=\"font-size:14px\">一、&ldquo;天时&rdquo;</span></h2>\r\n\r\n<p><strong>做管理的&ldquo;天时&rdquo;，其实就是机会、时机、大环境、时代背景。</strong></p>\r\n\r\n<p>如果你要做管理，最好选择那些发展快的行业和公司，这意味着更多的机会。当然更多的机会也意味着更多的挑战，如果你希望工作得舒服轻松一些，依然可以去稳定的行业和企业工作，但在稳定的行业要走上管理岗位，可能就需要漫长的等待了</p>\r\n\r\n<p>创业公司、小公司机会多，锻炼的能力也更加全面。如果你是因为其他原因去初创公司，我不做评判；但如果你的初衷是想做管理，那我可以明确告诉你，天使轮、A 轮这样的早期公司，大多处于生存期，还没有上规模，而没有规模的公司并不需要你去做管理，所以你很大概率会失望。</p>\r\n\r\n<p>而且，管理是需要长期积累的。百度曾经有个不成文的规定，技术岗位最优秀的员工可以半年晋升，但管理岗必须在当前职位干满一年才能晋升，可见对实战经验的积累是多么重视。对于初创公司来说，能否再活一年都不好说，更别提让你稳定积累了。而你如果频繁更换公司，对管理能力的提升则更为不利</p>\r\n\r\n<p>以自身独特优势为前提的因素，虽然看起来更像是&ldquo;地利&rdquo;，但其实更加受限于时机。所以一个人走上管理岗位有很多&ldquo;机缘&rdquo;，你可以审视一下，你所在的公司和团队可能产生出哪些新的机会</p>\r\n\r\n<h2><span style=\"font-size:14px\">二、&ldquo;地利&rdquo;</span></h2>\r\n\r\n<p><strong><span style=\"font-size:14px\">做管理的&ldquo;地利&rdquo;，就是你的优势、能力，以及你所负责的工作内容。</span></strong></p>\r\n\r\n<p>所谓优势，都是基于特定的工作内容和工作任务而言的，抛开具体工作场景泛泛地谈优势和能力没有意义。那么对于技术人来说，从事什么样的工作内容，以及具有哪些能力和优势对走上管理岗位有帮助呢？</p>\r\n\r\n<p><strong>第一类是负责最全局的模块，核心是&ldquo;广&rdquo;。</strong></p>\r\n\r\n<p>每一个团队的业务，都会分成很多模块，总会有那么几个模块是事关全局的，也是跟大家关联最多的，比如提供所有的服务接口、做所有的数据组装和呈现、产品功能的实现等等。</p>\r\n\r\n<p>这样的工作内容，使得负责的工程师很快锻炼出全局的视野、积极的沟通协调能力，并和很多人建立起合作关系。做得好的话，很快就可以成为一个团队的工作核心。</p>\r\n\r\n<p>因此，很多技术人是这样走上管理岗位的，他们往往管理成熟度也高，成功的概率很大。</p>\r\n\r\n<p><strong>第二类是负责最核心的技术模块，核心是&ldquo;深&rdquo;。</strong></p>\r\n\r\n<p>这个就容易理解了，掌握着团队最核心、最重要、最有技术含量、最能体现团队价值的模块的工程师，是团队里的骨干，不可或缺的技术核心，容易得到上级重视去承担重任。他们往往影响力比较大，所以容易走上管理岗位，不过常常是被动的。</p>\r\n\r\n<p>有一点需要注意的是，这类工程师即便能走上管理岗位，很多管理的意识和能力还是需要修炼的，因为他不像第一类天然就有锻炼全局视野和管理技能的机会。但无论如何，他们也是容易脱颖而出的。</p>\r\n\r\n<p>所以你看，负责的工作内容是否全局和关键，是会影响你能多快地走上管理之路的。</p>\r\n\r\n<h2><span style=\"font-size:14px\">三、&ldquo;人和&rdquo;</span></h2>\r\n\r\n<p><strong><span style=\"font-size:14px\">做管理的&ldquo;人和&rdquo;，就是你能否得到他人的支持。</span></strong></p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/1_20220721174414.jpg\" style=\"height:226px; width:400px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>第一类，为你提供机会、平台和资源的支持。一般是你的上级，他们是否支持你做管理非常重要。</p>\r\n\r\n<p>第二类，为你提供陪伴和共同成长的支持。一般是和你平级的管理者，尤其是那些你愿意与之持续交流、切磋管理问题的伙伴。当然也可以是之前的同学和朋友，还可以是一些管理社群。总之，你可以根据自己的情况和喜好来看看，谁可以做你的管理伙伴。</p>\r\n\r\n<p>第三类，为你提供指导和前进的方向。一般是你的导师、指导人、管理教练或上级。你可以设定你认可的管理榜样，多和他交流，多听听他的看法和意见，这会让你的管理之路顺畅很多。</p>\r\n\r\n<p>第四类，为你提供情感支持，让你勇于面对困难和挫折，在管理之路上走得更远。一般来说，你的家人和朋友，可以担当这样的角色。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/1_20220721174520.jpg\" style=\"height:189px; width:400px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-21 20:45:50', '2022-07-21 20:45:50', 1, NULL);
INSERT INTO `blog` VALUES (22, 0, '01', 1, '对管理的患得和对技术的患失', '<h2><span style=\"font-size:14px\">第一个药方，专门针对&ldquo;患失&rdquo;来开。</span></h2>\r\n\r\n<p><strong>首先，把技术提到更高视角来看待</strong>。做技术的时候，把技术做好就是最大的目标；而做了管理之后，你会把技术作为一个手段来看待，看它究竟能为目标带来什么。但这并不意味着你就不再关心技术，只是关心的层次不同了，你开始需要借助每个人的技术能力去做更大的事情了</p>\r\n\r\n<p><strong>其次，换一种学习方式来掌握技术</strong>。</p>\r\n\r\n<ol>\r\n	<li><strong>建立你的学习机制</strong>。你可以想想在团队内建立什么样的学习机制，可以帮助你借助团队的力量来提升技术判断力，并结合自己的情况来创建。</li>\r\n	<li><strong>请教专家</strong>。在了解某一个领域的情况时，借助你的平台，找你能找到的最厉害的专家高手进行请教，他们之所以成为高手，一般都能给出高屋建瓴、醍醐灌顶的认知。</li>\r\n	<li><strong>共创</strong>。在这个知识型工作者的时代，和自己埋头思考相比，共创成果往往会出乎你想象，特别能增长见识，你可以看看在团队中如何建立共创机制。</li>\r\n</ol>\r\n\r\n<p><strong>关于&ldquo;患失&rdquo;，还有一个视角，如果你是真心热爱技术，擅长用技术的思路和方案解决问题，你可以做技术型管理者</strong></p>\r\n\r\n<h2><span style=\"font-size:14px\">第二个药方，专门针对&ldquo;患得&rdquo;开出。</span></h2>\r\n\r\n<p>这里的&ldquo;患得&rdquo;其实是患&ldquo;不得&rdquo;，那么怎样才能不再担心做不好管理呢？</p>\r\n\r\n<p><strong>首先，做管理对个人成长和个人发展来说，不会失败</strong>。因为管理总体上是一项修炼，只要你持续不断地实践、练习，你的造诣就会越来越高，最后你一定可以胜任某个规模或某个职能的团队。我们通常所谓的&ldquo;不胜任&rdquo;，只是说不匹配，而不是说你就完全做不了管理。而且，管理是很个性化的工作，你完全可以使用自己擅长的方式，去达成管理效果。</p>\r\n\r\n<p><strong>其次，一线技术管理者，即便&ldquo;做不好&rdquo;也并非没有&ldquo;回头路&rdquo;</strong>。刚刚从工程师岗位转到管理者岗位时，离技术很近，如果尝试下来，感觉管理工作确实不是自己想要的，那么，回过头来继续做工程师，几乎是没有门槛的。所以，如果当下不知道自己适不适合做管理，不如全力以赴去尝试一段时间，你其实还有充足的时间来慢慢做这个决定，不需要有后顾之忧。</p>\r\n\r\n<p><strong>最后，做管理所积累的能力，完全可以迁移到做&ldquo;技术带头人&rdquo;或&ldquo;技术 leader&rdquo;这个角色上</strong>。所以，你都不用担心管理的工作会白做，或者本来可以做技术的时间被耽误了。因为，即便你再回头去做工程师，也需要练习去做高级工程师或架构师，需要尝试去负责一个完整的技术方向，此时，你做管理时锻炼的全局视野、规划能力、结果导向意识、项目管理方法、沟通协调能力等等，都会派上用场。</p>\r\n\r\n<p>所以，<strong>第二个药方就是：你一定会有所得，会在做管理过程中有丰富的收获，既然一定能&ldquo;得到&rdquo;，所以不需要去&ldquo;患得&rdquo;。</strong></p>\r\n\r\n<h2><span style=\"font-size:14px\">第三个药方，有点猛，叫做&ldquo;认清现实&rdquo;。</span></h2>\r\n\r\n<p>如果你把&ldquo;编码时间减少&rdquo;叫做放弃技术，那我得告诉你一个残酷的现实，无论你做不做管理，这事都不可避免。现实是，你要么做技术管理，用更高的视角来看待技术；要么你继续做工程师，也要用更高的视角去看待技术。</p>\r\n\r\n<p>俗话说：&ldquo;人穷则反本&rdquo;，当人们遇到困难和挫折的时候，就想回到老路上去，这是人之常情。只是，你不得不面对的一个现实就是，即便回头去继续做技术，也不再是原来那个听指挥听安排就好、做好执行就 OK 的一线工程师，工作&ldquo;升维&rdquo;已不可避免。一方面，每个人的内心都有成长的诉求；另外一方面，公司和团队也需要你承担更复杂、更具挑战性的任务。</p>\r\n\r\n<p>所以，无论是做技术管理，还是做技术架构师，开启一条<strong>技术升维</strong>之路，都在所难免。即便不做技术管理者，要做好一位技术带头人或架构师，工作视角也要做如下的升级</p>\r\n\r\n<ul>\r\n	<li><strong>首先，从目标出发去看待技术</strong>。只有目标明确，才能选择最佳的技术方案，做出最好的技术决策。</li>\r\n	<li><strong>其次，从评估的角度去看待技术</strong>。做工程师的时候，把一个技术方案设计好、实现出来就好了，而做了架构师之后，你需要非常清楚一个技术方案是通过哪些维度来评估其好坏优劣的。并且，当一个技术问题暴露出来之后，得迅速判断会造成什么影响，损失的边界在哪里，有多紧急，以决定要不要放下手头的项目去立一个紧急项目。</li>\r\n	<li><strong>最后，从借助自己的技术到借助大家的技术</strong>。做技术的时候，了解自己能做什么就好了。但是无论是做管理者还是架构师，你都需要带人做事了，这个时候你就需要熟悉团队里每个人的技术情况，知道谁能胜任做什么事情，适合做什么事，然后借助大家的技术去做事。</li>\r\n</ul>\r\n\r\n<p><strong>既然你避无可避，不如奋力向前</strong></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-22 19:55:13', '2022-07-22 19:55:13', 1, NULL);
INSERT INTO `blog` VALUES (23, 0, '01', 1, '技术管理者要保持自己的技术判断力', '<p>技术管理者，和普通管理者最大的区别，就是&ldquo;技术&rdquo;二字，这也是技术管理者最鲜明的标签和最大的竞争力。</p>\r\n\r\n<p>当你还是一位工程师时，你是技术的操作者和实现者，所有的技术服务都从你的手中诞生；而在成为一个越来越成熟的管理者的过程中，你越来越少地直接去实操，慢慢变成了技术的应用者，你需要的是把这些技术服务装配成更大的服务和产品。</p>\r\n\r\n<p>作为一个技术管理者，即技术应用者，要评估的维度主要是以下三个方面：</p>\r\n\r\n<p><strong>第一个维度是结果评估</strong>。即，你要回答&ldquo;要不要做&rdquo;，希望拿到什么结果，你要从哪几个维度去衡量结果，从哪几个技术指标去验收成果。</p>\r\n\r\n<p style=\"margin-left:40px\">比如，你可能因为提升服务稳定性，去完善服务架构；也可能因为要提升数据准确性，去改写数据采集程序；还可能为了提升性能指标，去重构数据读写模块，等等。无论如何，你心里都需要很清楚，用什么技术指标来衡量团队的某项技术工作，而不只是完成一个个项目。</p>\r\n\r\n<p style=\"margin-left:40px\">事关每项工作的效果和业绩，对结果的评估能力最为关键。虽然结果验收都是放在项目完成后，但是在事先就要明确如何验收，这样才能让大家有的放矢，以终为始。</p>\r\n\r\n<p><strong>第二个维度是可行性评估</strong>。可行性有两层含义：一是&ldquo;能不能做&rdquo;，二是&ldquo;值不值得&rdquo;。 能不能和值不值得，是两码事。不懂技术的管理者一般问的都是&ldquo;能不能做&rdquo;，而有经验的技术管理者和资深工程师，考虑的是&ldquo;值不值得&rdquo;。</p>\r\n\r\n<p>所谓&ldquo;值不值得&rdquo;，就是成本收益问题。收益，往往是显而易见的；而成本，就有很多方面需要考虑了，这正是体现技术判断力的地方。</p>\r\n\r\n<p>首先是&ldquo;人财物时&rdquo;等<strong>资源投入成本</strong>，这是几乎每位工程师和管理者都能考虑到的，即需要投入多少人、多少时间，甚至是多少资金和物资在该项目上，这项成本相对容易评估。</p>\r\n\r\n<p>其次是<strong>维护成本</strong>，这是评估技术方案时要重点考虑的。由于我们考虑投入的时候，往往只考虑到项目发布，而发布后的维护成本很容易被忽略。</p>\r\n\r\n<p>常见的技术维护成本有如下四个方面，依次是：</p>\r\n\r\n<ul>\r\n	<li><strong>技术选型成本</strong>。这是指你在做<strong>技术选型</strong>的时候，选择不成熟的技术所带来的成本。越成熟的技术，其技术实现成本和人力成本都是相对要低的，但是并不是说，选择新技术就一定不划算，只要考虑到成本和风险，才能做出合理决策。</li>\r\n	<li><strong>技术升级成本</strong>。这是指在评估<strong>技术方案</strong>的时候，其兼容性和扩展性水平带来的后期升级的难度和成本。</li>\r\n	<li><strong>问题排查成本</strong>。在做<strong>技术实现</strong>的时候，要特别关注后续的问题排查。好的技术实现，分分钟可以排查出问题原因；而不好的技术实现和方案，查一个问题可能需要花上几天时间，成本差异不可同日而语。</li>\r\n	<li><strong>代码维护成本</strong>。在<strong>编写代码</strong>的时候，要记得代码是要有可读性的。这体现在别人升级代码要花多长时间才能看明白，修改起来是否简单、安全。</li>\r\n</ul>\r\n\r\n<p>考虑维护成本是技术管理者和架构师视野宽阔、能力成熟的体现。</p>\r\n\r\n<p>再次是<strong>机会成本</strong>，这是技术管理者做决策时要意识到的。即，当你把人力、时间花在这件事上，同时就等于放弃了另外一件事，而没有做另外这件事将带来什么样的影响呢？就是你要考虑的机会成本，你可能会因为这个思考而调整技术方案的选择。</p>\r\n\r\n<p>最后，希望你还能意识到<strong>协作成本</strong>，即多人协作所增加的时间精力开销。一个方案的协作方越多，需要沟通协调的成本也就越高，可控度越低。如果可能的话，尽量减少不同团队和人员之间的耦合，这样会大大降低协作成本。</p>\r\n\r\n<p><strong>第三个评估维度，即风险评估</strong>。技术风险评估，也叫技术风险判断力。即，有哪些技术风险需要未雨绸缪，考虑该技术方案带来最大损失的可能性和边界，以及在什么情形下会发生。这项评估工作很考验技术管理者的技术经验和风险意识，而且需要借助全团队的技术力量来做出准确判断。</p>\r\n\r\n<p>对于一个技术方案或一项技术决策，如果你能从以上三个维度去评估，就说明你拥有了很好的技术意识和判断力；另外，你还会发现，如果能做好技术评估工作，你的技术能力并不会降低，还会持续提高。</p>\r\n\r\n<p>去拓展技术视野和技术判断力：</p>\r\n\r\n<ol>\r\n	<li><strong>建立技术学习机制</strong>。盘点你负责的业务，需要哪些方面的技术，成立一个或几个核心的技术小组，让团队对各个方向的技术保持敏感，要求小组定期做交流和分享，这样你就可以保持技术的敏感度。</li>\r\n	<li><strong>专项技术调研项目化</strong>。如果某项技术对团队的业务有重要的价值，可以专门立项做技术调研，并要求项目负责人做调研汇报。</li>\r\n	<li><strong>和技术大牛交流</strong>。越是厉害的技术人，越能深入浅出地把技术讲明白，所以针对某项技术找大牛取经，也是学习的好途径。你看，虽然实际操刀的时间少了，但是你和技术大牛的交流机会多了，一方面因为你有更大的影响力了，另一方面，你和大牛有了共同的诉求，就是把技术&ldquo;变现&rdquo;，让技术产生价值。</li>\r\n	<li><strong>听取工作汇报</strong>。因为你带的是技术团队，大部分工作都和技术相关，在读员工的周报、季度汇报时，相互探讨，也是一种切磋和学习。</li>\r\n</ol>\r\n\r\n<p>四类领导力风格，简单概况如下：</p>\r\n\r\n<ol>\r\n	<li><strong>指令式管理：重事不重人</strong>，关注目标和结果，喜欢发号施令但不亲力亲为。</li>\r\n	<li><strong>支持式管理：重人不重事</strong>，希望带头冲锋亲力亲为，特别在意团队成员的感受，并替他们分担工作。</li>\r\n	<li><strong>教练式管理：重人也重事</strong>，关注全局和方向，并在做事上给予教练式辅导和启发。</li>\r\n	<li><strong>授权式管理：不重人也不重事</strong>，关注目标和结果，不关心过程和人员发展</li>\r\n</ol>\r\n\r\n<p>既然叫风格，就是手段层面的东西，<strong>评价手段我们往往是用有效无效来衡量，而不会用好坏来衡量，所以，这四类风格无所谓谁好谁坏</strong>。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>第一，你可以通过梳理自己可迁移的能力，提升能力自信；</p>\r\n\r\n<p>第二，你可以通过把自己从团队成员的对立面抽离，提升角色自信；</p>\r\n\r\n<p>第三，你可以通过收集外部积极正向的反馈，提升自我认同。</p>\r\n', '', NULL, NULL, 0, '2022-07-22 20:03:08', '2022-07-22 20:03:08', 1, NULL);
INSERT INTO `blog` VALUES (24, 0, '01', 1, '角色变化', '<p>一个人的行为、能力、价值观，都源于一个最根本的认知，就是自我角色的设定。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/1_20220721180557.jpg\" style=\"height:238px; width:400px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p><strong>第一个角度</strong>，从<strong>工作职责</strong></p>\r\n\r\n<p><strong>第二个角度</strong>，从<strong>负责对象</strong></p>\r\n\r\n<p><strong>第三个角度</strong>，从<strong>关注焦点</strong></p>\r\n\r\n<p><strong>第四个角度</strong>，从<strong>工作内容和能力要求</strong></p>\r\n\r\n<p><strong>第五个角度</strong>，从<strong>任务来源</strong></p>\r\n\r\n<p><strong>第六个角度</strong>，从<strong>实施手段</strong></p>\r\n\r\n<p><strong>第七个角度</strong>，从<strong>合作维度</strong></p>\r\n\r\n<p><strong>第八个角度</strong>，从和团队成员的<strong>合作关系</strong></p>\r\n\r\n<p><strong>第九个角度</strong>，从<strong>思维方式</strong></p>\r\n\r\n<p><strong>第十个角度</strong>，从<strong>技术视角</strong></p>\r\n\r\n<p>忌：</p>\r\n\r\n<p>1、<strong>过程导向、被动执行</strong></p>\r\n\r\n<p>至少会带来如下三个后果：</p>\r\n\r\n<ol>\r\n	<li><strong>团队方向感缺失</strong>。大家都只是着眼于手头工作，团队得不到愿景的凝聚和激励。</li>\r\n	<li><strong>团队做不出有效的业绩</strong>。因为团队没有方向感，所以结果就很难有效。</li>\r\n	<li><strong>无法带领一个团队</strong>。由于视角局限，所以还不具备带领团队的能力。</li>\r\n</ol>\r\n\r\n<p>2、<strong>大包大揽、唯我最强</strong></p>\r\n\r\n<ol>\r\n	<li><strong>梯队问题</strong>：大树底下寸草不生，梯队迟迟培养不起来。因为梯队的培养需要授权，需要让高潜人才有发挥空间并承担相应的责任。</li>\r\n	<li><strong>激励问题</strong>：由于管理者冲得太靠前，团队成员积极性受挫，遇事往后缩。</li>\r\n	<li><strong>个人发展问题</strong>：由于得不到团队成员的有效支持，自己又忙又累，做不了更大的业务。</li>\r\n</ol>\r\n\r\n<p>3、<strong>带头大哥、当家保姆</strong></p>\r\n\r\n<ol>\r\n	<li><strong>不职业的管理风格和文化</strong>，这会给公司带来很大的潜在风险。</li>\r\n	<li><strong>团队没有方向</strong>，所以很难有正确的判断和决策。</li>\r\n</ol>\r\n\r\n<p>4、<strong>单一视角、固化思维</strong></p>\r\n\r\n<ol>\r\n	<li><strong>习惯性卡住</strong>。遇到问题和困难，很容易被卡住，到处都是绕不过去的鸿沟。</li>\r\n	<li><strong>认知层次低</strong>。由于被单一惯性思维所支配，认知层次和考虑问题的维度无法提升。</li>\r\n	<li><strong>难堪重任</strong>。由于创造性地解决问题的能力不足，难以承担具有挑战性的工作。</li>\r\n</ol>\r\n\r\n<p>5、<strong>自扫门前雪、固守边界</strong></p>\r\n\r\n<ol>\r\n	<li><strong>项目推进不畅，从而影响全局的结果</strong>。</li>\r\n	<li><strong>自我设限，因此个人成长受限</strong>。</li>\r\n	<li><strong>个人影响力无法扩展</strong>。因为目光和手脚都局限在团队内，所以无法在更大的范围产生影响力，也就无法成为更高级的管理者。</li>\r\n</ol>\r\n\r\n<p>6、<strong>患得患失</strong></p>\r\n\r\n<ol>\r\n	<li>犹豫反复，无法全力以赴去做好管理，<strong>成长缓慢</strong>。</li>\r\n	<li><strong>对技术的看法太狭隘，从而影响技术判断力的提升</strong>。</li>\r\n	<li>由于<strong>误判</strong>，可能会错失一个好的发展平台。</li>\r\n</ol>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h1><span style=\"font-size:16px\">从哪里着手呢？</span></h1>\r\n\r\n<h2><span style=\"font-size:14px\">1、团队是干什么：你需要先看一下，这是辆什么车。</span></h2>\r\n\r\n<p><span style=\"font-size:14px\">2、团队想做出什么成果：你得看看，你要把这辆车拉到哪里去</span></p>\r\n\r\n<p style=\"margin-left:40px\"><span style=\"font-size:14px\"><strong>着眼自己想要的结果，去实现资源的有效配置</strong></span></p>\r\n\r\n<p><span style=\"font-size:14px\">3、依靠什么样的团队：你得盘点一下你有哪些马，它们情况如何。</span></p>\r\n\r\n<p><span style=\"font-size:14px\">4、需要投入哪些资源：你选择走哪条路。</span></p>\r\n\r\n<p>所谓的管理规划，其实就是要管理者说明白一个问题，即，你想要什么目标，以及你需要投入什么资源。由于目标取决于团队的职能，而团队又是管理者的核心资源。所以，一份合格的规划报告，至少需要体现<strong>职能、目标、团队、路径</strong>这四个要素</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-23 18:14:25', '2022-07-23 18:14:25', 1, NULL);
INSERT INTO `blog` VALUES (25, 0, '01', 1, '设定团队职责和使命的方法和步骤', '<p><strong>第一步，收集信息</strong>。可从以下四个角度来梳理职能信息：</p>\r\n\r\n<ol>\r\n	<li><strong>向上沟通</strong>。听听上级对你团队的期待和要求，以及希望用什么维度来衡量你做得好还是不好。这个信息非常重要，团队的初始定位和基本职责，一般都是上级直接给定的。</li>\r\n	<li><strong>向下沟通</strong>。主要是和大家探讨对团队业务的看法和理解，以及对未来发展的期待，为以后的沟通做好铺垫。</li>\r\n	<li><strong>左看右看</strong>。主要是看职能定位的边界在哪里，最好和兄弟团队的职能是无缝对接的。但不要覆盖兄弟团队的职责，否则会带来各种合作上的冲突。其实，快速发展的公司，要做的事情非常多，海阔天空，即便是广度不够，深度也还有作为空间，真没必要和兄弟团队争抢地盘。</li>\r\n	<li><strong>你的理解</strong>。即，你对业务的理解，你对领域的理解，你对团队的期待，以及你对自己的期待。团队的更高职责，即，团队使命和愿景，往往来自于你的设想。</li>\r\n</ol>\r\n\r\n<p><strong>第二步，提炼和升华</strong>。</p>\r\n\r\n<p>团队的职责和使命，不能只停留在 leader 的脑海中，为了方便记忆和传播，则必须从上述信息中进行提炼和升华。提炼和升华有三个要点：</p>\r\n\r\n<ol>\r\n	<li><strong>职责的提炼</strong>。基于上级的期待和要求，以及你对业务核心价值的理解，最好用上级和团队成员、兄弟部门都易于理解的语言，对职责进行简短化提炼，并尽可能长时间稳定下来。</li>\r\n	<li><strong>使命的升华</strong>。基于基本职责，寻找团队对于部门和公司的独特价值，并和行业发展趋势结合，设定自己的期待。要注意使用基于&ldquo;结果&rdquo;的描述，而非基于&ldquo;过程&rdquo;的描述。比如保证项目交付质量，是对结果的描述；而负责项目测试，则是对过程的描述。相比之下，基于结果的描述会更有使命感。</li>\r\n	<li><strong>确定衡量维度</strong>。一般来说，团队的职责和使命决定了衡量的维度，但是如果有明确的关于衡量维度的说法，会让员工对职责和使命有更深刻的理解。常见的案例有：服务端团队，会特别重视性能、稳定性、扩展性等维度；而前端团队，往往重视开发效率、兼容性、安全性等维度；数据团队关注数据准确性、完整性、及时性、安全性等维度。你也需要根据自己团队的职能，向员工明确传递，什么指标维度对团队是最重要的。</li>\r\n</ol>\r\n\r\n<p><strong>第三步，确认和主张</strong>。</p>\r\n\r\n<p>提炼完成之后，接下来就是确认和主张。确认主要是和自己的上级确认，得到上级的认同和支持后，就可以向团队内外进行主张了。当然，最好是在合适的场合，比如季度会、合作沟通会等，有计划、有步骤地把团队的职责和使命宣贯给大家。团队职能的设定和宣贯是一个长期工程，不要期待一蹴而就。当然，如果做得好的话，效果也很快就能显现出来。</p>\r\n\r\n<p>当你要评判一个目标是否合理时，需要从 SMART 这五个原则去逐个审视:</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/1_20220721181551.jpg\" style=\"height:131px; width:400px\" /></p>\r\n\r\n<p>目标的描述形式，大体分为两类：一类是可以量化的指标；另外一类是不可量化的目标</p>\r\n\r\n<h1><span style=\"font-size:16px\">如何来规划团队的组织结构呢？</span></h1>\r\n\r\n<p>探讨团队规划，主要从如下三个视角：</p>\r\n\r\n<ul>\r\n	<li><strong>第一个视角是看团队目标；---&nbsp;你希望在某个时间节点到来的时候，把团队发展成什么状态</strong></li>\r\n	<li><strong>第二个视角是看资源；--</strong>需要有<strong>成本意识。</strong>从资源视角来看待团队，是一个成熟管理者的标志之一。因为站在公司角度来看，每个团队都是一批人力资源，所以有个专门的职能角色叫 HR（人力资源）</li>\r\n	<li><strong>第三个视角是看人才培养。</strong></li>\r\n</ul>\r\n\r\n<p>组织架构图示例:</p>\r\n\r\n<p><strong><img alt=\"\" src=\"/blog/202207/1_20220721182016.jpg\" style=\"height:160px; width:400px\" /></strong></p>\r\n\r\n<h1><span style=\"font-size:16px\">都要申请哪些资源呢？</span></h1>\r\n\r\n<p>1、你是否了解资源的丰富性呢？</p>\r\n\r\n<p>2、你是否意识到手段的多样性呢？</p>\r\n\r\n<p>3、人力资源的持续性。通俗说就是，不是所有的人力短缺，都要通过招聘来解决。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-23 18:34:41', '2022-07-23 18:34:41', 1, NULL);
INSERT INTO `blog` VALUES (26, 1, '01', 4, 'redis-数据结构-hash', '<h1>哈希</h1>\r\n\r\n<p>哈希是键值对的集合。在 Redis 中，哈希是字符串字段和字符串值之间的映射。因此，它们适合表示对象。每个哈希可以存储多达 232&ndash; 1 个字段-值对。</p>\r\n\r\n<h4>hkeys、hvals</h4>\r\n\r\n<pre>\r\n#hkeys key :返回key这种哈希表所有域。key不存在返回空表\r\nredis&gt; HSET myhash field1 &quot;Hello&quot;\r\n(integer) 1\r\nredis&gt; HSET myhash field2 &quot;World&quot;\r\n(integer) 1\r\nredis&gt; HKEYS myhash\r\n1) &quot;field1&quot;\r\n2) &quot;field2&quot;\r\n​\r\n#hvals key :返回哈希表所有域的值。key不存在时返回空表\r\nredis&gt; HSET myhash field1 &quot;Hello&quot;\r\n(integer) 1\r\nredis&gt; HSET myhash field2 &quot;World&quot;\r\n(integer) 1\r\nredis&gt; HVALS myhash\r\n1) &quot;Hello&quot;\r\n2) &quot;World&quot;\r\n​\r\n​</pre>\r\n\r\n<h4>hset、hmset、hsetnx</h4>\r\n\r\n<pre>\r\n#hset key field value[field value ...] 给哈希表中的field字段赋值，哈希表不存在，创建并操作，field可以被覆盖。redis4.0之后可以一次设置多对\r\nredis&gt; HSET myhash field1 &quot;Hello&quot;\r\n(integer) 1\r\n​\r\n#hmset ；同时将多个field-value设置到哈希表中。4.0后hset代替\r\n​\r\n#hsetnx key field value :用于为哈希表中不存在的字段赋值，若field存在，则操作无效。\r\nredis&gt; HSETNX myhash field &quot;Hello&quot;\r\n(integer) 1 &nbsp;  成功状态码\r\nredis&gt; HSETNX myhash field &quot;World&quot;\r\n(integer) 0 &nbsp;  失败状态码\r\nredis&gt; HGET myhash field\r\n&quot;Hello&quot;\r\n​</pre>\r\n\r\n<h4>hget、hmget、hgetall</h4>\r\n\r\n<pre>\r\n#hget key field :返回哈希表中的field值\r\nredis&gt; HSET myhash field1 &quot;foo&quot;\r\n(integer) 1\r\n# 字段存在\r\nredis&gt; HGET myhash field1\r\n&quot;foo&quot;\r\n# 字段不存在\r\nredis&gt; HGET myhash field2\r\n(nil)\r\n​\r\n#hmget key :返回哈希表中，一个或多个给定字段（field）的值\r\nredis&gt; HSET myhash field1 &quot;Hello&quot;\r\n(integer) 1\r\nredis&gt; HSET myhash field2 &quot;World&quot;\r\n(integer) 1\r\nredis&gt; HMGET myhash field1 field2 nofield\r\n1) &quot;Hello&quot;\r\n2) &quot;World&quot;\r\n3) (nil)\r\n​\r\n#hgetall key :返回存储在 key 中的哈希表中所有的域和值,在返回值里，紧跟每个域(field name)之后是域的值(value)，所以返回值的长度是哈希表大小的两倍。\r\nredis&gt; HSET myhash field1 &quot;Hello&quot;\r\n(integer) 1\r\nredis&gt; HSET myhash field2 &quot;World&quot;\r\n(integer) 1\r\nredis&gt; HGETALL myhash\r\n1) &quot;field1&quot;\r\n2) &quot;Hello&quot;\r\n3) &quot;field2&quot;\r\n4) &quot;World&quot;\r\n​</pre>\r\n\r\n<h4>hincrby、hincrbyfloat</h4>\r\n\r\n<pre>\r\n#hincrby key field increment :给key中的域field的值加上增量increment。域的值是字符串类型时，返回错误\r\nredis&gt; HSET myhash field 5\r\n(integer) 1\r\nredis&gt; HINCRBY myhash field 1\r\n(integer) 6\r\nredis&gt; HINCRBY myhash field -1\r\n(integer) 5\r\nredis&gt; HSET myhash field aa\r\n(integer) 0\r\nredis&gt; HINCRBY myhash field 1\r\nERR ERR hash value is not an integer\r\nredis&gt; hget myhash field\r\n&quot;aa&quot;\r\n​\r\n#hincrbyfloat key field increment: 增加浮点数。域的值需要时字符串或者可转换为双精度浮点数才可。\r\nredis&gt; HSET mykey field 10.50\r\n(integer) 1\r\nredis&gt; HINCRBYFLOAT mykey field 0.1\r\n&quot;10.6&quot;\r\nredis&gt; HSET mykey field aa\r\n(integer) 0\r\nredis&gt; HINCRBYFLOAT mykey field 2.0\r\nERR ERR hash value is not a float\r\n​</pre>\r\n\r\n<h4>hlen、hexists</h4>\r\n\r\n<pre>\r\n#hlen key :获取哈希表中域的数量\r\nredis&gt; HSET myhash field1 &quot;Hello&quot;\r\n(integer) 1\r\nredis&gt; HSET myhash field2 &quot;World&quot;\r\n(integer) 1\r\nredis&gt; HLEN myhash\r\n(integer) 2\r\n​\r\n​\r\n#hexists key field :查看哈希表的指定字段field 是否存在\r\nredis&gt; HSET myhash field1 &quot;foo&quot;\r\n(integer) 1\r\nredis&gt; HEXISTS myhash field1\r\n(integer) 1\r\nredis&gt; HEXISTS myhash field2\r\n(integer) 0\r\n​</pre>\r\n\r\n<h4>hdel</h4>\r\n\r\n<pre>\r\n#hdel key field[field ...] :删除之定点杆的字段，不存在的字段被忽略。结果返回被删除字段的数量，不包括忽略的字段\r\nredis&gt; HSET myhash field1 &quot;foo&quot;\r\n(integer) 1\r\nredis&gt; HDEL myhash field1\r\n(integer) 1\r\nredis&gt; HDEL myhash field2\r\n(integer) 0\r\n​</pre>\r\n\r\n<h4>hscan、hstrlen</h4>\r\n\r\n<pre>\r\n#hscan key cursor[match pattern][COUNT count]:遍历哈希表中的键值对。\r\n#cursor-游标；pattern-匹配模式；count-指定从集合里返回多少元素，默认为10.\r\nredis&gt; HSET myhash field1 &quot;11&quot; field2 &quot;22&quot;\r\n(integer) 2\r\nredis&gt; hscan myhash 0\r\n1) &quot;0&quot;\r\n2) 1) &quot;field1&quot;\r\n &nbsp; 2) &quot;11&quot;\r\n &nbsp; 3) &quot;field2&quot;\r\n &nbsp; 4) &quot;22&quot;\r\nredis&gt; hscan myhash 0 match &quot;1*&quot;\r\n1) &quot;0&quot;\r\n2) 1) &quot;field1&quot;\r\n &nbsp; 2) &quot;11&quot;\r\n​</pre>\r\n', '', NULL, NULL, 0, '2022-07-24 17:57:31', '2022-07-24 17:57:31', 0, NULL);
INSERT INTO `blog` VALUES (27, 1, '01', 4, 'redis-数据结构-集合', '<p>集合（set）是 Redis 数据库中的无序字符串集合。在 Redis 中，添加，删除和查找的时间复杂度是 O(1)。由于该集的唯一属性，它只添加一次。集合中的最大成员数为 2^32-1 个元素（超过 40 亿个元素）。</p>\r\n\r\n<h4>sadd、srem、spop</h4>\r\n\r\n<pre>\r\n<code>#sadd key member[member ...]:将一个或多个元素添加到集合中。返回添加成功的个数，不包含重复元素\r\nredis&gt; SADD myset \"Hello\"\r\n(integer) 1\r\nredis&gt; SADD myset \"World\"\r\n(integer) 1\r\nredis&gt; SADD myset \"World\"\r\n(integer) 0\r\nredis&gt; SMEMBERS myset\r\n1) \"World\"\r\n2) \"Hello\"\r\n\r\n#srem key member[member ...]:删除指定的元素。返回被删除的元素个数，不包含不存在的元素\r\nredis&gt; sadd wyh v1 v2 v3 v4 v5\r\n(integer) 5\r\nredis&gt; srem wyh v2 v3\r\n(integer) 2\r\nredis&gt; smembers wyh\r\n1) \"v5\"\r\n2) \"v4\"\r\n3) \"v1\"\r\n\r\n#spop key[count]: 从集合 key中删除并返回一个或多个随机元素。\r\n#count 大于内部集合元素，将返回整个集合。spop使用Knuth采样和Floyd采样算法\r\nredis&gt; sadd wyh v1 v2 v3 v4\r\n(integer) 4\r\nredis&gt; spop wyh 2\r\n1) \"v2\"\r\n2) \"v4\"\r\nredis&gt; smembers wyh\r\n1) \"v1\"\r\n2) \"v3\"\r\n\r\n</code></pre>\r\n\r\n<h4>smembers、scard、srandmenber、sismember、smismember</h4>\r\n\r\n<pre>\r\n<code>#smember key :返回key中的成员，不存在为空集合\r\n#sismember key member :判断member是否是key集合的成员\r\nredis&gt; SADD myset \"one\"\r\n(integer) 1\r\nredis&gt; SISMEMBER myset \"one\"\r\n(integer) 1\r\nredis&gt; SISMEMBER myset \"two\"\r\n(integer) 0\r\n\r\n#smismember key member[member ...] :用来检查给定的 member 是不是特定集合的成员\r\nredis&gt; SADD myset \"one\"\r\n(integer) 1\r\nredis&gt; SMISMEMBER myset \"one\"\r\n(integer) 1\r\nredis&gt; SMISMEMBER myset \"two\"\r\n(integer) 0\r\n\r\n#srandmember key [count] :随即返回集合中的元素。\r\n#count&gt;0,返回含有count个不同元素的数组。count大于集合，则返回集合中的所有元素。\r\n#count&lt;0,绝对值小于元素的个数，则返回不同元素的集合；绝对值大于集合个数，则返回的结果集会存在一个元素出现多次的情况\r\n#该命令类似于spop,spop会将被选择的元素从集合中移除，而srandmember仅仅是返回元素，不进行移除操作。\r\nredis&gt; sadd wyh v1 v2 v3\r\n(integer) 3\r\nredis&gt; srandmember wyh -2\r\n1) \"v3\"\r\n2) \"v1\"\r\nredis&gt; srandmember wyh -5\r\n1) \"v3\"\r\n2) \"v3\"\r\n3) \"v3\"\r\n4) \"v3\"\r\n5) \"v1\"\r\nredis&gt; \r\n\r\n</code></pre>\r\n\r\n<h4>sdiff、sdiffstore</h4>\r\n\r\n<pre>\r\n<code>#sdiff key[key ...] :返回第一个集合与其它集合的差异，可以认为是第一个集合独有的元素\r\nredis&gt; sadd wyh a b c d\r\n(integer) 4\r\nredis&gt; sadd wyh1 a c e f\r\n(integer) 4\r\nredis&gt; sdiff wyh wyh1\r\n1) \"b\"\r\n2) \"d\"\r\n\r\n#sdiffstore destination key [key ...] :将差异的结果集放到desination,并返回给客户端.当desination存在时，将被覆盖。\r\nredis&gt; sadd wyh a b c d\r\n(integer) 4\r\nredis&gt; sadd wyh1 a b\r\n(integer) 2\r\nredis&gt; sdiffstore result wyh wyh1\r\n(integer) 2\r\nredis&gt; smembers result\r\n1) \"c\"\r\n2) \"d\"\r\n\r\n</code></pre>\r\n\r\n<h4>sinter sinterstore</h4>\r\n\r\n<pre>\r\n<code>#sinter key [key ...] :返回所有几何的交集，结果返回成员个数\r\nredis&gt; sadd wyh a b c\r\n(integer) 3\r\nredis&gt; sadd xw a\r\n(integer) 1\r\nredis&gt; sinter wyh xw\r\n1) \"a\"\r\n\r\n#sinterstore destination key [key] :将结果保存在destination中，集合存在时，被覆盖\r\nredis&gt; sadd wyh a b c d\r\n(integer) 4\r\nredis&gt; sadd xw a c\r\n(integer) 2\r\nredis&gt; sinterstore result wyh xw\r\n(integer) 2\r\nredis&gt; smembers result\r\n1) \"a\"\r\n2) \"c\"\r\n\r\n</code></pre>\r\n\r\n<h4>sunion、sunionstore</h4>\r\n\r\n<pre>\r\n<code>#sunion key [key ...] :返回集合的并集\r\nredis&gt; sadd wyh a c b\r\n(integer) 3\r\nredis&gt; sadd xw a d e\r\n(integer) 3\r\nredis&gt; sadd xs f g\r\n(integer) 2\r\nredis&gt; sunion wyh xw xs\r\n1) \"g\"\r\n2) \"f\"\r\n3) \"b\"\r\n4) \"d\"\r\n5) \"c\"\r\n6) \"a\"\r\n7) \"e\"\r\n\r\n#sunion destination key [key] :存储在 destination 中,如果 destination 已经存在，则被覆盖。\r\nredis&gt; sadd wyh a b\r\n(integer) 2\r\nredis&gt; sadd xw c d\r\n(integer) 2\r\nredis&gt; sunionstore result wyh xw\r\n(integer) 4\r\nredis&gt; smembers result\r\n1) \"c\"\r\n2) \"d\"\r\n3) \"a\"\r\n4) \"b\"\r\n\r\n</code></pre>\r\n\r\n<h4>sscan、smove</h4>\r\n\r\n<pre>\r\n<code>#sscan key cursor [match pattern][count count] :继承自scan\r\n&gt; SADD myset1 \"Google\"\r\n(integer) 1\r\n&gt; SADD myset1 \"Redis\"\r\n(integer) 1\r\n&gt; SADD myset1 \"Taobao\"\r\n(integer) 1\r\n&gt; SSCAN myset1 0 match R*\r\n1) \"0\"\r\n2) 1) \"Redis\"\r\n\r\n</code></pre>\r\n', '', NULL, NULL, 0, '2022-07-24 19:35:24', '2022-07-24 19:35:24', 0, NULL);
INSERT INTO `blog` VALUES (28, 1, '01', 4, '初用axure', '<p>很早就想学习axure画原型，所谓技多不压身。但是由于懒惰一直没有进行。早上洗漱的时候有意识的找了一个视频看，感觉有点简单，中午休息的时候画了一下，感觉还不错。下面是我跟着视频画的微信界面。</p>\r\n\r\n<p><img alt=\"\" src=\"/202207/4_20220725134658.png\" /><img alt=\"\" src=\"blog/202207/4_20220725134658.png\" /><img alt=\"\" src=\"/blog/202207/4_20220725134658.png\" style=\"height:715px; width:775px\" /></p>\r\n\r\n<p>模仿微信的界面，简单用了axure的一些小功能。首先将微信截图复制到中间的布局中。方便照葫芦画瓢。这个原型用到的都已经圈到下面的图里面。</p>\r\n\r\n<ol>\r\n	<li>第一部分，暂时没有用到，后面看动态页面的时候大概会用到吧</li>\r\n	<li>第二部分是元件，主要用了box\\text还有一个椭圆。</li>\r\n	<li>第三部分是标尺。在进行对齐，保持同样间距有很大的作用，使用的时候在标尺处按住向下拖动，即可产生一条横线，拖动元器件过来的时候就可以利用标尺对齐了。不用的时候可以鼠标框一下，delete就可以</li>\r\n	<li>第四部分也是标尺，只不过是垂直方向的，同上</li>\r\n	<li>第五部分调整元件的大小还有背景颜色等，还没有怎么用。后续待开发&hellip;&hellip;</li>\r\n	<li>第六部分是元件的填充色，点开之后里面有一个铅笔样的图标，可以用它吸取别处的颜色，然后进行填充。这个真的是绝绝子。</li>\r\n	<li>第七部分是线条的填充色，跟第六部分是一样的</li>\r\n	<li>序号6-7的上面是剧中对齐之类的功能，试着用了一次，但感觉不怎么会。</li>\r\n	<li>最后导出就好了，或者直接F5浏览器可以直接看</li>\r\n</ol>\r\n\r\n<p>未完待续&hellip;&hellip;</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/4_20220725202931.jpg\" style=\"height:428px; width:800px\" /><img alt=\"\" src=\"blog/202207/4_20220725134658.png\" /></p>\r\n', '', NULL, NULL, 0, '2022-07-25 13:45:54', '2022-07-25 13:45:54', 0, NULL);
INSERT INTO `blog` VALUES (29, 1, '01', 2, 'axure使用2', '<p>昨天练了几个微信的原型图交下作业</p>\r\n\r\n<p>1、在阿里巴巴矢量图网站找一些图标：https://www.iconfont.cn/。可以找到对应的图片和颜色，点击下载</p>\r\n\r\n<p>2、下载下来的图片不适用时，可以选择截取。在axure里面右击鼠标，选择crop image。</p>\r\n\r\n<p>3、再做朋友圈的点赞和评论的入口时，是一个..，且他下面还有一个浅灰色的底。这个时候需要叠加元件。右击鼠标，order-&gt;brage to &hellip;&hellip; 然后。。就显示在底图上面了。</p>\r\n\r\n<p>4、遮盖页面。比如登录输入错误密码之后，会弹出出一个提示，这个时候只有弹框显示在最上面，下面的图片被暗色遮盖。是拖动一个box，设置颜色为纯黑，然后透明度设置为50即可。都是在颜色填充部分的操作。</p>\r\n\r\n<p>5、添加事件。选择热区，放到想要操作的地方，然后在最后测得属性选择事件，进行想要操作的时间属性即可。</p>\r\n', '', NULL, NULL, 0, '2022-07-27 12:56:45', '2022-07-27 12:56:45', 0, NULL);
INSERT INTO `blog` VALUES (30, 1, '01', 2, 'axure-控制面板', '<p>使用控制面板可以实现图片的变换，轮播图。</p>\r\n\r\n<p>选择控制面板之后，双击控制面板区域，弹出一个弹窗。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/4_20220727234821.jpg\" style=\"height:517px; width:1142px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<ol>\r\n	<li>添加状态：点击+号添加状态。添加完状态之后，双击状态名字，会重新打开一个页面，可以将图片等放到里面。而且添加后的状态在右下角可以显示出来，点击该处也可进行状态。</li>\r\n	<li>动态面板的点击时事件主要是通过设置面板状态来控制的。</li>\r\n</ol>\r\n\r\n<ul>\r\n	<li>1-4的按钮事件：选择左侧set panel state ，中间和右侧都勾上。选择点击他时的状态是具体那张图片。</li>\r\n	<li>自动轮播事件：自动轮播是在控制面板外点击，在时间里面会多出来一个onpageload操作，给他添加的select stats 为下一个即可实现，还可以指定每个图片出现的时间，滑动的方向</li>\r\n	<li>5-6的左右滑动事件：左右添加热区，给热区添加事件，select stats选择next或者previous就可以。访问的时候会发现点击了5或6之后，打断了图片的自动轮播。这个时候可以直接将自动轮播的事件复制到5-6的case里面去。</li>\r\n</ul>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/4_20220728000637.jpg\" style=\"height:645px; width:886px\" /></p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/4_20220728000703.jpg\" style=\"height:583px; width:886px\" /></p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/4_20220728000722.jpg\" style=\"height:579px; width:867px\" /></p>\r\n', '', NULL, NULL, 0, '2022-07-27 23:45:09', '2022-07-27 23:45:09', 0, NULL);
INSERT INTO `blog` VALUES (31, 0, '01', 1, 'MySQL索引', '<p>&nbsp;</p>\r\n\r\n<table>\r\n	<tbody>\r\n		<tr>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n		<tr>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n		<tr>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n		<tr>\r\n			<td>&nbsp;</td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p>1</p>\r\n', '', NULL, NULL, 0, '2022-06-22 19:48:02', '2023-02-08 16:39:23', 1, '数据库');
INSERT INTO `blog` VALUES (32, 1, '02', 1, 'MySQL', '<p><strong>概念</strong></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/113\" target=\"_blank\">数据库设计步骤</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/114\" target=\"_blank\">一条 SQL 语句在 MySQL 中如何执行的?</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/115\" target=\"_blank\">InnoDB 与 MyISAM 的区别</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/62\" target=\"_blank\">Mysql 中锁</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/57\" target=\"_blank\">MySQL隔离级别</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/56\" target=\"_blank\">分库与分表设计</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/64\" target=\"_blank\">MySQL 的复制原理以及流程</a></li>\r\n</ul>\r\n\r\n<p><strong>数据表/库相关</strong></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/60\" target=\"_blank\">Blob 和 text 有什么区别</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/61\" target=\"_blank\">mysql 里记录货币用什么字段类型比较好</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/52\" target=\"_blank\">百万级别或以上的数据，如何删除?</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/53\" target=\"_blank\">MySQL 死锁如何解决</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/63\" target=\"_blank\">MySQL 数据库 cpu 飙升的话，要怎么处理呢</a></li>\r\n</ul>\r\n\r\n<p><strong>索引</strong></p>\r\n\r\n<p>三个维度：索引哪些情况会失效，索引不适合哪些场景，索引一些规则特性</p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/50\" target=\"_blank\">索引类型、分类、原则、场景</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/49\" target=\"_blank\">索引优缺点、创建索引原则</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/51\" target=\"_blank\">索引哪些情况会失效</a></li>\r\n</ul>\r\n\r\n<p><strong>sql相关</strong></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/54\" target=\"_blank\">优化 SQL</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/59\" target=\"_blank\">一条 sql 执行过长的时间如何优化</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/58\" target=\"_blank\">select for update 含义</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/38\" target=\"_blank\">MySQL 中 in 和 exists 的区别</a></li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2020-06-20 20:48:34', '2023-02-08 19:38:59', 0, '数据库');
INSERT INTO `blog` VALUES (33, 1, '01', 1, '七、Nacos Config-实现多环境切换', '<p><strong><span style=\"font-size:16px\">1、如何实现多环境切换</span></strong></p>\r\n\r\n<p>在日常开发过程中，对于同一个服务或者项目工程在不同的环境所需要的配置文件是不同的。如访问的数据库、redis或者MQ等其他中间件， 要进行环境隔离。如果每次部署都需要去修改配置文件的话是十分不便的。在微服务场景下，这个问题尤为突出，因为代码工程的数量是传统 目的几十倍。需要借助一些组件，在不修改配置文件的前提下动态的切换运行环境。Nacos Config 给我们提供了类似的功能。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202208/1_20220803155817.png\" /><a href=\"/blog/202208/1_20220803155817.png\"> </a></p>\r\n\r\n<p><a href=\"/blog/202208/1_20220803155817.png\">1、添加依赖</a></p>\r\n\r\n<pre>\r\n<a href=\"/blog/202208/1_20220803155817.png\">\r\n<code>	&lt;!-- nacos-config --&gt;\r\n		&lt;dependency&gt;\r\n			&lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\r\n			&lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;\r\n		&lt;/dependency&gt;\r\n		&lt;!-- SpringCloud alibaba nacos --&gt;\r\n		&lt;dependency&gt;\r\n			&lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\r\n			&lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\r\n		&lt;/dependency&gt;</code></a></pre>\r\n\r\n<p><a href=\"/blog/202208/1_20220803155817.png\">2、写 yml 配置文件：<code>bootstrap.yml</code>&nbsp;、<code>application.yml</code>。<br />\r\n<code>问题：为什么需要两个 yml 配置文件？</code></a></p>\r\n\r\n<p><a href=\"/blog/202208/1_20220803155817.png\">Nacos 和 SpringCloud Config 一样，在项目初始化时，要保证从配置中心进行配置拉取，拉取配置后才能保证项目正常启动。SpringBoot 中配置文件的加载是存在优先级顺序的：<code>bootstrap 优先级高于 application&nbsp;</code></a></p>\r\n\r\n<pre>\r\n<a href=\"/blog/202208/1_20220803155817.png\">\r\n<code>server:\r\n  port: 3377\r\n\r\nspring:\r\n  application:\r\n    name: nacos-config-center-client\r\n  cloud:\r\n    nacos:\r\n      # 服务注册\r\n      discovery:\r\n        server-addr: localhsot:8848 # 服务注册中心地址\r\n      # 服务配置\r\n      config:\r\n        server-addr: localhost:8848 # 服务配置中心地址\r\n        file-extension: yaml # 指定 yaml 格式的配置\r\n        group: config-group1\r\n</code></a></pre>\r\n\r\n<pre>\r\n<a href=\"/blog/202208/1_20220803155817.png\">\r\n<code>spring:\r\n  profiles:\r\n    active: dev #表示开发环境\r\n</code></a></pre>\r\n\r\n<p><a href=\"/blog/202208/1_20220803155817.png\">主启动类</a></p>\r\n\r\n<pre>\r\n<a href=\"/blog/202208/1_20220803155817.png\">\r\n<code>@SpringBootApplication\r\n@EnableDiscoveryClient\r\npublic class NacosConfigCenterClientMain3377 {\r\n    public static void main(String[] args) {\r\n        SpringApplication.run(NacosConfigCenterClientMain3377.class, args);\r\n    }\r\n}\r\n</code></a></pre>\r\n\r\n<p><a href=\"/blog/202208/1_20220803155817.png\">&nbsp;</a></p>\r\n\r\n<p><a href=\"/blog/202208/1_20220803155817.png\">配置</a></p>\r\n\r\n<pre>\r\n<a href=\"/blog/202208/1_20220803155817.png\">\r\n<code>Data Id 配置公式：${spring.application.name}-${spring.profile.active}.${spring.cloud.nacos.config.file-extension}\r\n\r\n1、${spring.application.name} 微服务名称\r\n2、${spring.profile.active} 当前配置环境对应的配置文件 profile\r\n3、${spring.cloud.nacos.config.file-extension} 指定配置文件格式，即文件后缀名\r\n\r\nGroup 配置公式：${spring.cloud.nacos.config.group}\r\n</code></a></pre>\r\n\r\n<p><a href=\"/blog/202208/1_20220803155817.png\">Nacos 存储配置有几个比较重要的表分别是:&nbsp;<br />\r\nconfig_info 存储配置信息的主表，里面包含 dataId、groupId、content、tenantId、encryptedDataKey 等数据。<br />\r\nconfig_info_beta 灰度测试的配置信息表，存储的内容和 config_info 基本相似。有⼀个beta_ips 字段用于客户端请求配置时判断是否是灰度的 ip。<br />\r\nconfig_tags_relation 配置的标签表，在发布配置的时候如果指定了标签，那么会把标签和配置的关联信息存储在该表中。<br />\r\nhis_config_info 配置的历史信息表，在配置的发布、更新、删除等操作都会记录⼀条数据，可以做多版本管理和快速回滚。</a></p>\r\n\r\n<p><a href=\"/blog/202208/1_20220803155817.png\">&nbsp;</a></p>\r\n\r\n<p><a href=\"/blog/202208/1_20220803155817.png\">&nbsp;</a></p>\r\n\r\n<p><em>@RefreshScope</em> // 支持Nacos得动态刷新功能</p>\r\n\r\n<pre>\r\n<code>@RestController\r\n@RefreshScope // 支持Nacos得动态刷新功能\r\npublic class TestController {\r\n	@Value(\"${server.port}\")\r\n	private String serverPort;\r\n\r\n	@GetMapping(value = \"/payment/nacos/{id}\")\r\n	public SuccessProtocol getPayment(@PathVariable(\"id\") Integer id) {\r\n		String data = \"nacos registry,serverPort:\" + serverPort + \"\\t id\" + id;\r\n		return new SuccessProtocol(data);\r\n	}\r\n\r\n	@Value(\"${config.info}\")\r\n	private String configInfo;\r\n\r\n	@GetMapping(\"/config/info\")\r\n	public String getConfigInfo() {\r\n		return configInfo;\r\n	}\r\n\r\n}\r\n</code></pre>\r\n\r\n<p><strong><span style=\"font-size:16px\">2、如何解决不同环境相同配置的问题</span></strong></p>\r\n\r\n<p>在实际的开发过程中，我们的工程项目所用到的配置参数大多数并不需要根据不同的环境进行区分，生产、测试、开发环境所用到的参数值 的。如何解决同一服务在多环境中，引用相同的配置的问题?Nacos Config也提供了相应的解决方案。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202208/1_20220803161459.png\" /></p>\r\n\r\n<p>在Nacos config中添加 配置，data_id为configdemo.yaml</p>\r\n\r\n<p><strong>思考:如果同一个配置项在三个配置文件中都存在且值不同，最终项目读取的是哪个呢?</strong></p>\r\n\r\n<p><strong>结论:如果配置了spring.profile.active 则优先获取configdemo-${spring.profile.active},yaml中的值</strong></p>\r\n\r\n<p><strong><span style=\"font-size:16px\">3、不同微服务之间相同配置如何共享</span></strong></p>\r\n\r\n<p>上面我们介绍了同一个微服务在多个环境中基于nacos config的解决方案和具体的配置方法。但是在日常的开发过程中也存在一些跨服务之间 配置。比如我们的redis地址，或者MQ、服务注册中心等公共组件。这些公共组件往往是多个微服务共享的，并不属于某一个微服务。如果使 提到的配置方式则会冗余很多份相同的配置在不同的微服务中</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202208/1_20220803162003.png\" /></p>\r\n\r\n<p><strong>通过shared-configs方式</strong></p>\r\n\r\n<p>在nacos config中增加配置 data_id redis.yaml，添加配置内容redisip: 10.10.10.10</p>\r\n\r\n<p>修改configdemo的bootstrap.yaml的配置文件，增加配置spring.cloud.nacos.config.shared-configs[0]</p>\r\n\r\n<pre>\r\n<code>spring:\r\n  application:\r\n    name: configdemo #表示当前微服务需要向配置中心索要configdemo的配置 \r\n  cloud:\r\n    nacos:\r\n      config:\r\n        server-addr: localhost:8848 #表示微服务怎么去找配置中心 \r\n        file-extension: yaml #表示支持的扩展文件名 \r\n        shared-configs[0]: #shared-configs是一个列表\r\n          data_id: redis.yaml\r\n          group:DEFAULT_GROUP#可以不写 默认值为DEFAULT_GROUP\r\n          refresh: true #默认是false，如果需要支持自动刷新需要配置true,搭配@RefreshScope实现动态刷新\r\n  profiles:\r\n    active: test #表示我需要向配置中心索要的生产环境的配置</code></pre>\r\n\r\n<p>如何添加多个shard-configs?</p>\r\n\r\n<pre>\r\n<code>spring:\r\n  application:\r\n    name: configdemo #表示当前微服务需要向配置中心索要configdemo的配置 \r\n  cloud:\r\n    nacos:\r\n      config:\r\n        server-addr: localhost:8848 #表示微服务怎么去找配置中心 \r\n        file-extension: yaml #表示支持的扩展文件名 \r\n        shared-configs[0]: #shared-configs是一个列表\r\n          data_id: redis.yaml\r\n          group:DEFAULT_GROUP#可以不写 默认值为DEFAULT_GROUP\r\n          refresh: true #默认是false，如果需要支持自动刷新需要配置true,搭配@RefreshScope实现动态刷新\r\n        shared-configs[1]: #shared-configs是一个列表\r\n          data_id: mq.yaml\r\n          group : DEFAULT_GROUP #可以不写 默认值为DEFAULT_GROUP\r\n          refresh: true #默认是false，如果需要支持自动刷新需要配置true,搭配@RefreshScope实现动态刷新\r\n  profiles:\r\n    active: test #表示我需要向配置中心索要的生产环境的配置</code></pre>\r\n\r\n<p><strong>通过extension-configs的方式</strong></p>\r\n\r\n<p>修改bootstrap.yaml文件，删除shard-configs相关配置，增加extension-configs[0]和extension-configs[1]如下</p>\r\n\r\n<pre>\r\n<code>spring:\r\n  application:\r\n	name: configdemo #表示当前微服务需要向配置中心索要configdemo的配置 cloud:\r\n    nacos:\r\n      config:\r\n		server-addr: localhost:8848 #表示微服务怎么去找配置中心 \r\n		file-extension: yaml #表示支持的扩展文件名 \r\n		extension-configs[0]: #shared-configs是一个列表\r\n			data_id: redis.yaml\r\n			group:DEFAULT_GROUP#可以不写 默认值为DEFAULT_GROUP\r\n			refresh: true #默认是false，如果需要支持自动刷新需要配置true,搭配@RefreshScope实现动态刷新\r\n		extension-configs[1]: #shared-configs是一个列表\r\n			data_id: mq.yaml\r\n			group : DEFAULT_GROUP #可以不写 默认值为DEFAULT_GROUP\r\n			refresh: true #默认是false，如果需要支持自动刷新需要配置true,搭配@RefreshScope实现动态刷新\r\n	profiles:\r\n		active: test #表示我需要向配置中心索要的生产环境的配置</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-06-15 21:16:24', '2022-06-15 21:16:24', 0, 'Nacos');
INSERT INTO `blog` VALUES (34, 1, '01', 1, '八、Nacos Config 动态刷新原理', '<p>所谓动态监听，简单理解就是指Nacos会自动找到那些服务已经注册，而对比来说静态监听，就是指需要有指定配置指定的服务。</p>\r\n\r\n<ul>\r\n	<li>Push：表示服务端主动将数据变更信息推送给客户端</li>\r\n</ul>\r\n\r\n<p style=\"margin-left:80px\">服务需要维持客户端的长连接，因为需要知道具体推送的客户端<br />\r\n客户端耗费内存高，因为需要保存所有客户端的连接，并且需要检测连接有效性（心跳机制</p>\r\n\r\n<ul>\r\n	<li>Pull：表示客户端主动去服务端拉取数据</li>\r\n</ul>\r\n\r\n<p style=\"margin-left:80px\">需要定时拉取数据<br />\r\n缺点：时效性，数据实时性，无效请求</p>\r\n\r\n<p>核心：Nacos动态刷新机制，采用推和拉的优点，避免缺点。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202208/1_20220803165012.png\" /></p>\r\n\r\n<p>Nacos做配置中心的时候，配置数据的交互模式是有服务端push推送的，还是客户端pull拉取的？</p>\r\n\r\n<p>Nacos客户端发送一个请求连接到服务端，然后服务端中会有一个29.5+0.5s的一个hold期，然后服务端会将此次请求放入到allSubs队列中等待，触发服务端返回结果的情况只有两种，第一种是时间等待了29.5秒，配置未发生改变，则返回未发生改变的配置；第二种是操作Nacos Dashboard或者API对配置文件发生一次变更，此时会触发配置变更的事件，发送一条LocalDataEvent消息，此时服务端监听到消息，然后遍历allSubs队列，根据对应的groupId找到配置变更的这条ClientLongPolling任务，并且通过连接返回给客户端<br />\r\n&nbsp;</p>\r\n\r\n<p>短轮询<br />\r\n不管服务端的配置是否发生变化，不停发起请求去获取配置，比如支付订单场景中前端不断轮询订单支付的状态，这样的坏处显而易见，由于配置并不会频繁发生变更，如果是一直发请求，一定会对服务端造成很大的压力。还会造成数据推送的延迟，比如每10秒请求一次配置，如果在第11秒的时候配置更新，那么推送将会延迟9秒，等待下一次请求这就是短轮询，为了解决短轮询的问题，有了长轮询的方案<br />\r\n&nbsp;</p>\r\n\r\n<p>长轮询<br />\r\n长轮询不是什么新技术，它其实就是由服务端控制响应客户端请求结果的返回时间，来减少客户端无效请求的一种优化手段，其实对于客户端来说，长轮询的使用并没有本质上的区别，客户端发起请求后，服务端不会立即返回请求结果，而是将请求hold挂起一段时间，如果此时间段内配置数据发生变更，则立即响应客户端，若一直无变更则等到指定超时时间后响应给客户端结果，客户端重新发起长链接</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>动态刷新流程解析</p><br />\r\n<img alt=\"\" src=\"/blog/202208/1_20220803165216.png\" />\r\n', '', NULL, NULL, 0, '2022-06-16 22:49:07', '2022-06-16 22:49:07', 0, 'Nacos');
INSERT INTO `blog` VALUES (35, 1, '01', 1, '九、Sentinel 服务熔断降级、限流', '<p><a href=\"#a1\"><strong><span style=\"font-size:14px\">一、Sentinel 服务限流降级</span></strong></a></p>\r\n\r\n<p><a href=\"#a2\"><strong><span style=\"font-size:14px\">二、Sentinel 进行降级</span></strong></a></p>\r\n\r\n<p><a href=\"#a3\"><strong><span style=\"font-size:14px\">三、Sentinel 进行热点限流</span></strong></a></p>\r\n\r\n<p><a href=\"#a4\"><strong><span style=\"font-size:14px\">四、Sentinel 进行授权控制</span></strong></a></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>安装步骤<br />\r\n1、下载：https://github.com/alibaba/Sentinel/releases/download/1.8.2/sentinel-dashboard-1.8.2.jar<br />\r\n2、前提准备好 Java 8 运行环境，命令如下：java -jar sentinel-dashboard-1.8.2.jar<br />\r\n3、访问 Sentinel 的管理界面：http://localhost:8080，密码账号都是：sentinel<br />\r\n&nbsp;</p>\r\n\r\n<p><a id=\"a1\" name=\"a1\"><strong><span style=\"font-size:14px\">一、Sentinel 服务限流降级</span></strong></a></p>\r\n\r\n<p><strong>1.集成步骤</strong></p>\r\n\r\n<p>pom.xml引入依赖</p>\r\n\r\n<pre>\r\n<code>&lt;!-- SpringCloud alibaba sentinel --&gt;\r\n\r\n&lt;dependency&gt;\r\n\r\n&lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\r\n\r\n&lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;\r\n\r\n&lt;/dependency&gt;</code></pre>\r\n\r\n<p>配置文件</p>\r\n\r\n<pre>\r\n<code>server:\r\n  port: 9000\r\nspring:\r\n  application:\r\n    name: cloudalibaba-sentinel-service\r\n  cloud:\r\n    nacos:\r\n      discovery:\r\n        server-addr: localhost:8848\r\n  sentinel:\r\n    enabled: true\r\n    eager: true\r\n    transport:   #配置Sentinel Dashboard地址\r\n      dashboard: localhost:8888  #默认8719端口，假如被占用会自动从8719开始一依次+1扫描，知道找到未占用的端口\r\n      port: 8719\r\n      clientIp: localhost:8401\r\n    filter:\r\n        url-patterns: /**\r\nmanagement:\r\n  endpoints:\r\n    web:\r\n      exposure:\r\n        include: \'*\'</code></pre>\r\n\r\n<p>登录sentinel控制台 http://127.0.0.1:9000/ 可看到服务已经注册到sentinel</p>\r\n\r\n<p><strong>2.使用Sentinel进行流控</strong></p>\r\n\r\n<p>如何新增流控规则--在页面表单上配置</p>\r\n\r\n<p>流控高级选项</p>\r\n\r\n<p style=\"margin-left:40px\">流控模式</p>\r\n\r\n<ul>\r\n	<li>直接模式:默认的流控模式，直接限制资源名的QPS或者线程数</li>\r\n	<li>关联模式:</li>\r\n	<li>链路模式:之前我们都是基于controller层的限流，sentinel同样支持颗粒度更细的从controller到service层的限流。</li>\r\n</ul>\r\n\r\n<p>链路模式:</p>\r\n\r\n<p>在pom.xml中增加配置</p>\r\n\r\n<pre>\r\n<code>&lt;dependency&gt;\r\n        &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt;\r\n        &lt;artifactId&gt;sentinel-web-servlet&lt;/artifactId&gt;\r\n&lt;/dependency&gt;</code></pre>\r\n\r\n<p>在application.yaml中增加配置spring.cloud.sentinel.filter.enable: false ,增加后yaml文件为</p>\r\n\r\n<pre>\r\n<code>server:\r\n  port: 8401\r\nspring:\r\n  application:\r\n    name: cloudalibaba-sentinel-service\r\n  cloud:\r\n    nacos:\r\n      discovery:\r\n        server-addr: localhost:8848\r\n  sentinel:\r\n    enabled: true\r\n    eager: true\r\n    transport:   #配置Sentinel Dashboard地址\r\n      dashboard: localhost:8888  #默认8719端口，假如被占用会自动从8719开始一依次+1扫描，知道找到未占用的端口\r\n      port: 8719\r\n      clientIp: localhost:8401\r\n    filter:\r\n      url-patterns: /**\r\n      enabled: false\r\nmanagement:\r\n  endpoints:\r\n    web:\r\n      exposure:\r\n        include: \'*\'</code></pre>\r\n\r\n<p>新增配置类开放全部链路</p>\r\n\r\n<pre>\r\n<code>import com.alibaba.csp.sentinel.adapter.servlet.CommonFilter;\r\nimport org.springframework.boot.web.servlet.FilterRegistrationBean;\r\nimport org.springframework.context.annotation.Bean;\r\nimport org.springframework.context.annotation.Configuration;\r\n\r\n@Configuration\r\npublic class FilterConfiguration {\r\n    @Bean\r\n    public FilterRegistrationBean registrationBean(){\r\n        FilterRegistrationBean registrationBean = new FilterRegistrationBean();\r\n        registrationBean.setFilter(new CommonFilter());\r\n        registrationBean.addUrlPatterns(\"/*\");\r\n        registrationBean.addInitParameter(CommonFilter.WEB_CONTEXT_UNIFY,\"false\");\r\n        registrationBean.setName(\"sentinelFilter\");\r\n    return registrationBean;\r\n  }\r\n}</code></pre>\r\n\r\n<p>新增测试service</p>\r\n\r\n<pre>\r\n<code>import com.alibaba.csp.sentinel.annotation.SentinelResource;\r\nimport org.springframework.stereotype.Service;\r\n@Service\r\npublic class TestService {\r\n    @SentinelResource(\"test\")\r\n    public void test(){\r\n        System.out.println(\"test\");\r\n    }\r\n}</code></pre>\r\n\r\n<p>在TestConroller新增两个测试方法</p>\r\n\r\n<pre>\r\n<code>@GetMapping(\"/test2\")\r\npublic String test2() {\r\n    testService.test();\r\n    return \"sentinel test2\";\r\n}\r\n@GetMapping(\"/test3\")\r\npublic String test3() {\r\n    testService.test();\r\n    return \"sentinel test3\";\r\n}</code></pre>\r\n\r\n<p>重启项目后，需要先在浏览器分别访问几次http://localhost:9000/test2/和http://localhost:9000/test3/ 才能将这两个http接口注册到sentine 次重启后都需要访问下才能在sentinel控制台中看到需要限流的url)如图所示</p>\r\n\r\n<p>此时相当于限制了 TestController.test2-&gt;TestService.test 这条链路，而 TestController.test3-&gt;TestService.test这条链路没有被限制，可分别频繁访问http://localhost:9000/test2/和http://localhost:9000/test3/进行测试，发现test2的路径已经被限流，而test3可以随意访问无限制。</p>\r\n\r\n<p><strong>流控效果</strong></p>\r\n\r\n<p>**快速失败:**直接抛出异常<br />\r\n**Warm Up:**表示预热一段时间内进行严格的限流，超过这个时间后恢复普通的限流，表示在点击保存后5秒内，QPS超过9的三分之一 也就是3就会限流，5秒后QPS超过9才会限流。一般用于服务器刚刚启动时的场景。</p>\r\n\r\n<p>**排队等待:**在第一次超过单机阈值后等待超时时间300毫秒后，如果没有被限流则访问成功，如果被限流则访问失败抛出异常。</p>\r\n\r\n<p><a id=\"a2\" name=\"a2\"><strong><span style=\"font-size:14px\">二、Sentinel 进行降级</span></strong></a></p>\r\n\r\n<p><strong>熔断策略</strong></p>\r\n\r\n<p>慢调用比例 ( SLOW_REQUEST_RATIO ):</p>\r\n\r\n<p>选择以慢调用比例作为阈值，需要设置允许的慢调用 RT(即最大的响应时间)，请求的响应时间大 则统计为慢调用。当单位统计时长( statIntervalMs )内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔 长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态(HALF-OPEN 状态)，若接下来的一个请求响应时间小于设置的慢调 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202208/1_20220803172231.png\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>表示单个请求响应时间超过100毫秒后进入准降级状态，接下来1秒(系统默认值)内有超过10个请求，且其中只要有1次或者以上的请求响 超过100毫秒，则会在接下来的5秒内所有请求都会被熔断。5秒后，请求会再次探测响应时长，如果不足100毫秒，则恢复，否则继续保持熔 等待下一个5秒。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>异常比例 ( ERROR_RATIO ):</p>\r\n\r\n<p>当单位统计时长( statIntervalMs )内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下 熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态(HALF-OPEN 状态)，若接下来的一个请求成功完成(没有错 则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0] ，代表 0% - 100%。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202208/1_20220803172314.png\" /></p>\r\n\r\n<p>当1秒内请求数目大于10次且有超过1次的请求抛出过异常，则接下来5秒会被熔断，经过5秒后进入探测状态，如果接下来的一个请求成功则 断</p>\r\n\r\n<p>异常数 ( ERROR_COUNT ):</p>\r\n\r\n<p>当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态(HALF- OPEN 状态)，若接下来的一个请求成功完成(没有错误)则结束熔断，否则会再次被熔断。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202208/1_20220803172348.png\" /></p>\r\n\r\n<p>当1秒内请求数目大于10次且有超过1次的请求抛出过异常，则接下来5秒会被熔断，经过5秒后进入探测状态，如果接下来的一个请求成功则断。</p>\r\n\r\n<p><a id=\"a3\" name=\"a3\"><strong><span style=\"font-size:14px\">三、Sentinel 进行热点限流</span></strong></a></p>\r\n\r\n<p><strong>新增热点规则</strong></p>\r\n\r\n<p>在TestConroller 新增测试代码</p>\r\n\r\n<pre>\r\n<code>@GetMapping(\"/hot\")\r\n@SentinelResource(\"hot\")\r\npublic String hot(@RequestParam(value=\"productId\",required = false)Integer productId,@RequestParam(value=\"userId\",required = false)Integer userId) throws InterruptedException {\r\n    return \"productid is \"+productId+\"  userid is \"+userId;\r\n}</code></pre>\r\n\r\n<p>重启服务并在浏览器访问http://localhost:9000/hot?productId=1&amp;userId=2</p>\r\n\r\n<p>打开sentinel控制台 点击新增热点按钮</p>\r\n\r\n<p><a id=\"a4\" name=\"a4\"><strong><span style=\"font-size:14px\">四、Sentinel&nbsp;进行授权控制</span></strong></a></p>\r\n\r\n<p>授权控制整合</p>\r\n\r\n<p>Sentinel 整合 OpenFeign（参考）：<a href=\"https://blog.csdn.net/qq_36763419/article/details/120119872\">https://blog.csdn.net/qq_36763419/article/details/120119872</a></p>\r\n\r\n<p><a href=\"https://github.com/alibaba/spring-cloud-alibaba/wiki/Sentinel#%E5%8A%A8%E6%80%81%E6%95%B0%E6%8D%AE%E6%BA%90%E6%94%AF%E6%8C%81\">Sentinel规则持久化配置（官网说明）</a></p>\r\n', '', NULL, NULL, 0, '2022-06-17 22:11:32', '2022-06-17 22:11:32', 0, 'Sentinel');
INSERT INTO `blog` VALUES (36, 0, '01', 1, '十、使用Sentinel进行降级', '<p><strong>熔断策略</strong></p>\r\n\r\n<p>慢调用比例 ( SLOW_REQUEST_RATIO ):</p>\r\n\r\n<p>选择以慢调用比例作为阈值，需要设置允许的慢调用 RT(即最大的响应时间)，请求的响应时间大 则统计为慢调用。当单位统计时长( statIntervalMs )内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔 长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态(HALF-OPEN 状态)，若接下来的一个请求响应时间小于设置的慢调 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202208/1_20220803172231.png\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>表示单个请求响应时间超过100毫秒后进入准降级状态，接下来1秒(系统默认值)内有超过10个请求，且其中只要有1次或者以上的请求响 超过100毫秒，则会在接下来的5秒内所有请求都会被熔断。5秒后，请求会再次探测响应时长，如果不足100毫秒，则恢复，否则继续保持熔 等待下一个5秒。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>异常比例 ( ERROR_RATIO ):</p>\r\n\r\n<p>当单位统计时长( statIntervalMs )内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下 熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入探测恢复状态(HALF-OPEN 状态)，若接下来的一个请求成功完成(没有错 则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0] ，代表 0% - 100%。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202208/1_20220803172314.png\" /></p>\r\n\r\n<p>当1秒内请求数目大于10次且有超过1次的请求抛出过异常，则接下来5秒会被熔断，经过5秒后进入探测状态，如果接下来的一个请求成功则 断</p>\r\n\r\n<p>异常数 ( ERROR_COUNT ):</p>\r\n\r\n<p>当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态(HALF- OPEN 状态)，若接下来的一个请求成功完成(没有错误)则结束熔断，否则会再次被熔断。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202208/1_20220803172348.png\" /></p>\r\n\r\n<p>当1秒内请求数目大于10次且有超过1次的请求抛出过异常，则接下来5秒会被熔断，经过5秒后进入探测状态，如果接下来的一个请求成功则 断。</p>\r\n', '', NULL, NULL, 0, '2022-08-03 17:24:01', '2022-08-03 17:24:01', 1, NULL);
INSERT INTO `blog` VALUES (37, 0, '01', 1, '十一、使用Sentinel进行热点限流', '<p><strong>新增热点规则</strong></p>\r\n\r\n<p>在TestConroller 新增测试代码</p>\r\n\r\n<pre>\r\n<code>@GetMapping(\"/hot\")\r\n@SentinelResource(\"hot\")\r\npublic String hot(@RequestParam(value=\"productId\",required = false)Integer productId,@RequestParam(value=\"userId\",required = false)Integer userId) throws InterruptedException {\r\n    return \"productid is \"+productId+\"  userid is \"+userId;\r\n}</code></pre>\r\n\r\n<p>重启服务并在浏览器访问http://localhost:9000/hot?productId=1&amp;userId=2</p>\r\n\r\n<p>打开sentinel控制台 点击新增热点按钮</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-08-03 17:25:05', '2022-08-03 17:25:05', 1, NULL);
INSERT INTO `blog` VALUES (38, 1, '01', 1, 'MySQL中 in 和 exists 的区别', '<p><strong>&nbsp;mysql 中 in 和 exists 的区别</strong></p>\r\n\r\n<p>假设表 A 表示某企业的员工表，表 B 表示部门表，查询所有部门的所有员工，</p>\r\n\r\n<p>很容易有以下 SQL:</p>\r\n\r\n<pre>\r\n<code>select * from A where deptId in (select deptId from B);</code></pre>\r\n\r\n<p>这样写等价于:</p>\r\n\r\n<pre>\r\n<code>先查询部门表 B\r\nselect deptId from B\r\n再由部门 deptId，查询 A 的员工\r\nselect * from A where A.deptId = B.deptId</code></pre>\r\n\r\n<pre>\r\n可以抽象成这样的一个循环:\r\n</pre>\r\n\r\n<pre>\r\n<code>List&lt;&gt; resultSet ;\r\nfor(int i=0;i&lt;B.length;i++) {\r\n  for(int j=0;j&lt;A.length;j++) { \r\n    if(A[i].id==B[j].id) {\r\n       resultSet.add(A[i]);\r\n          break; \r\n    }\r\n  } \r\n}</code></pre>\r\n\r\n<p>显然，除了使用 in，我们也可以用 exists 实现一样的查询功能，如下:</p>\r\n\r\n<pre>\r\n<code>select * from A where exists (select 1 from B where A.deptId = B.deptId);</code></pre>\r\n\r\n<p>因为 exists 查询的理解就是，先执行主查询，获得数据后，再放到子查询中做 条件验证，根据验证结果(true 或者 false)，来决定主查询的数据结果是否 得意保留。<br />\r\n那么，这样写就等价于</p>\r\n\r\n<pre>\r\n<code>select * from A,先从 A 表做循环\r\nselect * from B where A.deptId = B.deptId,再从 B 表做循环.</code></pre>\r\n\r\n<p>数据库最费劲的就是跟程序链接释放。假设链接了两次，每次做上百万次的数 据集查询，查完就走，这样就只做了两次;相反建立了上百万次链接，申请链 接释放反复重复，这样系统就受不了了。即 mysql 优化原则，就是小表驱动大 表，小的数据集驱动大的数据集，从而让性能更优。 因此，我们要选择最外层循环小的，也就是，<strong>如果 B 的数据量小于 A，适合使 用 in，如果 B 的数据量大于 A，即适合选择 exists</strong>，这就是 in 和 exists 的区 别。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-08-24 22:09:30', '2022-08-26 16:22:34', 0, '数据库');
INSERT INTO `blog` VALUES (39, 1, '01', 1, '大表查询的优化方案', '<p>&nbsp;</p>\r\n\r\n<p><a id=\"a1\" name=\"a1\"><strong>数据库自增主键可能遇到什么问题</strong></a></p>\r\n\r\n<ul>\r\n	<li>使用自增主键对数据库做分库分表，可能出现诸如主键重复等的问题。解决方案的话，简单点的话可以考虑使用 UUID 哈</li>\r\n	<li>自增主键会产生表锁，从而引发问题</li>\r\n	<li>自增主键可能用完问题。</li>\r\n</ul>\r\n\r\n<p><strong>数据库中间件，sharding jdbc，mycat?</strong></p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>sharding-jdbc 目前是基于 jdbc 驱动，无需额外的 proxy，因此也无需关注 proxy 本身的高可用。</p>\r\n	</li>\r\n	<li>\r\n	<p>Mycat 是基于 Proxy，它复写了 MySQL 协议，将 Mycat Server 伪装成一个 MySQL 数据库，而 Sharding-JDBC 是基于 JDBC 接口的扩展，是以 jar 包的形 式提供轻量级服务的</p>\r\n	</li>\r\n</ul>\r\n\r\n<p><strong>主从延迟</strong></p>\r\n\r\n<pre>\r\n<strong style=\"font-family:sans-serif,Arial,Verdana,&quot;Trebuchet MS&quot;,&quot;Apple Color Emoji&quot;,&quot;Segoe UI Emoji&quot;,&quot;Segoe UI Symbol&quot;\">大表查询的优化方案</strong>\r\n</pre>\r\n\r\n<ul>\r\n	<li>\r\n	<p>优化 shema、sql 语句+索引;</p>\r\n	</li>\r\n	<li>\r\n	<p>可以考虑加缓存，memcached, redis，或者 JVM 本地缓存;</p>\r\n	</li>\r\n	<li>\r\n	<p>主从复制，读写分离;</p>\r\n	</li>\r\n	<li>\r\n	<p>分库分表;</p>\r\n	</li>\r\n</ul>\r\n\r\n<p><strong>MySQL 数据库服务器性能分析的方法命令有哪些?</strong></p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>Show status, 一些值得监控的变量值:</p>\r\n	</li>\r\n	<li>\r\n	<p>Bytes_received 和 Bytes_sent 和服务器之间来往的流量。</p>\r\n	</li>\r\n	<li>\r\n	<p>Com_*服务器正在执行的命令。</p>\r\n	</li>\r\n	<li>\r\n	<p>Created_*在查询执行期限间创建的临时表和文件。</p>\r\n	</li>\r\n	<li>\r\n	<p>Handler_*存储引擎操作。</p>\r\n	</li>\r\n	<li>\r\n	<p>Select_*不同类型的联接执行计划。</p>\r\n	</li>\r\n	<li>\r\n	<p>Sort_*几种排序信息。</p>\r\n	</li>\r\n	<li>\r\n	<p>Show profiles 是 MySql 用来分析当前会话 SQL 语句执行的资源消耗情况</p>\r\n	</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-07-28 21:10:35', '2022-08-26 17:56:22', 0, '数据库');
INSERT INTO `blog` VALUES (40, 1, '02', 1, 'Redis', '<p><span style=\"font-size:18px\"><strong>什么是 Redis?</strong></span></p>\r\n\r\n<p><span style=\"font-size:14px\">Redis，英文全称是 Remote Dictionary Server(远程字典服务)，是一 个开源的使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、 Key-Value 数据库，并提供多种语言的 API。<br />\r\n与 MySQL 数据库不同的是，Redis 的数据是存在内存中的。它的读写速度非 常快，每秒可以处理超过 10 万次读写操作。因此 redis 被广泛应用于缓存，另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务、持久化、 LUA 脚本、LRU 驱动事件、多种集群方案。</span></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/65\" target=\"_blank\">Redis 为什么这么快</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/41\" target=\"_blank\">Redis 的基本数据结构类型</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/87\" target=\"_blank\">Redis持久化方式</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/134\" target=\"_blank\">Redis 事务</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/42\" target=\"_blank\">什么是缓存击穿、缓存穿透、缓存雪崩?</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/43\" target=\"_blank\">什么是热 Key 问题，如何解决热 key 问题</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/44\" target=\"_blank\">Redis 过期策略和内存淘汰策略</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/88\" target=\"_blank\">Redis 内存优化</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/133\" target=\"_blank\">Redis 内存淘汰机制</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/45\" target=\"_blank\">Redis 16 个常见使用场景</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/132\" target=\"_blank\">Redis 和 Memcached 的区别和共同点</a></li>\r\n	<li>Redis 集群</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2020-07-13 20:30:50', '2023-02-08 19:19:46', 0, '中间件、Redis');
INSERT INTO `blog` VALUES (41, 1, '01', 1, '一、Redis 的基本数据结构类型', '<p><strong>Redis 的基本数据结构类型</strong></p>\r\n\r\n<p>Redis 有以下这五种基本类型:</p>\r\n\r\n<ul>\r\n	<li>String(字符串)</li>\r\n	<li>Hash(哈希)</li>\r\n	<li>List(列表)</li>\r\n	<li>Set(集合)</li>\r\n	<li>zset(有序集合)</li>\r\n</ul>\r\n\r\n<p>它还有三种特殊的数据结构类型</p>\r\n\r\n<ul>\r\n	<li>Geospatial</li>\r\n	<li>Hyperloglog</li>\r\n	<li>Bitmap</li>\r\n</ul>\r\n\r\n<p><strong>Redis 的五种基本数据类型</strong></p>\r\n\r\n<p><strong>String(字符串)</strong><br />\r\n简介:String 是 Redis 最基础的数据结构类型，它是二进制安全的，可以存储图片或者序列化的对象，值最大存储为 512M<br />\r\n简单使用举例: set key value、get key 等<br />\r\n应用场景:共享 session、分布式锁，计数器、限流。<br />\r\n内部编码有 3 种，int(8 字节长整型)/embstr(小于等于 39 字节字符串)/raw(大于 39 个字节字符串)</p>\r\n\r\n<p>而 Redis 使用 SDS(simple dynamic string) 封装</p>\r\n\r\n<pre>\r\n<code>struct sdshdr{\r\nunsigned int len; // 标记 buf 的长度\r\nunsigned int free; //标记 buf 中未使用的元素个数 \r\nchar buf[]; // 存放元素的坑\r\n}</code></pre>\r\n\r\n<p><strong>Hash(哈希)</strong></p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>简介:在 Redis 中，哈希类型是指 v(值)本身又是一个键值对(k-v)结构</p>\r\n	</li>\r\n	<li>\r\n	<p>简单使用举例:hset key field value 、hget key field</p>\r\n	</li>\r\n	<li>\r\n	<p>内部编码:ziplist(压缩列表) 、hashtable(哈希表)</p>\r\n	</li>\r\n	<li>\r\n	<p>应用场景:缓存用户信息等。</p>\r\n	</li>\r\n	<li>\r\n	<p>注意点:如果开发使用 hgetall，哈希元素比较多的话，可能导致 Redis 阻塞，可以使用 hscan。而如果只是获取部分 field，建议使用 hmget。</p>\r\n	</li>\r\n</ul>\r\n\r\n<p><strong>List(列表)</strong></p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>简介:列表(list)类型是用来存储多个有序的字符串，一个列表最多可以存储 2^32-1 个元素。</p>\r\n	</li>\r\n	<li>\r\n	<p>简单实用举例: lpush key value [value ...] 、lrange key start end</p>\r\n	</li>\r\n	<li>\r\n	<p>内部编码:ziplist(压缩列表)、linkedlist(链表)</p>\r\n	</li>\r\n	<li>\r\n	<p>应用场景: 消息队列，文章列表,</p>\r\n	</li>\r\n</ul>\r\n\r\n<p><strong>Set(集合)</strong></p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>简介:集合(set)类型也是用来保存多个的字符串元素，但是不允许重复元素</p>\r\n	</li>\r\n	<li>\r\n	<p>简单使用举例:sadd key element [element ...]、smembers key</p>\r\n	</li>\r\n	<li>\r\n	<p>内部编码:intset(整数集合)、hashtable(哈希表)</p>\r\n	</li>\r\n	<li>\r\n	<p>注意点:smembers 和 lrange、hgetall 都属于比较重的命令，如果元素过多存</p>\r\n	</li>\r\n	<li>\r\n	<p>在阻塞 Redis 的可能性，可以使用 sscan 来完成。</p>\r\n	</li>\r\n	<li>\r\n	<p>应用场景: 用户标签,生成随机数抽奖、社交需求。</p>\r\n	</li>\r\n</ul>\r\n\r\n<p><strong>zSet(有序集合)</strong></p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>简介:已排序的字符串集合，同时元素不能重复</p>\r\n	</li>\r\n	<li>\r\n	<p>简单格式举例:zadd key score member [score member ...]，zrank key member</p>\r\n	</li>\r\n	<li>\r\n	<p>底层内部编码:ziplist(压缩列表)、skiplist(跳跃表)</p>\r\n	</li>\r\n	<li>\r\n	<p>应用场景:排行榜，社交需求(如用户点赞)。</p>\r\n	</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-07-14 20:24:08', '2022-07-14 20:24:08', 0, 'Redis');
INSERT INTO `blog` VALUES (42, 1, '01', 1, '二、 什么是缓存击穿、缓存穿透、缓存雪崩?', '<p><strong>&nbsp;什么是缓存击穿、缓存穿透、缓存雪崩?</strong></p>\r\n\r\n<p><strong>缓存穿透</strong></p>\r\n\r\n<p>常见的缓存使用方式:读请求来了，先查下缓存，缓存有值命中，就直接返回;缓存没命中，就去查数据库，然后把数据库的值更新到缓存，再返回。</p>\r\n\r\n<p>缓存穿透:指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到 数据库去查询，进而给数据库带来压力。</p>\r\n\r\n<pre>\r\n通俗点说，读请求访问时，缓存和数据库都没有某个值，这样就会导致每次对这个值的查询请求都会穿透到数据库，这就是缓存穿透。\r\n</pre>\r\n\r\n<pre>\r\n缓存穿透一般都是这几种情况产生的:\r\n</pre>\r\n\r\n<ul>\r\n	<li>\r\n	<p>业务不合理的设计，比如大多数用户都没开守护，但是你的每个请求都去缓存，查 询某个 userid 查询有没有守护。</p>\r\n	</li>\r\n	<li>\r\n	<p>业务/运维/开发失误的操作，比如缓存和数据库的数据都被误删除了。</p>\r\n	</li>\r\n	<li>\r\n	<p>黑客非法请求攻击，比如黑客故意捏造大量非法请求，以读取不存在的业务数据。</p>\r\n	</li>\r\n</ul>\r\n\r\n<p>如何避免缓存穿透呢? 一般有三种方法。</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>1.如果是非法请求，我们在 API 入口，对参数进行校验，过滤非法值。</p>\r\n	</li>\r\n	<li>\r\n	<p>2.如果查询数据库为空，我们可以给缓存设置个空值，或者默认值。但是如有有写 请求进来的话，需要更新缓存哈，以保证缓存一致性，同时，最后给缓存设置适当的过期时间。(业务上比较常用，简单有效)</p>\r\n	</li>\r\n	<li>\r\n	<p>3.使用布隆过滤器快速判断数据是否存在。即一个查询请求过来时，先通过布隆过 滤器判断值是否存在，存在才继续往下查。</p>\r\n	</li>\r\n</ul>\r\n\r\n<p><strong>缓存雪崩</strong></p>\r\n\r\n<p>缓存雪崩: 指缓存中数据大批量到过期时间，而查询数据量巨大，请求都直接访问数据库，引起数据库压力过大甚至 down 机。</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>缓存雪奔一般是由于大量数据同时过期造成的，对于这个原因，可通过均匀设置过 期时间解决，即让过期时间相对离散一点。如采用一个较大固定值+一个较小的随 机值，5 小时+0 到 1800 秒酱紫。</p>\r\n	</li>\r\n	<li>\r\n	<p>Redis 故障宕机也可能引起缓存雪奔。这就需要构造 Redis 高可用集群啦。</p>\r\n	</li>\r\n</ul>\r\n\r\n<p><strong>缓存击穿问题</strong></p>\r\n\r\n<p>缓存击穿: 指热点 key 在某个时间点过期的时候，而恰好在这个时间点对这个 Key 有大量的并发请求过来，从而大量的请求打到 db。缓存击穿看着有点像，其实它两区别是，缓存雪奔是指数据库压力过大甚至 down 机，缓存击穿只是大量并发请求到了 DB 数据库层面。可以认为击穿是 缓存雪奔的一个子集吧。有些文章认为它俩区别，是区别在于击穿针对某一热 点 key 缓存，雪奔则是很多 key。</p>\r\n\r\n<p>解决方案就有两种:</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>1.使用互斥锁方案。缓存失效时，不是立即去加载 db 数据，而是先使用某些带成 功返回的原子操作命令，如(Redis 的 setnx)去操作，成功的时候，再去加载 db 数据库数据和设置缓存。否则就去重试获取缓存。</p>\r\n	</li>\r\n	<li>\r\n	<p>2. &ldquo;永不过期&rdquo;，是指没有设置过期时间，但是热点数据快要过期时，异步线程去 更新和设置过期时间。</p>\r\n	</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-07-16 21:24:45', '2022-07-16 21:24:45', 0, 'Redis');
INSERT INTO `blog` VALUES (43, 1, '01', 1, '三、什么是热 Key 问题，如何解决热 key 问题', '<p><strong>什么是热 Key 问题，如何解决热 key 问题</strong></p>\r\n\r\n<p>什么是热 Key ?在 Redis 中，我们把访问频率高的 key，称为热点 key。 如果某一热点 key 的请求到服务器主机时，由于请求量特别大，可能会导致主 机资源不足，甚至宕机，从而影响正常的服务。</p>\r\n\r\n<p>热点 Key 是怎么产生的呢?主要原因有两个：</p>\r\n\r\n<ul>\r\n	<li>用户消费的数据远大于生产的数据，如秒杀、热点新闻等读多写少的场景。</li>\r\n	<li>请求分片集中，超过单 Redi 服务器的性能，比如固定名称 key，Hash 落入同一台服务器，瞬间访问量极大，超过机器瓶颈，产生热点 Key 问题。</li>\r\n</ul>\r\n\r\n<p>如何识别到热点 key ?</p>\r\n\r\n<ul>\r\n	<li>凭经验判断哪些是热 Key; </li>\r\n	<li>客户端统计上报;</li>\r\n	<li>服务代理层上报</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-07-18 22:25:19', '2022-07-18 22:25:19', 0, 'Redis');
INSERT INTO `blog` VALUES (44, 1, '01', 1, '四、Redis 过期策略和内存淘汰策略', '<p><strong>&nbsp;Redis 过期策略和内存淘汰策略</strong></p>\r\n\r\n<p><strong>Redis 的过期策略</strong></p>\r\n\r\n<p>我们在 set key 的时候，可以给它设置一个过期时间，比如 expire key 60。指 定这 key60s 后过期，60s 后，redis 是如何处理的嘛?我们先来介绍几种过 期策略:<br />\r\n<strong>定时过期</strong></p>\r\n\r\n<p>每个设置过期时间的 key 都需要创建一个定时器，到过期时间就会立即对 key 进行清除。该策略可以立即清除过期的数据，对内存很友好;但是会占用大量 的 CPU 资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。</p>\r\n\r\n<p><strong>惰性过期</strong></p>\r\n\r\n<p>只有当访问一个 key 时，才会判断该 key 是否已过期，过期则清除。该策略可以最大化地节省 CPU 资源，却对内存非常不友好。极端情况可能出现大量的过 期 key 没有再次被访问，从而不会被清除，占用大量内存。</p>\r\n\r\n<p><strong>定期过期</strong></p>\r\n\r\n<p>每隔一定的时间，会扫描一定数量的数据库的 expires 字典中一定数量的 key，并清除其中已过期的 key。该策略是前两者的一个折中方案。通过调整 定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得 CPU 和内 存资源达到最优的平衡效果。</p>\r\n\r\n<p>expires 字典会保存所有设置了过期时间的 key 的过期时间数据，其中，key 是指向键空间中的某个键的指针，value 是该键的毫秒精度的 UNIX 时间戳表 示的过期时间。键空间是指该 Redis 集群中保存的所有键。</p>\r\n\r\n<p>Redis 中同时使用了惰性过期和定期过期两种过期策略。</p>\r\n\r\n<ul>\r\n	<li>假设 Redis 当前存放 30 万个 key，并且都设置了过期时间，如果你每隔 100ms 就去检查这全部的 key，CPU 负载会特别高，最后可能会挂掉。</li>\r\n	<li>\r\n	<p>因此，Redis 采取的是定期过期，每隔 100ms 就随机抽取一定数量的 key 来检查和删除的。</p>\r\n	</li>\r\n	<li>\r\n	<p>但是呢，最后可能会有很多已经过期的 key 没被删除。这时候，redis 采用惰性删 除。在你获取某个 key 的时候，redis 会检查一下，这个 key 如果设置了过期时间 并且已经过期了，此时就会删除。</p>\r\n	</li>\r\n</ul>\r\n\r\n<p>如果定期删除漏掉了很多过期的 key，然后也没走惰性删除。就会有 很多过期 key 积在内存内存，直接会导致内存爆的。或者有些时候，业务量大 起来了，redis 的 key 被大量使用，内存直接不够了，运维小哥哥也忘记加大 内存了。难道 redis 直接这样挂掉?不会的!Redis 用 8 种内存淘汰策略保护 自己~</p>\r\n\r\n<p><strong>Redis 内存淘汰策略</strong></p>\r\n\r\n<pre>\r\n<code class=\"language-html\">volatile-lru:当内存不足以容纳新写入数据时，从设置了过期时间的 key 中 使用 LRU(最近最少使用)算法进行淘汰;\r\nallkeys-lru:当内存不足以容纳新写入数据时，从所有 key 中使用 LRU(最近 最少使用)算法进行淘汰。\r\nvolatile-lfu:4.0 版本新增，当内存不足以容纳新写入数据时，在过期的 key 中，使用 LFU 算法进行删除 key。\r\nallkeys-lfu:4.0 版本新增，当内存不足以容纳新写入数据时，从所有 key 中 使用 LFU 算法进行淘汰;\r\nvolatile-random:当内存不足以容纳新写入数据时，从设置了过期时间的 key 中，随机淘汰数据;。\r\nallkeys-random:当内存不足以容纳新写入数据时，从所有 key 中随机淘汰 数据。\r\nvolatile-ttl:当内存不足以容纳新写入数据时，在设置了过期时间的 key 中， 根据过期时间进行淘汰，越早过期的优先被淘汰;\r\nnoeviction:默认策略，当内存不足以容纳新写入数据时，新写入操作会报错</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-23 21:25:48', '2022-07-23 21:25:48', 0, 'Redis');
INSERT INTO `blog` VALUES (45, 1, '01', 1, '五、Redis 16 个常见使用场景', '<ul>\r\n	<li>\r\n	<p><a href=\"#a1\">缓存</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a2\">数据共享分布式</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a3\">分布式锁</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a4\">全局ID</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a5\">计数器</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a6\">限流</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a7\">位统计</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a8\">购物车</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a9\">用户消息时间线timeline</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a10\">消息队列</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a11\">抽奖</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a12\">点赞、签到、打卡</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a13\">商品标签</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a14\">商品筛选</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a15\">用户关注、推荐模型</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"#a16\">排行榜</a></p>\r\n	</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h3><a id=\"a1\" name=\"a1\">1、缓存</a></h3>\r\n\r\n<p>String类型</p>\r\n\r\n<p>例如：热点数据缓存（例如报表、明星出轨），对象缓存、全页缓存、可以提升热点数据的访问数据。</p>\r\n\r\n<h3><a id=\"a2\" name=\"a2\">2、数据共享分布式</a></h3>\r\n\r\n<p>String 类型，因为 Redis 是分布式的独立服务，可以在多个应用之间共享</p>\r\n\r\n<p>例如：分布式Session</p>\r\n\r\n<pre>\r\n<code>&lt;dependency&gt; \r\n &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; \r\n &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt; \r\n&lt;/dependency&gt;</code></pre>\r\n\r\n<h3><a id=\"a3\" name=\"a3\">3、分布式锁</a></h3>\r\n\r\n<p>String 类型setnx方法，只有不存在时才能添加成功，返回true</p>\r\n\r\n<pre>\r\n<code>public static boolean getLock(String key) {\r\n    Long flag = jedis.setnx(key, \"1\");\r\n    if (flag == 1) {\r\n        jedis.expire(key, 10);\r\n    }\r\n    return flag == 1;\r\n}\r\n\r\npublic static void releaseLock(String key) {\r\n    jedis.del(key);\r\n}</code></pre>\r\n\r\n<h3><a id=\"a4\" name=\"a4\">4、全局ID</a></h3>\r\n\r\n<p>int类型，incrby，利用原子性</p>\r\n\r\n<p>incrby userid 1000</p>\r\n\r\n<p>分库分表的场景，一次性拿一段</p>\r\n\r\n<h3><a id=\"a5\" name=\"a5\">5、计数器</a></h3>\r\n\r\n<p>int类型，incr方法</p>\r\n\r\n<p>例如：文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库</p>\r\n\r\n<h3><a id=\"a6\" name=\"a6\">6、限流</a></h3>\r\n\r\n<p>int类型，incr方法</p>\r\n\r\n<p>以访问者的ip和其他信息作为key，访问一次增加一次计数，超过次数则返回false</p>\r\n\r\n<h3><a id=\"a7\" name=\"a7\">7、位统计</a></h3>\r\n\r\n<p>String类型的bitcount（1.6.6的bitmap数据结构介绍）</p>\r\n\r\n<p>字符是以8位二进制存储的</p>\r\n\r\n<pre>\r\n<code>set k1 a\r\nsetbit k1 6 1\r\nsetbit k1 7 0\r\nget k1 \r\n/* 6 7 代表的a的二进制位的修改\r\na 对应的ASCII码是97，转换为二进制数据是01100001\r\nb 对应的ASCII码是98，转换为二进制数据是01100010\r\n\r\n因为bit非常节省空间（1 MB=8388608 bit），可以用来做大数据量的统计。\r\n*/</code></pre>\r\n\r\n<p>例如：在线用户统计，留存用户统计</p>\r\n\r\n<pre>\r\n<code>setbit onlineusers 01 \r\nsetbit onlineusers 11 \r\nsetbit onlineusers 20</code></pre>\r\n\r\n<p>支持按位与、按位或等等操作</p>\r\n\r\n<pre>\r\n<code>BITOPANDdestkeykey[key...] ，对一个或多个 key 求逻辑并，并将结果保存到 destkey 。       \r\nBITOPORdestkeykey[key...] ，对一个或多个 key 求逻辑或，并将结果保存到 destkey 。 \r\nBITOPXORdestkeykey[key...] ，对一个或多个 key 求逻辑异或，并将结果保存到 destkey 。 \r\nBITOPNOTdestkeykey ，对给定 key 求逻辑非，并将结果保存到 destkey 。\r\n</code></pre>\r\n\r\n<p>计算出7天都在线的用户</p>\r\n\r\n<pre>\r\n<code>BITOP \"AND\" \"7_days_both_online_users\" \"day_1_online_users\" \"day_2_online_users\" ...  \"day_7_online_users\"\r\n</code></pre>\r\n\r\n<h3><a id=\"a8\" name=\"a8\">8、购物车</a></h3>\r\n\r\n<p>String 或hash。所有String可以做的hash都可以做</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>key：用户id；field：商品id；value：商品数量。</p>\r\n	</li>\r\n	<li>\r\n	<p>+1：hincr。-1：hdecr。删除：hdel。全选：hgetall。商品数：hlen。</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3><a id=\"a9\" name=\"a9\">9、用户消息时间线timeline</a></h3>\r\n\r\n<p>list，双向链表，直接作为timeline就好了。插入有序</p>\r\n\r\n<h3><a id=\"a10\" name=\"a10\">10、消息队列</a></h3>\r\n\r\n<p>List提供了两个阻塞的弹出操作：blpop/brpop，可以设置超时时间</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>blpop：blpop key1 timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</p>\r\n	</li>\r\n	<li>\r\n	<p>brpop：brpop key1 timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。</p>\r\n	</li>\r\n</ul>\r\n\r\n<p>上面的操作。其实就是java的阻塞队列。学习的东西越多。学习成本越低</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>队列：先进先除：rpush blpop，左头右尾，右边进入队列，左边出队列</p>\r\n	</li>\r\n	<li>\r\n	<p>栈：先进后出：rpush brpop</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3><a id=\"a11\" name=\"a11\">11、抽奖</a></h3>\r\n\r\n<p>自带一个随机获得值</p>\r\n\r\n<pre>\r\n<code>spop myset</code></pre>\r\n\r\n<h3><a id=\"a12\" name=\"a12\">12、点赞、签到、打卡</a></h3>\r\n\r\n<p>假如上面的微博ID是t1001，用户ID是u3001</p>\r\n\r\n<p>用 like:t1001 来维护 t1001 这条微博的所有点赞用户</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>点赞了这条微博：sadd like:t1001 u3001</p>\r\n	</li>\r\n	<li>\r\n	<p>取消点赞：srem like:t1001 u3001</p>\r\n	</li>\r\n	<li>\r\n	<p>是否点赞：sismember like:t1001 u3001</p>\r\n	</li>\r\n	<li>\r\n	<p>点赞的所有用户：smembers like:t1001</p>\r\n	</li>\r\n	<li>\r\n	<p>点赞数：scard like:t1001</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3><a id=\"a13\" name=\"a13\">13、商品标签</a></h3>\r\n\r\n<p>用 tags:i5001 来维护商品所有的标签。</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>sadd tags:i5001 画面清晰细腻</p>\r\n	</li>\r\n	<li>\r\n	<p>sadd tags:i5001 真彩清晰显示屏</p>\r\n	</li>\r\n	<li>\r\n	<p>sadd tags:i5001 流程至极</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3><a id=\"a14\" name=\"a14\">14、商品筛选</a></h3>\r\n\r\n<pre>\r\n<code>// 获取差集\r\nsdiff set1 set2\r\n// 获取交集（intersection ）\r\nsinter set1 set2\r\n// 获取并集\r\nsunion set1 set2</code></pre>\r\n\r\n<h3><a id=\"a15\" name=\"a15\">15、用户关注、推荐模型</a></h3>\r\n\r\n<p>follow 关注 fans 粉丝</p>\r\n\r\n<p>相互关注：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>sadd 1:follow 2</p>\r\n	</li>\r\n	<li>\r\n	<p>sadd 2:fans 1</p>\r\n	</li>\r\n	<li>\r\n	<p>sadd 1:fans 2</p>\r\n	</li>\r\n	<li>\r\n	<p>sadd 2:follow 1</p>\r\n	</li>\r\n</ul>\r\n\r\n<p>我关注的人也关注了他(取交集)：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>sinter 1:follow 2:fans</p>\r\n	</li>\r\n</ul>\r\n\r\n<p>可能认识的人：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>用户1可能认识的人(差集)：sdiff 2:follow 1:follow</p>\r\n	</li>\r\n	<li>\r\n	<p>用户2可能认识的人：sdiff 1:follow 2:follow</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3><a id=\"a16\" name=\"a16\">16、排行榜</a></h3>\r\n\r\n<p>id 为6001 的新闻点击数加1：</p>\r\n\r\n<pre>\r\n<code>zincrby hotNews:20190926 1 n6001</code></pre>\r\n\r\n<p>获取今天点击最多的15条：</p>\r\n\r\n<pre>\r\n<code>zrevrange hotNews:20190926 0 15 withscores</code></pre>\r\n', '', NULL, NULL, 0, '2022-07-29 20:36:25', '2022-07-29 20:36:25', 0, 'Redis');
INSERT INTO `blog` VALUES (46, 0, '01', 1, '索引有哪几种类型、分类、不适合哪些场景、规则', '<p>&nbsp;</p>\r\n\r\n<ul>\r\n	<li>&nbsp;</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<ul>\r\n	<li>&nbsp;</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<ul>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-08-26 15:46:08', '2022-08-26 16:03:32', 1, NULL);
INSERT INTO `blog` VALUES (47, 0, '01', 1, '索引哪些情况会失效', '<p><strong>索引哪些情况会失效</strong></p>\r\n\r\n<ul>\r\n	<li>如果字段类型是字符串，where时一定要用引号括起来，否则失效</li>\r\n	<li>联合索引，查询时的条件列不是联合索引中的第一列，失效</li>\r\n	<li>在索引列上使用mysql的内置函数，索引失效</li>\r\n	<li>查询条件包含or，可能导致索引失效</li>\r\n	<li>like通配符可能导致索引失效</li>\r\n	<li>对索引列进行运算，失效</li>\r\n	<li>索引字段使用（!= 或者 &lt; &gt;，not in)时，可能会导致索引失效。</li>\r\n	<li>索引字段上使用 is null， is not null，可能导致索引失效。</li>\r\n	<li>左连接查询或者右连接查询 查询关联的字段编码格式不一样，可能导致索引失效</li>\r\n	<li>mysql 估计使用全表扫描要比使用索引快,则不使用索引。</li>\r\n</ul>\r\n\r\n<p><strong>如何写 sql 能够有效的使用到复合索引</strong></p>\r\n\r\n<p>复合索引，也叫联合索引，用户可以在多个列上建立索引,这种索引叫做复合索 引。 当我们创建一个组合索引的时候，如(k1,k2,k3)，相当于创建了(k1)、 (k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。</p>\r\n\r\n<pre>\r\n<code>select * from table where k1=A AND k2=B AND k3=D</code></pre>\r\n\r\n<p>有关于复合索引，我们需要关注查询 Sql 条件的顺序，确保最左匹配原则有效，同时可以删除不必要的冗余索引</p>\r\n', '', NULL, NULL, 0, '2022-08-26 15:46:53', '2022-08-26 15:52:48', 1, NULL);
INSERT INTO `blog` VALUES (48, 0, '01', 1, '索引不适合哪些场景、规则', '<p><strong>索引不适合哪些场景</strong></p>\r\n\r\n<ul>\r\n	<li>数据量少的不适合加索引</li>\r\n	<li>更新比较频繁的也不适合加索引</li>\r\n	<li>区分度低的字段不适合加索引</li>\r\n</ul>\r\n\r\n<p><strong>索引的一些潜规则</strong></p>\r\n\r\n<ul>\r\n	<li>覆盖索引</li>\r\n	<li>回表</li>\r\n	<li>索引数据结构(B+树) </li>\r\n	<li>最左前缀原则</li>\r\n	<li>索引下推</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-08-26 15:48:03', '2022-08-26 15:50:20', 1, NULL);
INSERT INTO `blog` VALUES (49, 1, '01', 1, '索引优缺点、创建索引原则', '<p><a href=\"#a1\"><strong>索引有哪些优缺点</strong></a></p>\r\n\r\n<p><a href=\"#a2\"><strong>创建索引有什么原则呢?</strong></a></p>\r\n\r\n<hr />\r\n<p>&nbsp;</p>\r\n\r\n<p><a name=\"a1\"><strong>索引有哪些优缺点</strong></a></p>\r\n\r\n<p>优点：</p>\r\n\r\n<ul>\r\n	<li>唯一索引可以保证数据库表中每一行的数据的唯一性</li>\r\n	<li>索引可以加快数据查询速度，减少查询时间</li>\r\n</ul>\r\n\r\n<p>缺点：</p>\r\n\r\n<ul>\r\n	<li>创建索引和维护索引要耗费时间</li>\r\n	<li>索引需要占物理空间，除了数据表占用数据空间之外，每一个索引还要占用一定的物理空间</li>\r\n	<li>以表中的数据进行增、删、改的时候，索引也要动态的维护。</li>\r\n</ul>\r\n\r\n<p><a name=\"a2\"><strong>创建索引有什么原则呢?</strong></a></p>\r\n\r\n<ul>\r\n	<li>最左前缀匹配原则</li>\r\n	<li>频繁作为查询条件的字段才去创建索引</li>\r\n	<li>频繁更新的字段不适合创建索引</li>\r\n	<li>索引列不能参与计算，不能有函数操作</li>\r\n	<li>优先考虑扩展索引，而不是新建索引，避免不必要的索引</li>\r\n	<li>在 order by 或者 group by 子句中，创建索引需要注意顺序</li>\r\n	<li>区分度低的数据列不适合做索引列(如性别)</li>\r\n	<li>定义有外键的数据列一定要建立索引。</li>\r\n	<li>对于定义为 text、image 数据类型的列不要建立索引。</li>\r\n	<li>删除不再使用或者很少使用的索引</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-07-26 22:06:50', '2022-08-26 16:18:57', 0, '数据库');
INSERT INTO `blog` VALUES (50, 1, '01', 1, '索引类型、分类、原则、场景', '<p><span style=\"font-size:16px\"><strong><a href=\"#type\"><span style=\"background-color:#ecf0f1\">索引类型</span></a></strong></span></p>\r\n\r\n<p><span style=\"font-size:16px\"><strong><a href=\"#sort\"><span style=\"background-color:#ecf0f1\">索引分类?</span></a></strong></span></p>\r\n\r\n<p><a href=\"#b1\"><span style=\"font-size:16px\"><strong><span style=\"background-color:#ecf0f1\">数据库索引的原理，为什么要用 B+树，为什么不用二叉 树?</span></strong></span></a></p>\r\n\r\n<p><span style=\"font-size:16px\"><a href=\"#a2\"><strong><span style=\"background-color:#ecf0f1\">索引不适合哪些场景</span></strong></a></span></p>\r\n\r\n<p><span style=\"font-size:16px\"><a href=\"#a3\"><strong><span style=\"background-color:#ecf0f1\">索引的一些潜规则</span></strong></a></span></p>\r\n\r\n<hr />\r\n<p>&nbsp;</p>\r\n\r\n<p><strong><a id=\"type\" name=\"type\">索引有哪几种类型?</a></strong></p>\r\n\r\n<ul>\r\n	<li>主键索引: 数据列不允许重复，不允许为 NULL，一个表只能有一个主键。</li>\r\n	<li>唯一索引: 数据列不允许重复，允许为 NULL 值，一个表允许多个列创建唯一索引。</li>\r\n	<li>普通索引: 基本的索引类型，没有唯一性的限制，允许为 NULL 值。</li>\r\n	<li>全文索引:是目前搜索引擎使用的一种关键技术，对文本的内容进行分词、搜索。</li>\r\n	<li>覆盖索引:查询列要被所建的索引覆盖，不必读取数据行</li>\r\n	<li>组合索引:多列值组成一个索引，用于组合搜索，效率大于索引合并</li>\r\n</ul>\r\n\r\n<p><strong><a id=\"sort\" name=\"sort\">索引分类?</a></strong></p>\r\n\r\n<p><strong>Hash 索引和 B+树</strong></p>\r\n\r\n<ul>\r\n	<li>B+树可以进行范围查询，Hash 索引不能。</li>\r\n	<li>B+树支持联合索引的最左侧原则，Hash 索引不支持。</li>\r\n	<li>B+树支持 order by 排序，Hash 索引不支持。</li>\r\n	<li>Hash 索引在等值查询上比 B+树效率更高。</li>\r\n	<li>B+树使用 like 进行模糊查询的时候，like 后面(比如%开头)的话可以起到优化的作用，Hash索引根本无法进行模糊查询。</li>\r\n</ul>\r\n\r\n<p><a id=\"b1\" name=\"b1\"><strong>数据库索引的原理，为什么要用 B+树，为什么不用二叉 树?</strong></a></p>\r\n\r\n<p>查询是否够快，效率是否稳定，存储数据多少， 以及查找磁盘次数，<br />\r\n为什么不是二叉树，为什么不是平衡二叉树，为什么不是B 树，而偏偏是 B+树呢?</p>\r\n\r\n<p style=\"margin-left:40px\">为什么不是一般二叉树?<br />\r\n&nbsp; &nbsp; &nbsp; 如果二叉树特殊化为一个链表，相当于全表扫描。平衡二叉树相比于二叉查找 树来说，查找效率更稳定，总体的查找速度也更快。</p>\r\n\r\n<p style=\"margin-left:40px\">为什么不是平衡二叉树呢?<br />\r\n&nbsp; &nbsp; &nbsp; 在内存比在磁盘的数据，查询效率快得多。如果树这种数据结构作 为索引，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说 的一个磁盘块，但是平衡二叉树可是每个节点只存储一个键值和数据的，如果是 B 树，可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数 就降下来啦，查询效率就快啦。</p>\r\n\r\n<p style=\"margin-left:40px\">那为什么不是 B 树而是 B+树呢?</p>\r\n\r\n<ul>\r\n	<li style=\"margin-left: 40px;\">B+树非叶子节点上是不存储数据的，仅存储键值，而 B 树节点中不仅存储 键值，也会存储数据。innodb 中页的默认大小是 16KB，如果不存储数据，那 么就会存储更多的键值，相应的树的阶数(节点的子节点树)就会更大，树就 会更矮更胖，如此一来我们查找数据进行磁盘的 IO 次数有会再次减少，数据查 询的效率也会更快。</li>\r\n	<li style=\"margin-left: 40px;\">B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链 表连着的。那么 B+树使得范围查找，排序查找，分组查找以及去重查找变得 异常简单。</li>\r\n</ul>\r\n\r\n<p><strong><a id=\"a2\" name=\"a2\">索引不适合哪些场景</a></strong></p>\r\n\r\n<ul>\r\n	<li>数据量少的不适合加索引</li>\r\n	<li>更新比较频繁的也不适合加索引</li>\r\n	<li>区分度低的字段不适合加索引</li>\r\n</ul>\r\n\r\n<p><strong><a id=\"a3\" name=\"a3\">索引的一些潜规则</a></strong></p>\r\n\r\n<ul>\r\n	<li>覆盖索引</li>\r\n	<li>回表</li>\r\n	<li>索引数据结构(B+树)</li>\r\n	<li>最左前缀原则</li>\r\n	<li>索引下推</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-26 21:06:50', '2022-08-26 16:55:38', 0, '数据库');
INSERT INTO `blog` VALUES (51, 1, '01', 1, '索引哪些情况会失效', '<p><strong><a href=\"#a1\">索引哪些情况会失效</a></strong></p>\r\n\r\n<p><strong><a href=\"#a5\">如何写 sql 能够有效的使用到复合索引</a></strong></p>\r\n\r\n<p><a href=\"#a3\"><strong>什么是最左前缀原则?什么是最左匹配原则?</strong></a></p>\r\n\r\n<hr />\r\n<p>&nbsp;</p>\r\n\r\n<p><strong><a id=\"a1\" name=\"a1\">索引哪些情况会失效</a></strong></p>\r\n\r\n<ul>\r\n	<li>查询条件包含 or，可能导致索引失效</li>\r\n	<li>如何字段类型是字符串，where 时一定用引号括起来，否则索引失效</li>\r\n	<li>like 通配符可能导致索引失效。</li>\r\n	<li>联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。</li>\r\n	<li>在索引列上使用 mysql 的内置函数，索引失效。</li>\r\n	<li>对索引列运算(如，+、-、*、/)，索引失效。</li>\r\n	<li>索引字段上使用(!= 或者 &lt; &gt;，not in)时，可能会导致索引失效。</li>\r\n	<li>索引字段上使用 is null， is not null，可能导致索引失效。</li>\r\n	<li>左连接查询或者右连接查询查询关联的字段编码格式不一样，可能导致索引失效。</li>\r\n	<li>mysql 估计使用全表扫描要比使用索引快,则不使用索引。</li>\r\n</ul>\r\n\r\n<p><a id=\"a5\" name=\"a5\"><strong>如何写 sql 能够有效的使用到复合索引</strong></a></p>\r\n\r\n<p>复合索引，也叫联合索引，用户可以在多个列上建立索引,这种索引叫做复合索 引。 当我们创建一个组合索引的时候，如(k1,k2,k3)，相当于创建了(k1)、 (k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。</p>\r\n\r\n<pre>\r\n<code>select * from table where k1=A AND k2=B AND k3=D</code></pre>\r\n\r\n<p>有关于复合索引，我们需要关注查询 Sql 条件的顺序，确保最左匹配原则有效，同时可以删除不必要的冗余索引</p>\r\n\r\n<p><a id=\"a3\" name=\"a3\"><strong>什么是最左前缀原则?什么是最左匹配原则?</strong></a></p>\r\n\r\n<ul>\r\n	<li>&nbsp;最左前缀原则，就是最左优先，在创建多列索引时，要根据业务需求，where 子句中使用最频繁的一列放在最左边。</li>\r\n	<li>&nbsp;当我们创建一个组合索引的时候，如(k1,k2,k3)，相当于创建了(k1)、 (k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。。</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-07-26 20:06:50', '2022-08-26 16:19:43', 0, '数据库');
INSERT INTO `blog` VALUES (52, 1, '01', 1, '百万级别或以上的数据，如何删除?', '<p><strong>百万级别或以上的数据，你是如何删除的?</strong></p>\r\n\r\n<p>我们想要删除百万数据的时候</p>\r\n\r\n<ul>\r\n	<li>可以先删除索引</li>\r\n	<li>然后批量删除其中无用数据</li>\r\n	<li>删除完成后重新创建索引。</li>\r\n</ul>\r\n\r\n<p><strong>如果某个表有近千万数据，CRUD 比较慢，如何优化</strong></p>\r\n\r\n<p>分库分表</p>\r\n\r\n<pre>\r\n某个表有近千万数据，可以考虑优化表结构，分表(水平分表，垂直分表)，\r\n当然，你这样回答，需要准备好面试官问你的分库分表相关问题呀，如\r\n</pre>\r\n\r\n<ul>\r\n	<li>分表方案(水平分表，垂直分表，切分规则 hash 等)</li>\r\n	<li>分库分表中间件(Mycat，sharding-jdbc 等)</li>\r\n	<li>分库分表一些问题(事务问题?跨节点 Join 的问题)</li>\r\n	<li>解决方案(分布式事务等)</li>\r\n</ul>\r\n\r\n<p>索引优化</p>\r\n\r\n<p style=\"margin-left:40px\">除了分库分表，优化表结构，还有索引优化</p>\r\n\r\n<table>\r\n	<tbody>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/54\" target=\"_blank\">优化 SQL</a></td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n', '', NULL, NULL, 0, '2022-08-26 22:16:50', '2022-08-26 17:30:26', 0, '数据库');
INSERT INTO `blog` VALUES (53, 1, '01', 1, 'MySQL死锁如何解决', '<ul>\r\n	<li>查看死锁日志 show engine innodb status;</li>\r\n	<li>找出死锁 Sql</li>\r\n	<li>分析 sql 加锁情况</li>\r\n	<li>模拟死锁案发</li>\r\n	<li>分析死锁日志</li>\r\n	<li>分析死锁结果</li>\r\n</ul>\r\n\r\n<pre>\r\n<code>https://mp.weixin.qq.com/s?__biz=Mzg3NzU5NTIwNg==&amp;amp;mid=2247499275&amp;amp;idx=1&amp;amp;sn=ca72f48a290e4fd2a2ded6ef6fd045be&amp;amp;chksm=cf222122f855a8347b911352cebdd722b17ea45733b91ff169353c0805d9f31cea5261ef01b9&amp;amp;token=1712314640&amp;amp;lang=zh_CN#rd</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-16 22:16:50', '2022-08-26 16:37:47', 0, '数据库');
INSERT INTO `blog` VALUES (54, 1, '01', 1, '优化SQL ', '<p>步骤</p>\r\n\r\n<ul>\r\n	<li>show status 命令了解各种 sql 的执行频率</li>\r\n	<li>通过慢查询日志定位那些执行效率较低的 sql 语句</li>\r\n	<li>explain 分析低效 sql 的执行计划(这点非常重要，日常开发中用它分析 Sql，会大大降低 Sql 导致的线上事故)</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<hr />\r\n<ul>\r\n	<li>加索引</li>\r\n	<li>避免返回不必要的数据</li>\r\n	<li>适当分批量进行</li>\r\n	<li>优化 sql 结构</li>\r\n	<li>分库分表</li>\r\n	<li>读写分离</li>\r\n</ul>\r\n\r\n<h3>1、查询SQL尽量不要使用select *，而是select具体字段。</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>只取需要的字段，节省资源、减少网络开销。</li>\r\n	<li>select * 进行查询时，很可能就不会使用到覆盖索引了，就会造成回表查询。</li>\r\n</ul>\r\n\r\n<h3>2、如果知道查询结果只有一条或者只要最大/最小一条记录，建议用limit 1</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>加上limit 1后,只要找到了对应的一条记录,就不会继续向下扫描了,效率将会大大提高。</li>\r\n	<li>当然，如果name是唯一索引的话，是不必要加上limit 1了，因为limit的存在主要就是为了防止全表扫描，从而提高性能,如果一个语句本身可以预知不用全表扫描，有没有limit ，性能的差别并不大</li>\r\n</ul>\r\n\r\n<h3>3、应尽量避免在where子句中使用or来连接条件</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>使用or可能会使索引失效，从而全表扫描。</p>\r\n\r\n	<pre>\r\n<code>对于or+没有索引的age这种情况，假设它走了userId的索引，但是走到age查询条件时，它还得全表扫描，也就是需要三步过程：全表扫描+索引扫描+合并\r\n如果它一开始就走全表扫描，直接一遍扫描就完事。mysql是有优化器的，处于效率与成本考虑，遇到or条件，索引可能失效，看起来也合情合理。</code></pre>\r\n	</li>\r\n</ul>\r\n\r\n<h3>4、优化limit分页</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>当偏移量最大的时候，查询效率就会越低，因为Mysql并非是跳过偏移量直接去取后面的数据，而是先把偏移量+要取的条数，然后再把前面偏移量这一段的数据抛弃掉再返回的。</li>\r\n	<li>如果使用优化方案一，返回上次最大查询记录（偏移量），这样可以跳过偏移量，效率提升不少。</li>\r\n	<li>方案二使用order by+索引，也是可以提高查询效率的。</li>\r\n	<li>方案三的话，建议跟业务讨论，有没有必要查这么后的分页啦。因为绝大多数用户都不会往后翻太多页。</li>\r\n</ul>\r\n\r\n<h3>5、优化你的like语句</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>把%放前面，并不走索引</li>\r\n	<li>把% 放关键字后面，还是会走索引的</li>\r\n</ul>\r\n\r\n<h3>6、使用where条件限定要查询的数据，避免返回多余的行</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>需要什么数据，就去查什么数据，避免返回不必要的数据，节省开销。</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3>7、尽量避免在索引列上使用mysql的内置函数</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>索引列上使用mysql的内置函数，索引失效</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3>8、应尽量避免在where子句中对字段进行表达式操作，这将导致系统放弃使用索引而进行全表扫</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>虽然age加了索引，但是因为对它进行运算，索引直接迷路了</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3>9、Inner join 、left join、right join，优先使用Inner join，如果是left join，左边表结果尽量小</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>如果inner join是等值连接，或许返回的行数比较少，所以性能相对会好一点。</li>\r\n	<li>同理，使用了左连接，左边表数据结果尽量小，条件尽量放到左边处理，意味着返回的行数可能比较少。</li>\r\n</ul>\r\n\r\n<h3>10、应尽量避免在where子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>使用!=和&lt;&gt;很可能会让索引失效</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3>11、使用联合索引时，注意索引列的顺序，一般遵循最左匹配原则。</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>当我们创建一个联合索引的时候，如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。</li>\r\n	<li>联合索引不满足最左原则，索引一般会失效，但是这个还跟Mysql优化器有关的。</li>\r\n</ul>\r\n\r\n<h3>12、对查询进行优化，应考虑在where及order by涉及的列上建立索引，尽量避免全表扫描。</h3>\r\n\r\n<h3>13、如果插入数据过多，考虑批量插入。</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>批量插入性能好，更加省时间</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3>14、在适当的时候，使用覆盖索引。</h3>\r\n\r\n<h3>15、慎用distinct关键字</h3>\r\n\r\n<p>distinct 关键字一般用来过滤重复记录，以返回不重复的记录。在查询一个字段或者很少字段的情况下使用时，给查询带来优化效果。但是在字段很多的时候使用，却会大大降低查询效率。</p>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>带distinct的语句cpu时间和占用时间都高于不带distinct的语句。因为当查询很多字段时，如果使用distinct，数据库引擎就会对数据进行比较，过滤掉重复数据，然而这个比较、过滤的过程会占用系统资源，cpu时间。</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3>16、删除冗余和重复索引</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>重复的索引需要维护，并且优化器在优化查询的时候也需要逐个地进行考虑，这会影响性能的。</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3>17、如果数据量较大，优化你的修改/删除语句。</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>一次性删除太多数据，可能会有lock wait timeout exceed的错误，所以建议分批操作。</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3>18、where子句中考虑使用默认值代替null。</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>并不是说使用了is null 或者 is not null 就会不走索引了，这个跟mysql版本以及查询成本都有关。</p>\r\n	</li>\r\n</ul>\r\n\r\n<ul>\r\n	<li>\r\n	<h3>如果把null值，换成默认值，很多时候让走索引成为可能，同时，表达意思会相对清晰一点。</h3>\r\n	</li>\r\n</ul>\r\n\r\n<h3>19、不要有超过5个以上的表连接</h3>\r\n\r\n<ul>\r\n	<li>连表越多，编译的时间和开销也就越大。</li>\r\n	<li>把连接表拆开成较小的几个执行，可读性更高。</li>\r\n	<li>如果一定需要连接很多表才能得到数据，那么意味着糟糕的设计了。</li>\r\n</ul>\r\n\r\n<h3>20、exist&amp;in的合理利用</h3>\r\n\r\n<h3>21、尽量用union all替换 union</h3>\r\n\r\n<h3>22、索引不宜太多，一般5个以内。</h3>\r\n\r\n<ul>\r\n	<li>索引并不是越多越好，索引虽然提高了查询的效率，但是也降低了插入和更新的效率。</li>\r\n	<li>insert或update时有可能会重建索引，所以建索引需要慎重考虑，视具体情况来定。</li>\r\n	<li>一个表的索引数最好不要超过5个，若太多需要考虑一些索引是否没有存在的必要。</li>\r\n</ul>\r\n\r\n<h3>23、尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>相对于数字型字段，字符型会降低查询和连接的性能，并会增加存储开销。</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3>24、索引不适合建在有大量重复数据的字段上，如性别这类型数据库字段。</h3>\r\n\r\n<p>因为SQL优化器是根据表中数据量来进行查询优化的，如果索引列有大量重复数据，Mysql查询优化器推算发现不走索引的成本更低，很可能就放弃索引了。</p>\r\n\r\n<h3>25、尽量避免向客户端返回过多数据量。</h3>\r\n\r\n<h3>26、当在SQL语句中连接多个表时,请使用表的别名，并把别名前缀于每一列上，这样语义更加清晰。</h3>\r\n\r\n<h3>27、尽可能使用varchar/nvarchar 代替 char/nchar。</h3>\r\n\r\n<p>理由：</p>\r\n\r\n<ul>\r\n	<li>因为首先变长字段存储空间小，可以节省存储空间。</li>\r\n	<li>其次对于查询来说，在一个相对较小的字段内搜索，效率更高。</li>\r\n</ul>\r\n\r\n<h3>28、为了提高group by 语句的效率，可以在执行到该语句前，把不需要的记录过滤掉。</h3>\r\n\r\n<h3>29、如果字段类型是字符串，where时一定用引号括起来，否则索引失效</h3>\r\n\r\n<h3>30、使用explain 分析你SQL的计划</h3>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-06-26 16:34:43', '2022-08-26 17:25:59', 0, '数据库');
INSERT INTO `blog` VALUES (55, 0, '01', 1, 'MySQL使用', '<p><strong>概念</strong></p>\r\n\r\n<table>\r\n	<tbody>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/62\" target=\"_blank\">Mysql 中锁</a></td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/57\" target=\"_blank\">MySQL隔离级别</a></td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/56\" target=\"_blank\">分库与分表设计</a></td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/64\" target=\"_blank\">MySQL 的复制原理以及流程</a></td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p><strong>问题</strong></p>\r\n\r\n<p><strong>sql相关</strong></p>\r\n\r\n<table>\r\n	<tbody>\r\n<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/54\" target=\"_blank\">优化 SQL</a></td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/59\" target=\"_blank\">一条 sql 执行过长的时间如何优化</a></td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/58\" target=\"_blank\">select for update 含义</a></td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/38\" target=\"_blank\">MySQL 中 in 和 exists 的区别</a></td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p><strong>数据表/库相关</strong></p>\r\n\r\n<table>\r\n	<tbody>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/52\" target=\"_blank\">百万级别或以上的数据，如何删除?</a></td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/53\" target=\"_blank\">MySQL 死锁如何解决</a></td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/60\" target=\"_blank\">Blob 和 text 有什么区别</a></td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/61\" target=\"_blank\">mysql 里记录货币用什么字段类型比较好</a></td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/63\" target=\"_blank\">MySQL 数据库 cpu 飙升的话，要怎么处理呢</a></td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n', '', NULL, NULL, 0, '2022-06-26 16:35:04', '2022-08-26 18:11:13', 1, '数据库');
INSERT INTO `blog` VALUES (56, 1, '01', 1, '分库与分表设计', '<p>分库分表方案:</p>\r\n\r\n<ul>\r\n	<li>水平分库:以字段为依据，按照一定策略(hash、range 等)，将一个库中的数 据拆分到多个库中。</li>\r\n	<li>水平分表:以字段为依据，按照一定策略(hash、range 等)，将一个表中的数 据拆分到多个表中。</li>\r\n	<li>垂直分库:以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。</li>\r\n	<li>垂直分表:以字段为依据，按照字段的活跃性，将表中字段拆到不同的表(主表和扩展表)中。</li>\r\n</ul>\r\n\r\n<p>常用的分库分表中间件:</p>\r\n\r\n<ul>\r\n	<li>sharding-jdbc(当当)</li>\r\n	<li>Mycat</li>\r\n	<li>TDDL(淘宝)</li>\r\n	<li>Oceanus(58 同城数据库中间件)</li>\r\n	<li>vitess(谷歌开发的数据库中间件)</li>\r\n	<li>Atlas(Qihoo 360)</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>分库分表可能遇到的问题：</p>\r\n\r\n<p>​​</p>\r\n\r\n<ul>\r\n	<li>事务问题:需要用分布式事务啦</li>\r\n	<li>跨节点 Join 的问题:解决这一问题可以分两次查询实现</li>\r\n	<li>跨节点的 count,order by,group by 以及聚合函数问题:分别在各个节点上得到</li>\r\n	<li>&nbsp; &nbsp;结果后在应用程序端进行合并。</li>\r\n	<li>数据迁移，容量规划，扩容等问题</li>\r\n	<li>ID 问题:数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可</li>\r\n	<li>以考虑 UUID</li>\r\n	<li>跨分片的排序分页问题(后台加大 pagesize 处理?)</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-08-20 22:09:50', '2022-08-26 16:48:37', 0, '数据库');
INSERT INTO `blog` VALUES (57, 1, '01', 1, 'MySQL隔离级别', '<p><a href=\"#a1\">什么是事务？</a></p>\r\n\r\n<p><a href=\"#a2\">事务的四大特性</a></p>\r\n\r\n<p><a href=\"#a3\">事务并发存在的问题</a></p>\r\n\r\n<h2><a href=\"#a4\"><span style=\"font-size:14px\">事务的四大隔离级别</span></a></h2>\r\n\r\n<p><a href=\"#b1\">MySql隔离级别的实现原理</a></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h3><a id=\"a1\" name=\"a1\">什么是事务？</a></h3>\r\n\r\n<p>事务，由一个有限的数据库操作序列构成，这些操作要么全部执行,要么全部不执行，是一个不可分割的工作单位。</p>\r\n\r\n<pre>\r\n<code>假如A转账给B 100 元，先从A的账户里扣除 100 元，再在 B 的账户上加上 100 元。如果扣完A的100元后，还没来得及给B加上，银行系统异常了，最后导致A的余额减少了，B的余额却没有增加。所以就需要事务，将A的钱回滚回去</code></pre>\r\n\r\n<h3><a id=\"a2\" name=\"a2\">事务的四大特性</a></h3>\r\n\r\n<ul>\r\n	<li><strong>原子性：</strong>&nbsp;事务作为一个整体被执行，包含在其中的对数据库的操作要么全部都执行，要么都不执行。</li>\r\n	<li><strong>一致性：</strong>&nbsp;指在事务开始之前和事务结束以后，数据不会被破坏，假如A账户给B账户转10块钱，不管成功与否，A和B的总金额是不变的。</li>\r\n	<li><strong>隔离性：</strong>&nbsp;多个事务并发访问时，事务之间是相互隔离的，一个事务不应该被其他事务干扰，多个并发事务之间要相互隔离。。</li>\r\n	<li><strong>持久性：</strong>&nbsp;表示事务完成提交后，该事务对数据库所作的操作更改，将持久地保存在数据库之中。</li>\r\n</ul>\r\n\r\n<p><span style=\"font-size:16px\"><a id=\"a3\" name=\"a3\">事务并发存在的问题</a></span></p>\r\n\r\n<h3 style=\"margin-left:40px\"><strong>脏读（dirty read）</strong></h3>\r\n\r\n<p style=\"margin-left:40px\">假设现在有两个事务A、B：</p>\r\n\r\n<ul>\r\n	<li>假设现在A的余额是100，事务A正在准备查询Jay的余额</li>\r\n	<li>这时候，事务B先扣减Jay的余额，扣了10</li>\r\n	<li>最后A 读到的是扣减后的余额</li>\r\n</ul>\r\n\r\n<p style=\"margin-left:40px\">事务A、B交替执行，事务A被事务B干扰到了，因为事务A读取到事务B未提交的数据,这就是<strong>脏读</strong>。</p>\r\n\r\n<h3 style=\"margin-left:40px\"><strong>不可重复读（unrepeatable read）</strong></h3>\r\n\r\n<p style=\"margin-left:40px\">假设现在有两个事务A和B：</p>\r\n\r\n<ul>\r\n	<li>事务A先查询Jay的余额，查到结果是100</li>\r\n	<li>这时候事务B 对Jay的账户余额进行扣减，扣去10后，提交事务</li>\r\n	<li>事务A再去查询Jay的账户余额发现变成了90</li>\r\n</ul>\r\n\r\n<p style=\"margin-left:40px\">事务A又被事务B干扰到了！在事务A范围内，两个相同的查询，读取同一条记录，却返回了不同的数据，这就是<strong>不可重复读</strong>。</p>\r\n\r\n<h3 style=\"margin-left:40px\"><strong>幻读</strong></h3>\r\n\r\n<p style=\"margin-left:40px\">假设现在有两个事务A、B：</p>\r\n\r\n<ul>\r\n	<li>事务A先查询id大于2的账户记录，得到记录id=2和id=3的两条记录</li>\r\n	<li>这时候，事务B开启，插入一条id=4的记录，并且提交了</li>\r\n	<li>事务A再去执行相同的查询，却得到了id=2,3,4的3条记录了。</li>\r\n</ul>\r\n\r\n<p style=\"margin-left:40px\">事务A查询一个范围的结果集，另一个并发事务B往这个范围中插入/删除了数据，并静悄悄地提交，然后事务A再次查询相同的范围，两次读取得到的结果集不一样了，这就是<strong>幻读</strong>。</p>\r\n\r\n<h2><a id=\"a4\" name=\"a4\"><span style=\"font-size:16px\">事务的四大隔离级别</span></a></h2>\r\n\r\n<ul>\r\n	<li>读未提交(Read Uncommitted)</li>\r\n	<li>读已提交(Read Committed)</li>\r\n	<li>可重复读(Repeatable Read)</li>\r\n	<li>串行化(Serializable)</li>\r\n</ul>\r\n\r\n<p>Mysql 默认的事务隔离级别是可重复读(Repeatable Read)</p>\r\n\r\n<p>在<strong>读未提交（Read Uncommitted）</strong> 隔离级别下，一个事务会读到其他事务未提交的数据的，即存在<strong>脏读</strong>问题。事务B都还没commit到数据库呢，事务A就读到了，感觉都乱套了。。。实际上，读未提交是隔离级别最低的一种。</p>\r\n\r\n<p>为了避免脏读，数据库有了比<strong>读未提交</strong>更高的隔离级别，即<strong>读已提交</strong>。</p>\r\n\r\n<p>隔离级别设置为<strong>已提交读（READ COMMITTED）</strong> 时，已经不会出现脏读问题了，当前事务只能读取到其他事务提交的数据。但是，在同一个事务A里，相同的查询sql，读取同一条记录（id=1），读到的结果是不一样的，即<strong>不可重复读</strong>。所以，隔离级别设置为read committed的时候，还会存在<strong>不可重复读</strong>的并发问题。</p>\r\n\r\n<h3>可重复读（Repeatable Read）</h3>\r\n\r\n<p>串行化(Serializable),当数据库隔离级别设置为serializable的时候，事务B对表的写操作，在等事务A的读操作。其实，这是隔离级别中最严格的，读写都不允许并发。它保证了最好的安全性，性能却是个问题</p>\r\n\r\n<h2><a id=\"b1\" name=\"b1\"><span style=\"font-size:16px\">MySql隔离级别的实现原理</span></a></h2>\r\n\r\n<p><strong>实现隔离机制的方法主要有两种：</strong></p>\r\n\r\n<ul>\r\n	<li>读写锁</li>\r\n	<li>一致性快照读，即 MVCC</li>\r\n</ul>\r\n\r\n<p>MySql使用不同的锁策略(Locking Strategy)/MVCC来实现四种不同的隔离级别。RR、RC的实现原理跟MVCC有关，RU和Serializable跟锁有关。</p>\r\n\r\n<p><strong>读未提交，采取的是读不加锁原理。</strong></p>\r\n\r\n<ul>\r\n	<li>事务读不加锁，不阻塞其他事务的读和写</li>\r\n	<li>事务写阻塞其他事务写，但不阻塞其他事务读</li>\r\n</ul>\r\n\r\n<h3><strong><span style=\"font-size:10px\">串行化（Serializable)</span></strong></h3>\r\n\r\n<ul>\r\n	<li>所有SELECT语句会隐式转化为&nbsp;<code>SELECT...FOR SHARE</code>，即加共享锁。</li>\r\n	<li>读加共享锁，写加排他锁，读写互斥。如果有未提交的事务正在修改某些行，所有select这些行的语句都会阻塞。</li>\r\n</ul>\r\n\r\n<h3><span style=\"font-size:14px\"><strong>MVCC的实现原理</strong></span></h3>\r\n\r\n<p>MVCC，中文叫<strong>多版本并发控制</strong>，它是通过读取历史版本的数据，来降低并发事务冲突，从而提高并发性能的一种机制。它的实现依赖于<strong>隐式字段、undo日志、快照读&amp;当前读、Read View</strong>，因此，我们先来了解这几个知识点。</p>\r\n\r\n<h4><strong>隐式字段</strong></h4>\r\n\r\n<p>对于InnoDB存储引擎，每一行记录都有两个隐藏列DBTRXID,DBROLLPTR，如果表中没有主键和非NULL唯一键时，则还会有第三个隐藏的主键列 DBROWID。</p>\r\n\r\n<ul>\r\n	<li>DBTRXID，记录每一行最近一次修改（修改/更新）它的事务ID，大小为6字节；</li>\r\n	<li>DBROLLPTR，这个隐藏列就相当于一个指针，指向回滚段的undo日志，大小为7字节；</li>\r\n	<li>DBROWID，单调递增的行ID，大小为6字节；</li>\r\n</ul>\r\n\r\n<h4><strong>undo日志</strong></h4>\r\n\r\n<p>多个事务并行操作某一行数据时，不同事务对该行数据的修改会产生多个版本，然后通过回滚指针（DBROLLPTR）连一条<strong>Undo日志链</strong>。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h4>共享锁与排他锁</h4>\r\n\r\n<p>InnoDB 实现了标准的行级锁，包括两种：共享锁（简称 s 锁）、排它锁（简称 x 锁）。</p>\r\n\r\n<ul>\r\n	<li>共享锁（S锁）：允许持锁事务读取一行。</li>\r\n	<li>排他锁（X锁）：允许持锁事务更新或者删除一行。</li>\r\n</ul>\r\n\r\n<h4>记录锁（Record Locks）</h4>\r\n\r\n<ul>\r\n	<li>记录锁是最简单的行锁，<strong>仅仅锁住一行</strong>。如：&nbsp;<code>SELECT c1 FROM t WHERE c1=10FOR UPDATE</code></li>\r\n	<li>记录锁<strong>永远都是加在索引上</strong>的，即使一个表没有索引，InnoDB也会隐式的创建一个索引，并使用这个索引实施记录锁。</li>\r\n	<li>会阻塞其他事务对其插入、更新、删除</li>\r\n</ul>\r\n\r\n<h4>间隙锁（Gap Locks）</h4>\r\n\r\n<ul>\r\n	<li>间隙锁是一种加在两个索引之间的锁，或者加在第一个索引之前，或最后一个索引之后的间隙。</li>\r\n	<li>使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。</li>\r\n	<li>间隙锁只阻止其他事务插入到间隙中，他们不阻止其他事务在同一个间隙上获得间隙锁，所以 gap x lock 和 gap s lock 有相同的作用。</li>\r\n</ul>\r\n\r\n<h4>Next-Key Locks</h4>\r\n\r\n<ul>\r\n	<li>\r\n	<p>Next-key锁是记录锁和间隙锁的组合，它指的是加在某条记录以及这条记录前面间隙上的锁。</p>\r\n	</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-18 17:22:57', '2022-08-26 17:22:57', 0, '数据库');
INSERT INTO `blog` VALUES (58, 1, '01', 1, 'select for update 含义', '<p>select 查询语句是不会加锁的，但是 select for update 除了有查询的作用外， 还会加锁呢，而且它是悲观锁。至于加了是行锁还是表锁，这就要看是不是用了<strong>索引/主键</strong>。<br />\r\n<strong>没用索引/主键的话就是表锁</strong>，否则就是是<strong>行锁</strong>。</p>\r\n', '', NULL, NULL, 0, '2022-08-26 17:27:55', '2022-08-26 17:30:42', 0, '数据库');
INSERT INTO `blog` VALUES (59, 1, '01', 1, '一条 sql 执行过长的时间如何优化', '<ul>\r\n	<li>查看是否涉及多表和子查询，优化 Sql 结构，如去除冗余字段，是否可拆表等</li>\r\n	<li>优化索引结构，看是否可以适当添加索引</li>\r\n	<li>数量大的表，可以考虑进行分离/分表(如交易流水表)</li>\r\n	<li>数据库主从分离，读写分离</li>\r\n	<li>explain 分析 sql 语句，查看执行计划，优化 sql</li>\r\n	<li>查看 mysql 执行日志，分析是否有其他方面的问题</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-06-28 17:33:13', '2022-08-26 17:33:13', 0, '数据库');
INSERT INTO `blog` VALUES (60, 1, '01', 1, 'Blob 和 text 有什么区别', '<ul>\r\n	<li>Blob 用于存储二进制数据，而 Text 用于存储大字符串。</li>\r\n	<li>Blob 值被视为二进制字符串(字节字符串),它们没有字符集，并且排序和比较基于列值中的字节的数值。</li>\r\n	<li>text 值被视为非二进制字符串(字符字符串)。它们有一个字符集，并根据字符集的排序规则对值进行排序和比较。</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-06-23 17:35:32', '2022-08-26 17:35:32', 0, '数据库');
INSERT INTO `blog` VALUES (61, 1, '01', 1, 'mysql 里记录货币用什么字段类型比较好', '<ul>\r\n	<li>\r\n	<p>货币在数据库中 MySQL 常用 Decimal 和 Numric 类型表示，这两种类型被 MySQL 实现为同样的类型。他们被用于保存与金钱有关的数据。</p>\r\n	</li>\r\n	<li>\r\n	<p>salary DECIMAL(9,2)，9(precision)代表将被用于存储值的总的小数位数，而 2(scale)代表将被用于存储小数点后的位数。存储在 salary 列中的值的范围是从- 9999999.99 到 9999999.99。</p>\r\n	</li>\r\n	<li>\r\n	<p>DECIMAL 和 NUMERIC 值作为字符串存储，而不是作为二进制浮点数，以便保存 那些值的小数精度。</p>\r\n	</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-07-16 17:35:56', '2022-08-26 17:35:56', 0, '数据库');
INSERT INTO `blog` VALUES (62, 1, '01', 1, 'MySQL中锁', '<p>如果按锁粒度划分，有以下 3 种:</p>\r\n\r\n<ul>\r\n	<li>表锁: 开销小，加锁快;锁定力度大，发生锁冲突概率高，并发度最低;不会出现 死锁。</li>\r\n	<li>行锁: 开销大，加锁慢;会出现死锁;锁定粒度小，发生锁冲突的概率低，并发 度高。</li>\r\n	<li>页锁: 开销和加锁速度介于表锁和行锁之间;会出现死锁;锁定粒度介于表锁和 行锁之间，并发度一般</li>\r\n</ul>\r\n\r\n<p>按加锁机制，分为：</p>\r\n\r\n<ul>\r\n	<li>乐观锁</li>\r\n	<li>悲观锁</li>\r\n</ul>\r\n\r\n<p>按兼容性</p>\r\n\r\n<ul>\r\n	<li>共享锁</li>\r\n	<li>排他锁</li>\r\n</ul>\r\n\r\n<p>按锁模式</p>\r\n\r\n<ul>\r\n	<li>记录锁（Record Lock）</li>\r\n	<li>间隙锁（Gap Lock）</li>\r\n	<li>临键锁(Next-Key Lock)</li>\r\n	<li>插入意向锁</li>\r\n	<li>自增锁</li>\r\n	<li>意向锁</li>\r\n	<li>共享/排他锁</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h3>&nbsp;</h3>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-06-26 17:44:15', '2022-08-26 17:44:15', 0, '数据库');
INSERT INTO `blog` VALUES (63, 1, '01', 1, 'MySQL数据库 cpu 飙升的话，要怎么处理呢', '<p>排查过程:</p>\r\n\r\n<ul>\r\n	<li>使用 top 命令观察，确定是 mysqld 导致还是其他原因。</li>\r\n	<li>如果是 mysqld 导致的，show processlist，查看 session 情况，确定是不是有消耗资源的 sql 在运行。</li>\r\n	<li>找出消耗高的 sql，看看执行计划是否准确， 索引是否缺失，数据量是否太大。</li>\r\n</ul>\r\n\r\n<p>处理:</p>\r\n\r\n<ul>\r\n	<li>kill 掉这些线程(同时观察 cpu 使用率是否下降)，</li>\r\n	<li>进行相应的调整(比如说加索引、改 sql、改内存参数)</li>\r\n	<li>重新跑这些 SQL。</li>\r\n</ul>\r\n\r\n<p>其他情况:</p>\r\n\r\n<p>也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进 来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做 出相应的调整，比如说限制连接数等</p>\r\n', '', NULL, NULL, 0, '2022-07-16 17:49:41', '2022-08-26 17:49:41', 0, '数据库');
INSERT INTO `blog` VALUES (64, 1, '01', 1, 'MySQL的复制原理以及流程', '<pre>\r\n主从复制原理，简言之，就三步曲，如下:\r\n</pre>\r\n\r\n<ul>\r\n	<li>主数据库有个 bin-log 二进制文件，纪录了所有增删改 Sql 语句。(binlog 线程)</li>\r\n	<li>从数据库把主数据库的 bin-log 文件的 sql 语句复制过来。(io 线程)</li>\r\n	<li>从数据库的 relay-log 重做日志文件中再执行一次这些 sql 语句。(Sql 执行线程)</li>\r\n</ul>\r\n\r\n<pre>\r\n主从复制分了五个步骤进行:\r\n</pre>\r\n\r\n<ul>\r\n	<li>步骤一:主库的更新事件(update、insert、delete)被写到 binlog</li>\r\n	<li>步骤二:从库发起连接，连接到主库。</li>\r\n	<li>步骤三:此时主库创建一个 binlog dump thread，把 binlog 的内容发送到从库。</li>\r\n	<li>步骤四:从库启动之后，创建一个 I/O 线程，读取主库传过来的 binlog 内容并写入到 relay log</li>\r\n	<li>步骤五:还会创建一个 SQL 线程，从 relay log 里面读取内容，从Exec_Master_Log_Pos 位置开始执行读取到的更新事件，将更新内容写入到 slave 的 db</li>\r\n</ul>\r\n\r\n<p>主从同步延迟的原因</p>\r\n\r\n<p>一个服务器开放N个链接给客户端来连接的，这样有会有大并发的更新操作, 但是从服务器的里面读取 binlog 的线程仅有一个，当某个 SQL 在从服务器上 执行的时间稍长 或者由于某个 SQL 要进行锁表就会导致，主服务器的 SQL 大 量积压，未被同步到从服务器里。这就导致了主从不一致， 也就是主从延迟。</p>\r\n\r\n<p>主从同步延迟的解决办法</p>\r\n\r\n<ul>\r\n	<li>主服务器要负责更新操作，对安全性的要求比从服务器要高，所以有些设置参数可 以修改，比如 sync_binlog=1，innodb_flush_log_at_trx_commit = 1 之类的 设置等。</li>\r\n	<li>选择更好的硬件设备作为 slave。</li>\r\n	<li>把一台从服务器当度作为备份使用， 而不提供查询， 那边他的负载下来了， 执行</li>\r\n	<li>relay log 里面的 SQL 效率自然就高了。</li>\r\n	<li>增加从服务器喽，这个目的还是分散读的压力，从而降低服务器负载。</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-07-26 17:51:05', '2022-08-26 17:55:07', 0, '数据库');
INSERT INTO `blog` VALUES (65, 1, '01', 1, 'Redis 为什么这么快', '<p><strong>Redis 为什么这么快</strong></p>\r\n\r\n<ol>\r\n	<li><strong>基于内存存储实现。</strong>内存读写是比在磁盘快很多的，Redis 基于内存存储实现的数据库， 相对于数据存在磁盘的 MySQL 数据库，省去磁盘 I/O 的消耗。</li>\r\n	<li>\r\n	<p><strong>高效的数据结构。</strong></p>\r\n\r\n	<ol>\r\n		<li>\r\n		<p>字符串长度处理:Redis 获取字符串长度，时间复杂度为 O(1)，而 C 语言中， 需要从头开始遍历，复杂度为 O(n);</p>\r\n		</li>\r\n		<li>\r\n		<p>空间预分配:字符串修改越频繁的话，内存分配越频繁，就会消耗性能，而 SDS 修改和空间扩充，会额外分配未使用的空间，减少性能损耗。</p>\r\n		</li>\r\n		<li>\r\n		<p>&nbsp;惰性空间释放:SDS 缩短时，不是回收多余的内存空间，而是 free 记录下多 余的空间，后续有变更，直接使用 free 中记录的空间，减少分配。</p>\r\n		</li>\r\n		<li>\r\n		<p>二进制安全:Redis 可以存储一些二进制数据，在 C 语言中字符串遇到&#39;\\0&#39;会 结束，而 SDS 中标志字符串结束的是 len 属性。</p>\r\n		</li>\r\n	</ol>\r\n	</li>\r\n	<li>\r\n	<p><strong>合理的数据编码。</strong>Redis 支持多种数据数据类型，每种基本类型，可能对多种数据结构。什么时 候,使用什么样数据结构，使用什么样编码</p>\r\n\r\n	<ol>\r\n		<li>\r\n		<p>String:如果存储数字的话，是用 int 类型的编码;如果存储非数字，小于等于 39 字节的字符串，是 embstr;大于 39 个字节，则是 raw 编码。</p>\r\n		</li>\r\n		<li>\r\n		<p>List:如果列表的元素个数小于 512 个，列表每个元素的值都小于 64 字节 (默认)，使用 ziplist 编码，否则使用 linkedlist 编码</p>\r\n		</li>\r\n		<li>\r\n		<p>Hash:哈希类型元素个数小于 512 个，所有值小于 64 字节的话，使用 ziplist 编码,否则使用 hashtable 编码。</p>\r\n		</li>\r\n		<li>\r\n		<p>&nbsp;Set:如果集合中的元素都是整数且元素个数小于 512 个，使用 intset 编码， 否则使用 hashtable 编码。</p>\r\n		</li>\r\n		<li>\r\n		<p>Zset:当有序集合的元素个数小于 128 个，每个元素的值小于 64 字节时，使 用 ziplist 编码，否则使用 skiplist(跳跃表)编码</p>\r\n		</li>\r\n	</ol>\r\n	</li>\r\n	<li>\r\n	<p><strong>合理的线程模型</strong></p>\r\n	</li>\r\n</ol>\r\n', '', NULL, NULL, 0, '2022-08-26 18:15:52', '2022-08-26 18:15:52', 0, NULL);
INSERT INTO `blog` VALUES (66, 1, '01', 1, '消息队列', '<ul>\r\n	<li><a href=\"http://47.104.222.156/blog/67\" target=\"_blank\">什么是消息队列</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/69\" target=\"_blank\">消息队列如何解决消息丢失问题?</a></li>\r\n	<li><a href=\"http://47.104.222.156/blog/68\" target=\"_blank\">消息队列有哪些使用场景</a></li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2022-09-01 15:42:48', '2023-02-08 19:47:23', 0, NULL);
INSERT INTO `blog` VALUES (67, 1, '01', 1, '什么是消息队列', '<p>消息队列理解为一个使用队列来通信的组件。它的本质，就是个转发器，包含发消息、存消息、消费消息的过程。最简单的消息队列模型如下：</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202209/1_20220901154350.png\" style=\"height:200px; width:530px\" /></p>\r\n\r\n<p>我们通常说的消息队列，简称 MQ(Message Queue)，它其实就指消息 中间件，当前业界比较流行的开源消息中间件包括:<span style=\"color:#e74c3c\"> RabbitMQ、RocketMQ、Kafka</span></p>\r\n', '', NULL, NULL, 0, '2022-09-01 15:44:12', '2022-09-01 15:45:28', 0, NULL);
INSERT INTO `blog` VALUES (68, 1, '01', 1, '消息队列有哪些使用场景', '<p>1. 应用解耦 2. 流量削峰 3. 异步处理 4. 消息通讯 5. 远程调用</p>\r\n\r\n<p><strong>应用解耦</strong></p>\r\n\r\n<pre>\r\n常见业务场景:下单扣库存，用户下单后，订单系统去通知库存系统扣减。传统的做法就是订单系统直接调用库存系统\r\n</pre>\r\n\r\n<ul>\r\n	<li>如果库存系统无法访问，下单就会失败，订单和库存系统存在耦合关系</li>\r\n	<li>如果业务又接入一个营销积分服务，那订单下游系统要扩充，如果未来接入越来越多的下游系统，那订单系统代码需要经常修改</li>\r\n</ul>\r\n\r\n<p><img alt=\"\" src=\"/blog/202209/1_20220901155003.png\" style=\"height:340px; width:488px\" /></p>\r\n\r\n<pre>\r\n如何解决这个问题呢?可以引入消息队列\r\n</pre>\r\n\r\n<p><img alt=\"\" src=\"/blog/202209/1_20220901155010.png\" style=\"height:203px; width:548px\" /></p>\r\n\r\n<p>1. 订单系统:用户下单后，消息写入到消息队列，返回下单成功</p>\r\n\r\n<p>2. 库存系统:订阅下单消息，获取下单信息，进行库存操作。</p>\r\n\r\n<p><strong>流量削峰</strong></p>\r\n\r\n<p>流量削峰也是消息队列的常用场景。我们做秒杀实现的时候，需要避免流量暴涨，打垮应用系统的风险。可以在应用前面加入消息队列。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202209/1_20220901155308.png\" style=\"height:100px; width:528px\" /></p>\r\n\r\n<p>假设秒杀系统每秒最多可以处理 2k 个请求，每秒却有 5k 的请求过来，可以引 入消息队列，秒杀系统每秒从消息队列拉 2k 请求处理得了。 有些伙伴担心这样会出现消息积压的问题，</p>\r\n\r\n<ul>\r\n	<li>首先秒杀活动不会每时每刻都那么多请求过来，高峰期过去后，积压的请求可以慢 慢处理;</li>\r\n	<li>其次，如果消息队列长度超过最大数量，可以直接抛弃用户请求或跳转到错误页面</li>\r\n</ul>\r\n\r\n<p><strong>异步处理</strong></p>\r\n\r\n<p>我们经常会遇到这样的业务场景:用户注册成功后，给它发个短信和发个邮件。</p>\r\n\r\n<p>如果注册信息入库是 30ms，发短信、邮件也是 30ms，三个动作串行执行的 话，会比较耗时，响应 90ms:</p>\r\n\r\n<p>如果采用并行执行的方式，可以减少响应时间。注册信息入库后，同时异步发 短信和邮件。如何实现异步呢，用消息队列即可，就是说，注册信息入库成功 后，写入到消息队列(这个一般比较快，如只需要 3ms)，然后异步读取发邮 件和短信。</p>\r\n\r\n<p><strong>消息通讯</strong></p>\r\n\r\n<p>消息队列内置了高效的通信机制，可用于消息通讯。如实现点对点消息队列、聊天室等。</p>\r\n\r\n<p><strong>远程调用</strong></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-09-01 15:54:22', '2022-09-01 15:59:09', 0, NULL);
INSERT INTO `blog` VALUES (69, 1, '01', 1, '消息队列如何解决消息丢失问题?', '<p>一个消息从生产者产生，到被消费者消费，主要经过这 3 个过程:</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202209/1_20220901160040.png\" style=\"height:129px; width:504px\" /></p>\r\n\r\n<p>因此如何保证 MQ 不丢失消息，可以从这三个阶段阐述:</p>\r\n\r\n<ul>\r\n	<li>生产者保证不丢消息 </li>\r\n	<li>存储端不丢消息</li>\r\n	<li>消费者不丢消息</li>\r\n</ul>\r\n\r\n<p><strong>生产者保证不丢消息</strong></p>\r\n\r\n<p>如果是 RocketMQ 消息中间件，Producer 生产者提供了三种发送消息的方 式，分别是:</p>\r\n\r\n<ul>\r\n	<li>同步发送 </li>\r\n	<li>异步发送 </li>\r\n	<li>单向发送</li>\r\n</ul>\r\n\r\n<pre>\r\n生产者要想发消息时保证消息不丢失，可以:\r\n</pre>\r\n\r\n<ul>\r\n	<li>采用同步方式发送，send 消息方法返回成功状态，就表示消息正常到达了存储端 Broker。</li>\r\n	<li>如果 send 消息异常或者返回非成功状态，可以重试。</li>\r\n	<li>可以使用事务消息，RocketMQ 的事务消息机制就是为了保证零丢失来设计的</li>\r\n</ul>\r\n\r\n<p><strong>存储端不丢消息</strong></p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-09-01 16:09:23', '2022-09-01 16:25:10', 0, NULL);
INSERT INTO `blog` VALUES (70, 1, '01', 1, '微信支付-开发前准备-选择介入模式', '<p><span style=\"font-size:16px\"><strong>接入模式</strong></span></p>\r\n\r\n<p>商户/服务商在接入前首先要判断自己公司注册区域适用的接入模式，微信支付目前提供两种接入方式：直连模式和服务商模式</p>\r\n\r\n<h4>● 直连模式：</h4>\r\n\r\n<p>信息、资金流：微信支付&mdash;&gt;直连商户</p>\r\n\r\n<p>直连模式，商户自行申请入驻微信支付，无需服务商协助。（<a href=\"https://pay.weixin.qq.com/index.php/core/home/login?return_url=%2F\" target=\"_blank\">商户平台</a>申请）成为直连商户</p>\r\n\r\n<h4 style=\"text-align:start\"><span style=\"font-size:18px\"><strong><span style=\"color:#333333\"><span style=\"font-family:&quot;Helvetica Neue&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei&quot;,黑体,Arial,sans-serif\"><span style=\"background-color:#fafbfc\">● 服务商模式：</span></span></span></strong></span></h4>\r\n\r\n<p><span style=\"font-size:14px\"><span style=\"color:#333333\"><span style=\"font-family:&quot;Helvetica Neue&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei&quot;,黑体,Arial,sans-serif\"><span style=\"background-color:#fafbfc\"><img src=\"https://pay.weixin.qq.com/wiki/doc/apiv3/assets/img/common/ico-guide/chapter1_4_1.png\" style=\"border:none; padding:0px; vertical-align:top\" /></span></span></span></span></p>\r\n\r\n<p><span style=\"font-size:14px\"><span style=\"color:#333333\"><span style=\"font-family:&quot;Helvetica Neue&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei&quot;,黑体,Arial,sans-serif\"><span style=\"background-color:#fafbfc\">&nbsp;&nbsp;&nbsp;&nbsp;<strong><span style=\"color:#00cc00\">&mdash;&mdash; 信息流</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"color:#c66a53\">&mdash;&mdash; 资金流</span></strong></span></span></span></span></p>\r\n\r\n<p style=\"text-align:start\"><span style=\"font-size:14px\"><span style=\"color:#333333\"><span style=\"font-family:&quot;Helvetica Neue&quot;,&quot;Hiragino Sans GB&quot;,&quot;Microsoft YaHei&quot;,黑体,Arial,sans-serif\"><span style=\"background-color:#fafbfc\">服务商模式，商户申请成为微信支付服务商，服务商自身无法作为一个直连商户直接发起交易，其发起交易必须传入相关特约商户商户号的参数信息。（<a href=\"https://pay.weixin.qq.com/static/partner_guide/partner_types.shtml\" style=\"color:#00b54b; text-decoration:none\" target=\"_blank\">服务商平台</a>申请）成为服务商</span></span></span></span></p>\r\n\r\n<p style=\"text-align:start\">&nbsp;</p>\r\n\r\n<p style=\"text-align:start\">&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-09-07 20:45:34', '2022-09-07 20:54:39', 0, NULL);
INSERT INTO `blog` VALUES (71, 1, '01', 1, '微信支付-开发前准备-参数申请', '<h4><strong>1、申请APPID</strong></h4>\r\n\r\n<p>由于微信支付的产品体系全部搭载于微信的社交体系之上，所以直连商户或服务商接入微信支付之前，都需要有一个微信社交载体，该载体对应的ID即为APPID。</p>\r\n\r\n<p>对于直连商户，该社交载体可以是公众号（<a href=\"https://mp.weixin.qq.com/cgi-bin/readtemplate?t=business/faq_operation_tmpl&amp;type=info&amp;lang=zh_CN&amp;token=\" target=\"_blank\">什么是公众号</a>），小程序（<a href=\"https://mp.weixin.qq.com/cgi-bin/wx?token=&amp;lang=zh_CN\" target=\"_blank\">什么是小程序</a>）或APP。</p>\r\n\r\n<p>如申请社交载体为公众号，请前往&nbsp;<a href=\"https://mp.weixin.qq.com/cgi-bin/loginpage?t=wxm2-login&amp;lang=zh_CN&amp;token=\" target=\"_blank\">公众平台</a>申请，如申请社交载体为小程序，请前往&nbsp;<a href=\"https://developers.weixin.qq.com/miniprogram/dev/framework/quickstart/getstart.html#%E7%94%B3%E8%AF%B7%E5%B8%90%E5%8F%B7\" target=\"_blank\">小程序平台</a>&nbsp;申请</p>\r\n\r\n<p>如商户已拥有自己的APP，且希望该APP接入微信支付，请前往&nbsp;<a href=\"https://open.weixin.qq.com/\" target=\"_blank\">开放平台</a>申请</p>\r\n\r\n<p>商户可根据实际的业务需求来选择申请不同的社交载体。</p>\r\n\r\n<p>各类社交载体一旦申请成功后，可以登录对应平台查看账号信息以获取对应的appid。</p>\r\n\r\n<h4><strong>2、申请mchid</strong></h4>\r\n\r\n<p>申请mchid和APPID的操作互不影响，可以并行操作，申请地址如下：&nbsp;<a href=\"https://pay.weixin.qq.com/index.php/core/home/login?return_url=%2Fpublic%2Fwxpay%2Fapply_guidee\" target=\"_blank\">商户号申请平台</a></p>\r\n\r\n<p>申请成功后，会向服务商填写的联系邮箱下发通知邮件，内容包含申请成功的mchid及其登录账号密码，请妥善保存。</p>\r\n\r\n<p>注意：一个mchid只能对应一个结算币种，若需要使用多个币种收款，需要申请对应数量的mchid。</p>\r\n\r\n<p><strong>3、绑定APPID及mchid</strong></p>\r\n\r\n<p>APPID和mchid全部申请完毕后，需要建立两者之间的绑定关系。</p>\r\n\r\n<p>直连模式下，APPID与mchid之间的关系为多对多，即一个APPID下可以绑定多个mchid，而一个mchid也可以绑定多个APPID。</p>\r\n\r\n<p><img src=\"https://pay.weixin.qq.com/wiki/doc/api/wxpay/en/guide/img/Relationship2.png\" style=\"height:211px; width:500px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-09-07 20:47:53', '2022-09-07 20:55:52', 0, NULL);
INSERT INTO `blog` VALUES (72, 1, '01', 1, '微信支付-开发前准备-配置API key', '<h4>1、登录<a href=\"https://pay.weixin.qq.com/\" target=\"_blank\">微信商户平台</a>，进入【账户中心 &gt; API安全 】目录，设置APIV3密钥。</h4>\r\n\r\n<h4>2、在弹出窗口中点击&ldquo;已沟通&rdquo;。</h4>\r\n\r\n<p>3、输入API密钥，内容为32位字符，包括数字及大小写字母。点击获取短信验证码。</p>\r\n\r\n<p>4、输入短信验证码，点击&ldquo;确认&rdquo;即设置成功。</p>\r\n', '', NULL, NULL, 0, '2022-09-07 20:48:53', '2022-09-07 20:56:54', 0, NULL);
INSERT INTO `blog` VALUES (73, 1, '01', 1, '微信支付-开发前准备-下载并配置商户证书', '<p>商户可登录<a href=\"https://pay.weixin.qq.com/\" target=\"_blank\">微信商户平台</a>，在【账户中心】-&gt;【API安全】目录下载证书</p>\r\n\r\n<p>1、在证书申请页面上点击&ldquo;申请证书&rdquo;。</p>\r\n\r\n<h4>2、在弹出窗口中点击&ldquo;确定&rdquo;。</h4>\r\n\r\n<p>3、在弹出窗口内点击&ldquo;下载证书工具&rdquo;按钮下载证书工具。</p>\r\n\r\n<p>4、安装证书工具并打开，选择证书需要存储的路径后点击&ldquo;申请证书&rdquo;。</p>\r\n\r\n<p>5、在证书工具中，将复制的商户信息粘贴并点击&ldquo;下一步&rdquo;。</p>\r\n\r\n<p>6、获取请求串</p>\r\n\r\n<p>7、生成证书串</p>\r\n\r\n<p style=\"margin-left:40px\">步骤1&nbsp;在【商户平台】-&ldquo;复制证书串&rdquo;环节，点击&ldquo;复制证书串&rdquo;按钮后；</p>\r\n\r\n<p style=\"margin-left:40px\">步骤2&nbsp;在【证书工具】-&ldquo;复制请求串&rdquo;环节，点击&ldquo;下一步&rdquo;按钮进入&ldquo;粘贴证书串&rdquo;环节；</p>\r\n\r\n<p style=\"margin-left:40px\">步骤3&nbsp;在【证书工具】-&ldquo;粘贴证书串&rdquo;环节，点击&ldquo;粘贴&rdquo;按钮后；</p>\r\n\r\n<p style=\"margin-left:40px\">步骤4&nbsp;点击&ldquo;下一步&rdquo;按钮，进入【证书工具】-&ldquo;生成证书&rdquo;环节</p>\r\n\r\n<p>8、在【证书工具】-&ldquo;生成证书&rdquo;环节，已完成申请证书流程，点击&ldquo;查看证书文件夹&rdquo;，查看已生成的证书文件。</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-09-07 20:51:10', '2022-09-07 20:57:19', 0, NULL);
INSERT INTO `blog` VALUES (74, 1, '01', 1, '微信支付-开发前准备-配置应用（小程序）', '<p>1、申请小程序开发者账号，进行微信认证，获取appid登录《<a href=\"https://mp.weixin.qq.com/\">微信公众平台</a>》，注册一个小程序的开发者账号。<a href=\"https://mp.weixin.qq.com/debug/wxadoc/introduction/index.html\">小程序账号申请指引</a></p>\r\n\r\n<p>2、小程序开通微信支付，即申请或复用微信支付商户号，申请完小程序后，登录<a href=\"https://mp.weixin.qq.com/\">小程序后台</a>。点击左侧导航栏的微信支付，在页面中进行开通。</p>\r\n\r\n<p>点击开通按钮后，有2种方式可以获取微信支付能力，新申请微信支付商户号或绑定一个已有的微信支付商户号，请根据你的业务需要和具体情况选择，只能二选一。</p>\r\n', '', NULL, NULL, 0, '2022-09-07 20:53:40', '2022-09-07 20:57:42', 0, NULL);
INSERT INTO `blog` VALUES (75, 1, '01', 1, 'SpringBoot-拦截器', '<p><strong>The bean &#39;loginInterceptor&#39;, defined in class path resource<br />\r\ncould not be registered. A bean with that name has already been defined in file</strong></p>\r\n\r\n<p><strong>Consider renaming one of the beans or enabling overriding by setting spring.main.allow-bean-definition-overriding=true</strong></p>\r\n\r\n<p>拦截器</p>\r\n\r\n<pre>\r\n<code>@Configuration\r\npublic class InterceptorAdapterConfig implements WebMvcConfigurer {\r\n\r\n\r\n	@Bean\r\n	public LoginInterceptor loginInterceptor() {\r\n		return new LoginInterceptor();\r\n	}\r\n\r\n}\r\n</code></pre>\r\n\r\n<p>@Bean没有被识别，于是改变写法使用IOC注入：</p>\r\n\r\n<pre>\r\n<code>@Resource\r\nprivate LoginInterceptor loginInterceptor;</code></pre>\r\n\r\n<p>项目成功的运行起来了</p>\r\n\r\n<p>看一下LoginInterceptor 使用了<em>@Component</em></p>\r\n\r\n<p><strong>解决方案：</strong></p>\r\n\r\n<p><strong>1.删除拦截器类级别的@Component注解</strong></p>\r\n\r\n<p><strong>2.将配置类中的@Bean改为IOC自动注入</strong></p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-09-14 15:40:06', '2023-02-08 20:06:23', 0, NULL);
INSERT INTO `blog` VALUES (76, 1, '01', 1, 'Mybatis-plus Generator自动生成', '<pre>\r\n<code>&lt;!--Mybatis-Plus 注意版本 --&gt;\r\n		&lt;dependency&gt;\r\n			&lt;groupId&gt;com.baomidou&lt;/groupId&gt;\r\n			&lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;\r\n			&lt;version&gt;${mybatis-plus.version}&lt;/version&gt;\r\n		&lt;/dependency&gt;\r\n		&lt;!--mybatis-plus生成依赖 --&gt;\r\n		&lt;dependency&gt;\r\n			&lt;groupId&gt;com.baomidou&lt;/groupId&gt;\r\n			&lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt; &lt;!-- 代码生成器，使用它解析表结构 --&gt;\r\n			&lt;version&gt;${mybatis-plus-generator.version}&lt;/version&gt;\r\n		&lt;/dependency&gt;</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<pre>\r\n<code>public class MyFastAutoGenerator {\r\n	//https://github.com/baomidou/mybatis-plus-samples\r\n\r\n	private static final String OUTPUT_DIR = System.getProperty(\"user.dir\") + File.separator + \"src/main/java\";\r\n\r\n	public static void main(String[] args) {\r\n		FastAutoGenerator.create(MyDataSourceConfig.DATA_SOURCE_CONFIG_BUILDER).globalConfig(builder -&gt; {\r\n			builder.author(\"sunnannan\") // 设置作者\r\n					.enableSwagger() // 开启 swagger 模式\r\n					.outputDir(OUTPUT_DIR); // 指定输出目录\r\n		}).packageConfig(builder -&gt; {\r\n			builder.parent(\"com.allmsi.shortplay\")// 父包名\r\n					// .moduleName(\"aa\")// 父包模块名\r\n					.entity(\"po\")// Entity 包名\r\n					.service(\"service\")// Service 包名 默认值:service\r\n					.serviceImpl(\"service.impl\")// Service Impl 包名 默认值:service.impl\r\n					.mapper(\"dao\")// Mapper 包名 默认值:mapper\r\n					.xml(\"mapper.xml\")// Mapper XML 包名 默认值:mapper.xml\r\n					.controller(\"controller\")// Controller 包名 默认值:controller\r\n					.other(\"other\");// 自定义文件包名 输出自定义文件时所用到的包名\r\n			// .pathInfo(Collections.singletonMap(OutputFile.mapperXml, \"D://\"))); //\r\n			// 设置mapperXml生成路径\r\n		}).strategyConfig(builder -&gt; {\r\n			builder.addInclude() // 设置需要生成的表名\r\n					.addTablePrefix(\"video_\")\r\n					.entityBuilder()\r\n					.disableSerialVersionUID()\r\n					.enableChainModel()\r\n					.enableLombok()\r\n					.enableRemoveIsPrefix()\r\n					.enableTableFieldAnnotation()\r\n					.enableActiveRecord()\r\n					.versionColumnName(\"version\")\r\n					.versionPropertyName(\"version\")\r\n					.logicDeleteColumnName(\"del\")\r\n					.logicDeletePropertyName(\"del\")\r\n					.naming(NamingStrategy.underline_to_camel)\r\n					.columnNaming(NamingStrategy.underline_to_camel)\r\n//					.addSuperEntityColumns(\"id\", \"created_by\", \"created_time\", \"updated_by\", \"updated_time\")\r\n//					.addIgnoreColumns(\"age\").addTableFills(new Column(\"create_time\", FieldFill.INSERT))\r\n//					.addTableFills(new Property(\"updateTime\", FieldFill.INSERT_UPDATE)).formatFileName(\"%sPO\")\r\n					.controllerBuilder().enableHyphenStyle().enableRestStyle().formatFileName(\"%sControlller\")\r\n					.serviceBuilder().formatServiceFileName(\"%sService\").formatServiceImplFileName(\"%sServiceImp\")\r\n					.mapperBuilder().enableMapperAnnotation()// 开启 @Mapper 注解\r\n					.enableBaseResultMap()// 启用 BaseResultMap 生成\r\n					.enableBaseColumnList()// 启用 BaseColumnList\r\n					.formatMapperFileName(\"%sDao\")// 转换 mapper 类文件名称\r\n					.formatXmlFileName(\"%sXml\"); // 转换 xml 文件名称\r\n		}).templateEngine(new FreemarkerTemplateEngine()) // 使用Freemarker引擎模板，默认的是Velocity引擎模板\r\n				.execute();\r\n	}\r\n</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-09-14 15:42:03', '2023-02-08 20:19:32', 0, NULL);
INSERT INTO `blog` VALUES (77, 1, '02', 1, 'Linux', '<pre>\r\n<code>批量替换文件名\r\n\r\n# ①、批量替换文件中“_”字符为\"-\"字符\r\n# find ./ -name \"*_*\" | while read f; do mv $f ${f/_/-}; done\r\n\r\n# ②、批量替换文件中“test”字符为\"TEST\"字符\r\n# ls | while read f; do mv $f ${f/test/TEST}; done \r\n\r\n&gt; 引申，文件中的文本替换为：\r\n\r\n# A). 对于单个文件\r\n# sed -i \'s/string1/string2/g\' example.txt \r\n说明：将example.txt文件中的 \"string1\" 替换成 \"string2\"(如果不加-i参数,则在内存中替换; 添加-i参数,则在文件中直接替换)\r\n# B). 对于多个文件\r\n# $ ls|while read f; do sed -i \'s/beijing/shanghai/g\' $f; done\r\n\r\n</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-10-08 10:59:46', '2022-10-08 10:59:46', 0, NULL);
INSERT INTO `blog` VALUES (78, 1, '01', 1, '安装mysql', '<p><strong>1 查看是否已经安装 Mysql</strong></p>\r\n\r\n<p>rpm -qa | grep mysql</p>\r\n\r\n<p><strong>2安装MySQL包</strong></p>\r\n\r\n<p>yum -y install mysql57-community-release-el7-10.noarch.rpm</p>\r\n\r\n<p><strong>3安装 MySQL</strong></p>\r\n\r\n<p>yum -y install mysql-community-server</p>\r\n\r\n<p><strong>4启动 Mysql 服务</strong></p>\r\n\r\n<p>systemctl start mysqld.service</p>\r\n\r\n<p>5<strong>查看 Mysql 运行状态</strong></p>\r\n\r\n<p>service mysqld status</p>\r\n\r\n<p>6<strong>查看初始密码（红色部分为初始密码)</strong></p>\r\n\r\n<p>如果能正常查看到，则OK；如果查看不到，则表示没有密码。</p>\r\n\r\n<p><strong>7进入数据库</strong></p>\r\n\r\n<p>mysql -u root -p</p>\r\n\r\n<p><strong>注: 如果显示数据库无法访问</strong></p>\r\n\r\n<p>修改MySql配置文件my.cnf，新增skip-grant-tables</p>\r\n\r\n<p>find / -name my.cnf</p>\r\n\r\n<p>修改文件之前记得先关闭mysql服务</p>\r\n\r\n<p>service mysqld stop</p>\r\n\r\n<p>通过 vi 指令进入文件</p>\r\n\r\n<p><strong>重置密码（为 root ）</strong></p>\r\n\r\n<p><strong>切换到mysql数据库</strong></p>\r\n\r\n<blockquote>\r\n<p>update user set authentication_string=password(&lsquo;root&rsquo;) where user=&lsquo;root&rsquo;;</p>\r\n</blockquote>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h1>公钥尚未安装</h1>\r\n\r\n<p><strong>解决：</strong></p>\r\n\r\n<p>执行以下命令</p>\r\n\r\n<p>rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022</p>\r\n\r\n<p><strong>原因：</strong></p>\r\n\r\n<p>可能是MySQL GPG&nbsp;<a href=\"https://so.csdn.net/so/search?q=%E5%AF%86%E9%92%A5&amp;spm=1001.2101.3001.7020\" target=\"_blank\">密钥</a>已过期导致，改一下密钥。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-11-08 10:40:22', '2022-11-08 12:38:07', 0, NULL);
INSERT INTO `blog` VALUES (79, 1, '01', 1, '安装nginx', '<p>yum install -y nginx</p>\r\n', '', NULL, NULL, 0, '2022-11-08 12:39:13', '2022-11-08 12:39:13', 0, NULL);
INSERT INTO `blog` VALUES (80, 1, '01', 1, '安装jdk', '<h2>tar -xvf jdk-8u65-linux-x64.tar.gz -C /usr/local/jdk</h2>\r\n\r\n<h2><strong>配置环境变量</strong></h2>\r\n\r\n<p>JAVA_HOME=/usr/local/jdk/jdk1.8.0_181<br />\r\nJRE_HOME=$JAVA_HOME/jre<br />\r\nCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib<br />\r\nPATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH<br />\r\nexport JAVA_HOME JRE_HOME CLASS_PATH PATH</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-11-08 12:40:45', '2022-11-08 12:46:59', 0, NULL);
INSERT INTO `blog` VALUES (81, 1, '01', 1, '小程序外链', '<h1>小程序链接生成与使用规则调整公告</h1>\r\n\r\n<p>https://developers.weixin.qq.com/community/develop/doc/000aeab88a4ea0c5c89d81fde5b801</p>\r\n\r\n<h1>获取 URL Link</h1>\r\n\r\n<p>https://developers.weixin.qq.com/miniprogram/dev/framework/open-ability/url-link.html</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202211/1_20221110103435.png\" /></p>\r\n', '', NULL, NULL, 0, '2022-11-10 10:34:03', '2022-11-10 10:35:09', 0, NULL);
INSERT INTO `blog` VALUES (82, 1, '01', 1, 'Redis-短剧时', '<p>cd /usr/local/redis/redis-4.0.9/src</p>\r\n\r\n<p>./redis-cli</p>\r\n\r\n<p>auth&nbsp;</p>\r\n\r\n<p>当前库key的数量：dbsize</p>\r\n\r\n<p>所有库key的数量:&nbsp;info keyspace</p>\r\n\r\n<p>keys * 查询所有key<br />\r\n数据量很小的时候可以使用，生产环境极不推荐。<br />\r\n会引起阻塞，严重的话会引起应用程序出现雪崩</p>\r\n\r\n<p>info memory</p>\r\n\r\n<p>可视化工具</p>\r\n\r\n<pre>\r\nwget&nbsp;https://github.com/xueqiu/rdr/releases/download/v0.0.1/rdr-linux&nbsp;chmod&nbsp;+x&nbsp;rdr-linux\r\n</pre>\r\n\r\n<p>used_memory : 由 Redis 分配器分配的内存总量，以字节（byte）为单位</p>\r\n\r\n<p>used_memory_human : 以人类可读的格式返回 Redis 分配的内存总量</p>\r\n\r\n<p>used_memory_rss : 从操作系统的角度，返回 Redis 已分配的内存总量（俗称常驻集大小）。这个值和 top 、 ps 等命令的输出一致。</p>\r\n\r\n<p>分析 查询结果2</p>\r\n\r\n<p>used_memory_peak : Redis 的内存消耗峰值（以字节为单位）</p>\r\n\r\n<p>used_memory_peak_human : 以人类可读的格式返回 Redis 的内存消耗峰值</p>\r\n\r\n<p>used_memory_lua : Lua 引擎所使用的内存大小（以字节为单位）</p>\r\n\r\n<p>mem_fragmentation_ratio : used_memory_rss 和 used_memory 之间的比率</p>\r\n\r\n<p>mem_allocator : 在编译时指定的， Redis 所使用的内存分配器。可以是 libc 、 jemalloc 或者 tcmalloc 。</p>\r\n\r\n<p>对比几个值</p>\r\n\r\n<p>1）当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。<br />\r\n内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。</p>\r\n\r\n<p>2）当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。<br />\r\n当 Redis 释放内存时，分配器可能会，也可能不会，将内存返还给操作系统。</p>\r\n\r\n<p>如果 Redis 释放了内存，却没有将内存返还给操作系统，那么 used_memory 的值可能和操作系统显示的 Redis 内存占用并不一致。查看 used_memory_peak 的值可以验证这种情况是否发生。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>https://www.cnblogs.com/dsyo/p/15122529.html</p>\r\n\r\n<p>https://www.yisu.com/zixun/488970.html</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2022-11-22 16:33:45', '2023-02-08 20:16:13', 0, NULL);
INSERT INTO `blog` VALUES (83, 1, '01', 1, 'RocketMQ组成', '<p>RocketMQ架构上分四部分构成：Producer、Consumer、Broker、NameServer</p>\r\n\r\n<ul>\r\n	<li>Nameserver 无状态，动态列表；这也是和zookeeper的重要区别之一。zookeeper是有状态的。</li>\r\n	<li>Producer 消息生产者，负责发消息到Broker，通过MQ的负载均衡模块选择Broker集群队列进行消息投递，投递过程支持快速失败并且低延迟。</li>\r\n	<li>Broker 就是MQ本身，负责收发消息、持久化消息等。</li>\r\n	<li>Consumer 消息消费者，负责从Broker上拉取消息进行消费，消费完进行ack。</li>\r\n</ul>\r\n\r\n<p><strong>Broker有几个子模块：</strong></p>\r\n\r\n<ul>\r\n	<li>客户端管理器：管理客户端，并且维护consumer的的topic订阅信息</li>\r\n	<li>存储服务：提供简单api处理消息存储磁盘及消息查询功能</li>\r\n	<li>高可用服务：提供master和slave之间的消息同步功能</li>\r\n	<li>索引服务：为消息构建索引，并提供消息查找功能</li>\r\n</ul>\r\n\r\n<p><strong>NameServer主要有以下两个功能：</strong></p>\r\n\r\n<p>Broker管理：接受Broker集群的注册信息并保存作为路由信息的基本数据，提供心跳检测机制，检查Broker是否存活</p>\r\n\r\n<p>路由信息管理：保存Broker集群整个路由信息和用于客户端查询的队列信息，Producer和Consumer通过NameServer获取整个Broker集群的路由信息，进行消息的投递和消费。</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2020-11-29 13:39:31', '2023-02-08 16:58:09', 0, NULL);
INSERT INTO `blog` VALUES (84, 1, '01', 1, '个人主页', '<h2><strong>个人技术栈</strong></h2>\r\n\r\n<p><strong>框架</strong></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/146\" target=\"_blank\">Spring</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/86\" target=\"_blank\">SpringBoot</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/112\" target=\"_blank\">SpringMVC</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/138\" target=\"_blank\">MyBatis</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/76\" target=\"_blank\">Mybatis-plus Generator自动生成</a></li>\r\n	<li>JFinal （极速 web 开发框架）</li>\r\n	<li><a href=\"http://sunnannan.com/blog/157\" target=\"_blank\">JWT</a></li>\r\n</ul>\r\n\r\n<p>分布式</p>\r\n\r\n<ul>\r\n	<li>XXL-JOB分布式任务调度平台</li>\r\n	<li><a href=\"http://sunnannan.com/blog/111\" target=\"_blank\">SpringCloud</a></li>\r\n	<li>Dubbo</li>\r\n	<li>Hadoop</li>\r\n</ul>\r\n\r\n<p><strong>批量工作流任务调度器</strong></p>\r\n\r\n<ul>\r\n	<li>Azkaban</li>\r\n</ul>\r\n\r\n<p><strong>数据库</strong></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/32\" target=\"_blank\">MySQL</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/40\" target=\"_blank\">Redis</a></li>\r\n</ul>\r\n\r\n<p><strong>中间件</strong></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/116\" target=\"_blank\">消息中间件</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/14\" target=\"_blank\">Nginx</a></li>\r\n</ul>\r\n\r\n<p><strong>部署</strong></p>\r\n\r\n<ul>\r\n	<li>Linux</li>\r\n	<li>Docker</li>\r\n</ul>\r\n\r\n<p><strong>工具</strong></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/151\">GIT</a></li>\r\n	<li>Maven / Nexus部署</li>\r\n</ul>\r\n\r\n<p><strong>性能</strong></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/56\" target=\"_blank\">分库与分表设计</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/158\">负载均衡</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/89\" target=\"_blank\">JVM</a></li>\r\n</ul>\r\n\r\n<p><strong>测试</strong></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/156\" target=\"_blank\">测试</a></li>\r\n</ul>\r\n\r\n<p><strong>工作经历</strong></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/149\">2017.04~2023.01 映美&nbsp;技术经理/Java 工程师</a></li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2030-02-01 15:31:28', '2023-04-03 15:45:50', 0, NULL);
INSERT INTO `blog` VALUES (85, 0, '01', 1, 'Spring boot', '<h1>Spring Boot中的监视器:&nbsp;<a href=\"https://blog.csdn.net/ziaia/article/details/124133549\">https://blog.csdn.net/ziaia/article/details/124133549</a></h1>\r\n\r\n<h1>SpringBoot 读取配置文件的 5 种方法！</h1>\r\n\r\n<ol>\r\n	<li>\r\n	<p>使用 @Value 读取配置文件。</p>\r\n	&nbsp;@Value(&quot;${profile.name}&quot;)</li>\r\n	<li>\r\n	<p>使用 @<a href=\"https://so.csdn.net/so/search?q=ConfigurationProperties&amp;spm=1001.2101.3001.7020\" target=\"_blank\">ConfigurationProperties</a>&nbsp;读取配置文件。&nbsp;</p>\r\n\r\n	<p>@ConfigurationProperties 和 @Value 的使用略微不同，@Value 是读取单个配置项的，而 @ConfigurationProperties 是读取一组配置项的，我们可以使用 @ConfigurationProperties 加实体类读取一组配置项，如下代码所示：</p>\r\n	</li>\r\n	<li>\r\n	<p>使用 Environment 读取配置文件。</p>\r\n	</li>\r\n</ol>\r\n\r\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Environment 是 Spring Core 中的一个用于读取配置文件的类，将此类使用 @Autowired 注入到类中就可以使用它的 getProperty 方法来获取某个配置项的值了，如下代码所示：</p>\r\n\r\n<p>&nbsp; &nbsp; &nbsp;4、使用 @PropertySource 读取配置文件。</p>\r\n\r\n<p>使用原生方式读取配置文件。</p>\r\n\r\n<pre>\r\n<code>@SpringBootApplication\r\npublic class DemoApplication implements InitializingBean {\r\n    @Value(\"${profile.name}\")\r\n    private String name;\r\n \r\n    public static void main(String[] args) {\r\n        SpringApplication.run(DemoApplication.class, args);\r\n    }\r\n \r\n    @Override\r\n    public void afterPropertiesSet() throws Exception {\r\n        System.out.println(\"My Profile Name：\" + name);\r\n    }\r\n}\r\n</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 15:38:57', '2023-02-01 15:38:57', 1, NULL);
INSERT INTO `blog` VALUES (86, 1, '02', 1, 'SpringBoot', '<ul>\r\n	<li>\r\n	<p><a href=\"http://sunnannan.com/blog/139\" target=\"_blank\">SpringBoot-读取配置文件</a></p>\r\n	</li>\r\n	<li>\r\n	<p><a href=\"http://sunnannan.com/blog/75\" target=\"_blank\">SpringBoot-拦截器</a></p>\r\n	</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2020-02-01 15:38:58', '2023-02-08 20:08:49', 0, NULL);
INSERT INTO `blog` VALUES (87, 1, '01', 1, 'redis持久化方式有几种', '<h2>如何选择RDB和AOF</h2>\r\n\r\n<ul>\r\n	<li>如果数据不能丢失，RDB和AOF混用</li>\r\n	<li>如果只作为缓存使用，可以承受几分钟的数据丢失的话，可以只使用RDB。</li>\r\n	<li>如果只使用AOF，优先使用everysec的写回策略。</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h2>1、AOF 持久化</h2>\r\n\r\n<p>AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在 redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集。Redis默认情况是不开启AOF的。重启时再重新执行AOF文件中的命令来恢复数据。它主要解决数据持久化的实时性问题。</p>\r\n\r\n<p>AOF是执行完命令后才记录日志的。为什么不先记录日志再执行命令呢？这是因为Redis在向AOF记录日志时，不会先对这些命令进行语法检查，如果先记录日志再执行命令，日志中可能记录了错误的命令，Redis使用日志回复数据时，可能会出错。正是因为执行完命令后才记录日志，所以不会阻塞当前的写操作。但是会存在两个风险：</p>\r\n\r\n<ul>\r\n	<li>更执行完命令还没记录日志时，宕机了会导致数据丢失</li>\r\n	<li>AOF不会阻塞当前命令，但是可能会阻塞下一个操作。</li>\r\n</ul>\r\n\r\n<p>这两个风险最好的解决方案是折中妙用AOF机制的<strong>三种写回策略 appendfsync</strong>：</p>\r\n\r\n<ul>\r\n	<li><strong>always</strong>，同步写回，每个子命令执行完，都立即将日志写回磁盘。</li>\r\n	<li><strong>everysec</strong>，每个命令执行完，只是先把日志写到AOF内存缓冲区，每隔一秒同步到磁盘。</li>\r\n	<li><strong>no</strong>：只是先把日志写到AOF内存缓冲区，有操作系统去决定何时写入磁盘。</li>\r\n</ul>\r\n\r\n<p>always同步写回，可以基本保证数据不丢失，no策略则性能高但是数据可能会丢失，一般可以考虑折中选择everysec。</p>\r\n\r\n<p>AOF优点：</p>\r\n\r\n<ul>\r\n	<li><strong>数据保证</strong>：我们可以设置fsync策略，一般默认是everysec，也可以设置每次写入追加，所以即使服务死掉了，也最多丢失一秒数据</li>\r\n	<li><strong>自动缩小</strong>：当aof文件大小到达一定程度的时候，后台会自动的去执行aof重写，此过程不会影响主进程，重写完成后，新的写入将会写到新的aof中，旧的就会被删除掉。但是此条如果拿出来对比rdb的话还是没有必要算成优点，只是官网显示成优点而已。</li>\r\n</ul>\r\n\r\n<p>AOF缺点：</p>\r\n\r\n<ul>\r\n	<li><strong>性能相对较差</strong>：它的操作模式决定了它会对redis的性能有所损耗。</li>\r\n	<li><strong>体积相对更大</strong>：尽管是将aof文件重写了，但是毕竟是操作过程和操作结果仍然有很大的差别，体积也毋庸置疑的更大。</li>\r\n	<li><strong>恢复速度更慢</strong>：AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。测试套件里为这种情况添加了测试： 它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的。</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h2>2、RDB持久化</h2>\r\n\r\n<p>RDB，就是把内存数据以快照的形式保存到磁盘上。和AOF相比，它记录的是某一时刻的数据，并不是操作。RDB持久化，是指在指定的时间间隔内，执行指定次数的写操作，将内存中的数据集快照写入磁盘中，它是Redis默认的持久化方式。执行完操作后，在指定目录下会生成一个dump.rdb文件，Redis 重启的时候，通过加载dump.rdb文件来恢复数据。</p>\r\n\r\n<p>rdb的优点：</p>\r\n\r\n<ul>\r\n	<li><strong>体积更小</strong>：相同的数据量rdb数据比aof的小，因为rdb是紧凑型文件。</li>\r\n	<li><strong>恢复更快</strong>：因为rdb是数据的快照，基本上就是数据的复制，不用重新读取再写入内存。</li>\r\n	<li><strong>性能更高</strong>：父进程在保存rdb时候只需要fork一个子进程，无需父进程的进行其他io操作，也保证了服务器的性能。</li>\r\n</ul>\r\n\r\n<p>rdb的缺点：</p>\r\n\r\n<ul>\r\n	<li><strong>故障丢失</strong>：因为rdb是全量的，我们一般是使用shell脚本实现30分钟或者1小时或者每天对redis进行rdb备份，（注，也可以是用自带的策略），但是最少也要5分钟进行一次的备份，所以当服务死掉后，最少也要丢失5分钟的数据。</li>\r\n	<li><strong>耐久性差</strong>：相对aof的异步策略来说，因为rdb的复制是全量的，即使是fork的子进程来进行备份，当数据量很大的时候对磁盘的消耗也是不可忽视的，尤其在访问量很高的时候，fork的时间也会延长，导致cpu吃紧，耐久性相对较差。</li>\r\n</ul>\r\n\r\n<h2>&nbsp;</h2>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 15:58:29', '2023-02-01 16:02:43', 0, NULL);
INSERT INTO `blog` VALUES (88, 1, '01', 1, 'Redis 内存优化', '<p>Redis 内存优化神技，小内存保存大数据：&nbsp;<a href=\"https://baijiahao.baidu.com/s?id=1738951143718592440&amp;wfr=spider&amp;for=pc\">https://baijiahao.baidu.com/s?id=1738951143718592440&amp;wfr=spider&amp;for=pc</a></p>\r\n\r\n<p>主要优化神技如下：</p>\r\n\r\n<ul>\r\n	<li>键值对优化；</li>\r\n	<li>小数据集合的编码优化；</li>\r\n	<li>使用对象共享池；</li>\r\n	<li>使用 Bit 比特位或 byte 级别操作</li>\r\n	<li>使用 hash 类型优化；</li>\r\n	<li>内存碎片优化；</li>\r\n	<li>使用 32 位的 Redis。</li>\r\n</ul>\r\n\r\n<h3>Redis 如何存储键值对</h3>\r\n\r\n<ul>\r\n	<li><strong>dict：</strong>最重要的属性之一，就是靠这个定义了保存了对象数据键值对，dcit 的底层结构是一个哈希表。</li>\r\n	<li><strong>expires：</strong>保存着所有 key 的过期信息.</li>\r\n	<li>blocking_keys 和 ready_keys 主要为了<em>实现 BLPOP 等阻塞命令</em></li>\r\n	<li>watched_keys用于实现watch命令，<em>记录正在被watch的一些key</em>，与事务相关。</li>\r\n	<li>id 为<em>当前数据库的id</em>，redis 支持单个服务多数据库，默认有16个；</li>\r\n	<li>clusterSlotToKeyMapping：cluster 模式下，存储key 与哈希槽映射关系的数组。</li>\r\n</ul>\r\n\r\n<p>Redis 使用「dict」结构来保存所有的键值对（key-value）数据，这是一个全局哈希表，所以对 key 的查询能以 O(1) 时间得到。</p>\r\n\r\n<p>所谓哈希表，我们可以类比 Java 中的 HashMap，其实就是一个数组，数组的每个元素叫做哈希桶。</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 16:31:44', '2023-02-01 16:31:44', 0, NULL);
INSERT INTO `blog` VALUES (89, 1, '02', 1, 'JVM', '<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/90\" target=\"_blank\">1.栈内存溢出</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/91\" target=\"_blank\">2.JVM内存模型</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/92\" target=\"_blank\">3.JVM内存分新生代，老年代，持久代。新生代中为什么要分为Eden和Survivor</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/93\" target=\"_blank\">4.一次完整的GC流程，对象如何晋升到老年代</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/94\" target=\"_blank\">5.垃圾收集器，各自的优缺点</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/95\" target=\"_blank\">6.JVM内存模型:重排序，内存屏障，happen-before，主内存，工作内存</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/96\" target=\"_blank\">7.类加载器，打破双亲委派。</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/97\" target=\"_blank\">8.主要的JVM参数</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/98\" target=\"_blank\">9.打出线程栈信息</a></li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2020-02-01 16:37:12', '2023-02-08 20:10:37', 0, NULL);
INSERT INTO `blog` VALUES (90, 1, '01', 1, 'jvm-1.栈内存溢出', '<h3>&nbsp; &nbsp;栈定义---为什么会溢出---相关配置参数</h3>\r\n\r\n<ul>\r\n	<li>栈是线程私有的，他的生命周期与线程相同，每个方法在执行的时候都会创建一个栈帧，用来存储局部变量表，操作数栈，动态链接，方法出口等信息。局部变量表又包含基本数据类型，对象引用类型</li>\r\n	<li>如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常，方法递归调用产生这种结果。</li>\r\n	<li>如果Java虚拟机栈可以动态扩展，并且扩展的动作已经尝试过，但是无法申请到足够的内存去完成扩展，或者在新建立线程的时候没有足够的内存去创建对应的虚拟机栈，那么Java虚拟机将抛出一个OutOfMemory 异常。(线程启动过多)</li>\r\n	<li>参数 -Xss 去调整JVM栈的大小</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-01 16:37:36', '2023-02-08 19:26:46', 0, NULL);
INSERT INTO `blog` VALUES (91, 1, '01', 1, 'jvm-2.JVM内存模型', '<p>JVM内存模型图---每个模块的定义，作用，以及可能会存在的问题，如栈溢出等。</p>\r\n\r\n<ul>\r\n	<li>程序计数器：当前线程所执行的字节码的行号指示器，用于记录正在执行的虚拟机字节指令地址，线程私有。</li>\r\n	<li>Java虚拟栈：存放基本数据类型、对象的引用、方法出口等，线程私有。</li>\r\n	<li>Native方法栈：和虚拟栈相似，只不过它服务于Native方法，线程私有。</li>\r\n	<li>Java堆：java内存最大的一块，所有对象实例、数组都存放在java堆，GC回收的地方，线程共享。</li>\r\n	<li>方法区：存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码数据等。（即永久带），回收目标主要是常量池的回收和类型的卸载，各线程共享</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-01 16:39:42', '2023-02-08 19:27:32', 0, NULL);
INSERT INTO `blog` VALUES (92, 1, '01', 1, 'jvm-3.JVM内存分新生代，老年代，持久代。新生代中为什么要分为Eden和Survivor', '<p><strong>思路：</strong>&nbsp;JAVA堆，新生代的划分，</p>\r\n\r\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 它们之间的转化，</p>\r\n\r\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 一些参数的配置（如： &ndash;XX:NewRatio，&ndash;XX:SurvivorRatio等），</p>\r\n\r\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 为什么要这样划分。</p>\r\n\r\n<p>1）共享内存区划分</p>\r\n\r\n<ul>\r\n	<li>共享内存区 = 持久带 + 堆</li>\r\n	<li>持久带 = 方法区 + 其他</li>\r\n	<li>Java堆 = 老年代 + 新生代</li>\r\n	<li>新生代 = Eden + S0 + S1</li>\r\n</ul>\r\n\r\n<p>2）一些参数的配置</p>\r\n\r\n<ul>\r\n	<li>默认的，新生代 ( Young ) 与老年代 ( Old ) 的比例的值为 1:2 ，可以通过参数 &ndash;XX:NewRatio 配置。</li>\r\n	<li>默认的，Edem : from : to = 8 : 1 : 1 ( 可以通过参数 &ndash;XX:SurvivorRatio 来设定)</li>\r\n	<li>Survivor区中的对象被复制次数为15(对应虚拟机参数 -XX:+MaxTenuringThreshold)</li>\r\n</ul>\r\n\r\n<p>3)为什么要分为Eden和Survivor?为什么要设置两个Survivor区？</p>\r\n\r\n<ul>\r\n	<li>如果没有Survivor，Eden区每进行一次Minor GC，存活的对象就会被送到老年代。老年代很快被填满，触发Major GC.老年代的内存空间远大于新生代，进行一次Full GC消耗的时间比Minor GC长得多,所以需要分为Eden和Survivor。</li>\r\n	<li>Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代。</li>\r\n	<li>设置两个Survivor区最大的好处就是解决了碎片化，刚刚新建的对象在Eden中，经历一次Minor GC，Eden中的存活对象就会被移动到第一块survivor space S0，Eden被清空；等Eden区再满了，就再触发一次Minor GC，Eden和S0中的存活对象又会被复制送入第二块survivor space S1（这个过程非常重要，因为这种复制算法保证了S1中来自S0和Eden两部分的存活对象占用连续的内存空间，避免了碎片化的发生）</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 16:45:48', '2023-02-08 19:28:20', 0, NULL);
INSERT INTO `blog` VALUES (93, 1, '01', 1, 'jvm-4.一次完整的GC流程，对象如何晋升到老年代', '<p>Java堆内存划分---Minor GC，Major GC，full GC，---它们之间转化流程。</p>\r\n\r\n<ul>\r\n	<li>Java堆 = 老年代 + 新生代</li>\r\n	<li>新生代 = Eden + S0 + S1</li>\r\n	<li>当 Eden 区的空间满了， Java虚拟机会触发一次 Minor GC，以收集新生代的垃圾，存活下来的对象，则会转移到 Survivor区。</li>\r\n	<li>大对象（需要大量连续内存空间的Java对象，如那种很长的字符串）直接进入老年态；</li>\r\n	<li>如果对象在Eden出生，并经过第一次Minor GC后仍然存活，并且被Survivor容纳的话，年龄设为1，每熬过一次Minor GC，年龄+1，若年龄超过一定限制（15），则被晋升到老年态。即长期存活的对象进入老年态。</li>\r\n	<li>老年代满了而无法容纳更多的对象，Minor GC 之后通常就会进行Full GC，Full GC 清理整个内存堆 &ndash; 包括年轻代和年老代。</li>\r\n	<li>Major GC 发生在老年代的GC，清理老年区，经常会伴随至少一次Minor GC，比Minor GC慢10倍以上。</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-01 16:48:50', '2023-02-08 19:29:01', 0, NULL);
INSERT INTO `blog` VALUES (94, 1, '01', 1, 'jvm-5.垃圾收集器，各自的优缺点', '<p>1）几种垃圾收集器：</p>\r\n\r\n<ul>\r\n	<li>Serial收集器： 单线程的收集器，收集垃圾时，必须stop the world，使用复制算法。</li>\r\n	<li>ParNew收集器： Serial收集器的多线程版本，也需要stop the world，复制算法。</li>\r\n	<li>Parallel Scavenge收集器： 新生代收集器，复制算法的收集器，并发的多线程收集器，目标是达到一个可控的吞吐量。如果虚拟机总共运行100分钟，其中垃圾花掉1分钟，吞吐量就是99%。</li>\r\n	<li>Serial Old收集器： 是Serial收集器的老年代版本，单线程收集器，使用标记整理算法。</li>\r\n	<li>Parallel Old收集器： 是Parallel Scavenge收集器的老年代版本，使用多线程，标记-整理算法。</li>\r\n	<li>CMS(Concurrent Mark Sweep) 收集器： 是一种以获得最短回收停顿时间为目标的收集器，标记清除算法，运作过程：初始标记，并发标记，重新标记，并发清除，收集结束会产生大量空间碎片。</li>\r\n	<li>G1收集器： 标记整理算法实现，运作流程主要包括以下：初始标记，并发标记，最终标记，筛选标记。不会产生空间碎片，可以精确地控制停顿。</li>\r\n</ul>\r\n\r\n<p>2）CMS收集器和G1收集器的区别：</p>\r\n\r\n<ul>\r\n	<li>CMS收集器是老年代的收集器，可以配合新生代的Serial和ParNew收集器一起使用；</li>\r\n	<li>G1收集器收集范围是老年代和新生代，不需要结合其他收集器使用；</li>\r\n	<li>CMS收集器以最小的停顿时间为目标的收集器；</li>\r\n	<li>G1收集器可预测垃圾回收的停顿时间</li>\r\n	<li>CMS收集器是使用&ldquo;标记-清除&rdquo;算法进行的垃圾回收，容易产生内存碎片</li>\r\n	<li>G1收集器使用的是&ldquo;标记-整理&rdquo;算法，进行了空间整合，降低了内存空间碎片。</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 16:53:42', '2023-02-08 19:29:36', 0, NULL);
INSERT INTO `blog` VALUES (95, 1, '01', 1, 'jvm-6.JVM内存模型:重排序，内存屏障，happen-before，主内存，工作内存', '<p>&nbsp;Java内存模型图，volatile</p>\r\n\r\n<p><img alt=\"\" src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS83LzIzLzE2YzFjMTk4MmUzNjA5YjE_aW1hZ2VWaWV3Mi8wL3cvMTI4MC9oLzk2MC9mb3JtYXQvd2VicC9pZ25vcmUtZXJyb3IvMQ?x-oss-process=image/format,png\" style=\"height:461px; width:500px\" /></p>\r\n\r\n<p>Java内存模型规定了<strong>所有的变量都存储在主内存</strong>中，<strong>每条线程还有自己的工作内存</strong>，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，<strong>线程对变量的所有操作都必须在工作内存中进行</strong>，而不能直接读写主内存。不同的线程之间<strong>也无法直接访问对方工作内存中的变量</strong>，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。<br />\r\n2）指令重排序。</p>\r\n\r\n<pre>\r\n<code>public class PossibleReordering {\r\nstatic int x = 0, y = 0;\r\nstatic int a = 0, b = 0;\r\n \r\npublic static void main(String[] args) throws InterruptedException {\r\n    Thread one = new Thread(new Runnable() {\r\n        public void run() {\r\n            a = 1;\r\n            x = b;\r\n        }\r\n    });\r\n \r\n    Thread other = new Thread(new Runnable() {\r\n        public void run() {\r\n            b = 1;\r\n            y = a;\r\n        }\r\n    });\r\n    one.start();other.start();\r\n    one.join();other.join();\r\n    System.out.println(“(” + x + “,” + y + “)”);\r\n}</code></pre>\r\n\r\n<p>运行结果可能为(1,0)、(0,1)或(1,1)，也可能是(0,0)。因为，在实际运行时，代码指令可能并不是严格按照代码语句顺序执行的。大多数现代微处理器都会采用将指令乱序执行（out-of-order execution，简称OoOE或OOE）的方法，在条件允许的情况下，直接运行当前有能力立即执行的后续指令，避开获取下一条指令所需数据时造成的等待3。通过乱序执行的技术，处理器可以大大提高执行效率。而这就是指令重排。</p>\r\n\r\n<p>3）内存屏障</p>\r\n\r\n<p>内存屏障，也叫内存栅栏，是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。</p>\r\n\r\n<ul>\r\n	<li>LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</li>\r\n	<li>StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。</li>\r\n	<li>LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</li>\r\n	<li>StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。 在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。</li>\r\n</ul>\r\n\r\n<p>4）happen-before原则</p>\r\n\r\n<ul>\r\n	<li>单线程happen-before原则：在同一个线程中，书写在前面的操作happen-before后面的操作。 锁的happen-before原则：同一个锁的unlock操作happen-before此锁的lock操作。</li>\r\n	<li>volatile的happen-before原则：对一个volatile变量的写操作happen-before对此变量的任意操作(当然也包括写操作了)。</li>\r\n	<li>happen-before的传递性原则：如果A操作 happen-before B操作，B操作happen-before C操作，那么A操作happen-before C操作。</li>\r\n	<li>线程启动的happen-before原则：同一个线程的start方法happen-before此线程的其它方法。</li>\r\n	<li>线程中断的happen-before原则 ：对线程interrupt方法的调用happen-before被中断线程的检测到中断发送的代码。</li>\r\n	<li>线程终结的happen-before原则： 线程中的所有操作都happen-before线程的终止检测。</li>\r\n	<li>对象创建的happen-before原则： 一个对象的初始化完成先于他的finalize方法调用。</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 16:58:29', '2023-02-08 19:30:46', 0, NULL);
INSERT INTO `blog` VALUES (96, 1, '01', 1, 'jvm-7.类加载器，打破双亲委派', '<p>什么是类加载器</p>\r\n\r\n<p>类加载器存在的意义</p>\r\n\r\n<p><strong>双亲委派模型</strong></p>\r\n\r\n<p>怎么打破双亲委派模型</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>1) 什么是类加载器？</p>\r\n\r\n<p><strong>类加载器</strong>&nbsp;就是根据指定全限定名称将class文件加载到JVM内存，转为Class对象。</p>\r\n\r\n<pre>\r\n<code>启动类加载器（Bootstrap ClassLoader）：由C++语言实现（针对HotSpot）,负责将存放在&lt;JAVA_HOME&gt;\\lib目录或-Xbootclasspath参数指定的路径中的类库加载到内存中。\r\n其他类加载器：由Java语言实现，继承自抽象类ClassLoader。如：\r\n扩展类加载器（Extension ClassLoader）：负责加载&lt;JAVA_HOME&gt;\\lib\\ext目录或java.ext.dirs系统变量指定的路径中的所有类库。\r\n应用程序类加载器（Application ClassLoader）。负责加载用户类路径（classpath）上的指定类库，我们可以直接使用这个类加载器。一般情况，如果我们没有自定义类加载器默认就是用这个加载器。</code></pre>\r\n\r\n<p>2）双亲委派模型</p>\r\n\r\n<p>双亲委派模型工作过程是：</p>\r\n\r\n<p>如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。每个类加载器都是如此，只有当父加载器在自己的搜索范围内找不到指定的类时（即ClassNotFoundException），子加载器才会尝试自己去加载。</p>\r\n\r\n<p><img alt=\"\" src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS83LzIzLzE2YzFjNTRjZjRhZDg4NmI_aW1hZ2VWaWV3Mi8wL3cvMTI4MC9oLzk2MC9mb3JtYXQvd2VicC9pZ25vcmUtZXJyb3IvMQ?x-oss-process=image/format,png\" style=\"height:394px; width:500px\" /></p>\r\n\r\n<p>3）为什么需要双亲委派模型？</p>\r\n\r\n<p>在这里，先想一下，如果没有双亲委派，那么用户是不是可以自己定义一个java.lang.Object的同名类，java.lang.String的同名类，并把它放到ClassPath中,<strong>那么类之间的比较结果及类的唯一性将无法保证</strong>，因此，为什么需要双亲委派模型？<strong>防止内存中出现多份同样的字节码</strong></p>\r\n\r\n<p>4）怎么打破双亲委派模型？</p>\r\n\r\n<p>打破双亲委派机制则不仅<strong>要继承ClassLoader</strong>类，还要<strong>重写loadClass和findClass</strong>方法。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:02:29', '2023-02-08 19:31:39', 0, NULL);
INSERT INTO `blog` VALUES (97, 1, '01', 1, 'jvm-8.主要的JVM参数', '<p>堆栈配置相关</p>\r\n\r\n<p>垃圾收集器相关</p>\r\n\r\n<p>辅助信息相关</p>\r\n\r\n<p>1）堆栈配置相关</p>\r\n\r\n<pre>\r\n<code>java -Xmx3550m -Xms3550m -Xmn2g -Xss128k \r\n-XX:MaxPermSize=16m -XX:NewRatio=4 -XX:SurvivorRatio=4 -XX:MaxTenuringThreshold=0</code></pre>\r\n\r\n<p><br />\r\n-Xmx3550m： 最大堆大小为3550m。</p>\r\n\r\n<p>-Xms3550m： 设置初始堆大小为3550m。</p>\r\n\r\n<p>-Xmn2g： 设置年轻代大小为2g。</p>\r\n\r\n<p>-Xss128k： 每个线程的堆栈大小为128k。</p>\r\n\r\n<p>-XX:MaxPermSize： 设置持久代大小为16m</p>\r\n\r\n<p>-XX:NewRatio=4: 设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。</p>\r\n\r\n<p>-XX:SurvivorRatio=4： 设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6</p>\r\n\r\n<p>-XX:MaxTenuringThreshold=0： 设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。</p>\r\n\r\n<p>2）垃圾收集器相关</p>\r\n\r\n<pre>\r\n<code>-XX:+UseParallelGC\r\n-XX:ParallelGCThreads=20\r\n-XX:+UseConcMarkSweepGC \r\n-XX:CMSFullGCsBeforeCompaction=5\r\n-XX:+UseCMSCompactAtFullCollection：</code></pre>\r\n\r\n<p>-XX:+UseParallelGC： 选择垃圾收集器为并行收集器。</p>\r\n\r\n<p>-XX:ParallelGCThreads=20： 配置并行收集器的线程数</p>\r\n\r\n<p>-XX:+UseConcMarkSweepGC： 设置年老代为并发收集。</p>\r\n\r\n<p>-XX:CMSFullGCsBeforeCompaction：由于并发收集器不对内存空间进行压缩、整理，所以运行一段时间以后会产生&ldquo;碎片&rdquo;，使得运行效率降低。此值设置运行多少次GC以后对内存空间进行压缩、整理。</p>\r\n\r\n<p>-XX:+UseCMSCompactAtFullCollection： 打开对年老代的压缩。可能会影响性能，但是可以消除碎片</p>\r\n\r\n<p>3）辅助信息相关</p>\r\n\r\n<pre>\r\n<code>-XX:+PrintGC\r\n-XX:+PrintGCDetails</code></pre>\r\n\r\n<p>-XX:+PrintGC 输出形式:</p>\r\n\r\n<p>[GC 118250K-&gt;113543K(130112K), 0.0094143 secs] [Full GC 121376K-&gt;10414K(130112K), 0.0650971 secs]</p>\r\n\r\n<p>-XX:+PrintGCDetails 输出形式:</p>\r\n\r\n<p>[GC [DefNew: 8614K-&gt;781K(9088K), 0.0123035 secs] 118250K-&gt;113543K(130112K), 0.0124633 secs] [GC [DefNew: 8614K-&gt;8614K(9088K), 0.0000665 secs][Tenured: 112761K-&gt;10414K(121024K), 0.0433488 secs] 121376K-&gt;10414K(130112K), 0.0436268 secs<br />\r\n&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:05:07', '2023-02-08 19:32:09', 0, NULL);
INSERT INTO `blog` VALUES (98, 1, '01', 1, 'jvm-9.怎么打出线程栈信息', '<p>jps，top ，jstack这几个命令</p>\r\n\r\n<ul>\r\n	<li>输入jps，获得进程号。</li>\r\n	<li>top -Hp pid 获取本进程中所有线程的CPU耗时性能</li>\r\n	<li>jstack pid命令查看当前java进程的堆栈状态</li>\r\n	<li>或者 jstack -l &gt; /tmp/output.txt 把堆栈信息打到一个txt文件。</li>\r\n	<li>可以使用fastthread 堆栈定位，fastthread.io/<br />\r\n	&nbsp;</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:06:06', '2023-02-08 19:32:34', 0, NULL);
INSERT INTO `blog` VALUES (99, 1, '01', 1, 'jvm-10.强引用、软引用、弱引用、虚引用的区别', '<p>1）强引用</p>\r\n\r\n<p>我们平时new了一个对象就是强引用，例如 Object obj = new Object();即使在内存不足的情况下，JVM宁愿抛出OutOfMemory错误也不会回收这种对象。</p>\r\n\r\n<p>2）软引用</p>\r\n\r\n<p>如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。</p>\r\n\r\n<pre>\r\n<code>SoftReference&lt;String&gt; softRef=new SoftReference&lt;String&gt;(str);     // 软引用</code></pre>\r\n\r\n<p>用处： 软引用在实际中有重要的应用，例如浏览器的后退按钮。按后退时，这个后退时显示的网页内容是重新进行请求还是从缓存中取出呢？这就要看具体的实现策略了。</p>\r\n\r\n<p>（1）如果一个网页在浏览结束时就进行内容的回收，则按后退查看前面浏览过的页面时，需要重新构建</p>\r\n\r\n<p>（2）如果将浏览过的网页存储到内存中会造成内存的大量浪费，甚至会造成内存溢出<br />\r\n&nbsp;</p>\r\n\r\n<pre>\r\n<code>Browser prev = new Browser();               // 获取页面进行浏览\r\nSoftReference sr = new SoftReference(prev); // 浏览完毕后置为软引用        \r\nif(sr.get()!=null){ \r\n    rev = (Browser) sr.get();           // 还没有被回收器回收，直接获取\r\n}else{\r\n    prev = new Browser();               // 由于内存吃紧，所以对软引用的对象回收了\r\n    sr = new SoftReference(prev);       // 重新构建\r\n}</code></pre>\r\n\r\n<p>3）弱引用</p>\r\n\r\n<p>具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。</p>\r\n\r\n<pre>\r\n<code>String str=new String(\"abc\");    \r\nWeakReference&lt;String&gt; abcWeakRef = new WeakReference&lt;String&gt;(str);\r\nstr=null;\r\n等价于\r\nstr = null;\r\nSystem.gc();</code></pre>\r\n\r\n<p>4）虚引用</p>\r\n\r\n<p>如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用主要用来跟踪对象被垃圾回收器回收的活动。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:11:10', '2023-02-08 19:33:01', 0, NULL);
INSERT INTO `blog` VALUES (100, 0, '01', 1, 'jvm-11.JVM知识点精华汇总', '<p><img alt=\"\" src=\"https://img-blog.csdn.net/20180808112156511?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2h1eXV5YW5nNjY4OA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" /><img alt=\"\" src=\"https://img-blog.csdn.net/20180808112156511?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2h1eXV5YW5nNjY4OA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70\" /><img alt=\"\" src=\"/blog/202302/1_20230201171435.png\" /></p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:12:38', '2023-02-08 19:33:33', 0, NULL);
INSERT INTO `blog` VALUES (101, 1, '01', 1, '算法-字符串 s 中找出第一个只出现一次的字符', '<p>在字符串 s 中找出第一个只出现一次的字符。如果没有，返回一个单空格。 s 只包含小写字母。</p>\r\n\r\n<p>例如 &nbsp;: s = &quot;abaccdeff&quot; &nbsp;(可以写多种实现方法 , 越多越好)</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<pre>\r\n<code>package com.jfinal.admin.test;\r\n\r\nimport java.util.HashMap;\r\nimport java.util.LinkedHashMap;\r\nimport java.util.Map;\r\n\r\nimport com.jfinal.admin.util.StrUtil;\r\n\r\npublic class FirstS {\r\n\r\n	public static void main(String[] args) {\r\n		String s = \"abaccdeff\";\r\n		System.err.println(firstUniqHashMap(s));\r\n		System.err.println(firstUniqLinkedHashMap(s));\r\n	}\r\n\r\n	// 有序哈希，统计数量，遍历哈希map找出现一次的即可\r\n	public static char firstUniqLinkedHashMap(String s) {\r\n		if (StrUtil.isEmpty(s)) {// 判断字符串是否是空\r\n			return \' \';\r\n		}\r\n		Map&lt;Character, Integer&gt; map = new LinkedHashMap&lt;Character, Integer&gt;();\r\n		for (int i = 0; i &lt; s.length(); i++) {\r\n			char ch = s.charAt(i);\r\n			if (map.containsKey(s.charAt(i))) {\r\n				map.put(ch, map.get(ch) + 1);\r\n			} else {\r\n				map.put(ch, 1);\r\n			}\r\n		}\r\n		for (Map.Entry&lt;Character, Integer&gt; entry : map.entrySet()) {\r\n			if (entry.getValue() == 1) {\r\n				return entry.getKey();\r\n			}\r\n		}\r\n		return \' \';\r\n	}\r\n\r\n	// 普通哈希表，先统计数量，再遍历s,对比出现的次数\r\n	public static char firstUniqHashMap(String s) {\r\n		if (StrUtil.isEmpty(s)) {\r\n			return \' \';\r\n		}\r\n		Map&lt;Character, Integer&gt; charCountMap = new HashMap&lt;Character, Integer&gt;();\r\n		for (int i = 0; i &lt; s.length(); i++) {\r\n			char ch = s.charAt(i);\r\n			if (charCountMap.containsKey(ch)) {\r\n				charCountMap.put(ch, charCountMap.get(ch) + 1);\r\n			} else {\r\n				charCountMap.put(ch, 1);\r\n			}\r\n		}\r\n		for (int i = 0; i &lt; s.length(); i++) {\r\n			if (charCountMap.get(s.charAt(i)) == 1) {\r\n				return s.charAt(i);\r\n			}\r\n		}\r\n		return \' \';\r\n	}\r\n\r\n}\r\n</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:42:20', '2023-02-01 17:42:20', 0, NULL);
INSERT INTO `blog` VALUES (102, 1, '01', 1, '算法- 两数之和', '<p>方法一：暴力枚举<br />\r\n思路及算法</p>\r\n\r\n<p>最容易想到的方法是枚举数组中的每一个数 x，寻找数组中是否存在 target - x。</p>\r\n\r\n<p>当我们使用遍历整个数组的方式寻找 target - x 时，需要注意到每一个位于 x 之前的元素都已经和 x 匹配过，因此不需要再进行匹配。而每一个元素不能被使用两次，所以我们只需要在 x 后面的元素中寻找 target - x。</p>\r\n\r\n<pre>\r\n<code>class Solution {\r\n    public int[] twoSum(int[] nums, int target) {\r\n        int n = nums.length;\r\n        for (int i = 0; i &lt; n; ++i) {\r\n            for (int j = i + 1; j &lt; n; ++j) {\r\n                if (nums[i] + nums[j] == target) {\r\n                    return new int[]{i, j};\r\n                }\r\n            }\r\n        }\r\n        return new int[0];\r\n    }\r\n}</code></pre>\r\n\r\n<p>复杂度分析</p>\r\n\r\n<p>时间复杂度：O(N^2)，其中 NN 是数组中的元素数量。最坏情况下数组中任意两个数都要被匹配一次。</p>\r\n\r\n<p>空间复杂度：O(1)。</p>\r\n\r\n<p>方法二：哈希表<br />\r\n思路及算法</p>\r\n\r\n<p>注意到方法一的时间复杂度较高的原因是寻找 target - x 的时间复杂度过高。因此，我们需要一种更优秀的方法，能够快速寻找数组中是否存在目标元素。如果存在，我们需要找出它的索引。</p>\r\n\r\n<p>使用哈希表，可以将寻找 target - x 的时间复杂度降低到从 O(N)O(N) 降低到 O(1)O(1)。</p>\r\n\r\n<p>这样我们创建一个哈希表，对于每一个 x，我们首先查询哈希表中是否存在 target - x，然后将 x 插入到哈希表中，即可保证不会让 x 和自己匹配。</p>\r\n\r\n<p>代码</p>\r\n\r\n<pre>\r\n<code>class Solution {\r\n    public int[] twoSum(int[] nums, int target) {\r\n        Map&lt;Integer, Integer&gt; hashtable = new HashMap&lt;Integer, Integer&gt;();\r\n        for (int i = 0; i &lt; nums.length; ++i) {\r\n            if (hashtable.containsKey(target - nums[i])) {\r\n                return new int[]{hashtable.get(target - nums[i]), i};\r\n            }\r\n            hashtable.put(nums[i], i);\r\n        }\r\n        return new int[0];\r\n    }\r\n}\r\n</code></pre>\r\n\r\n<p>复杂度分析</p>\r\n\r\n<p>时间复杂度：O(N)，其中 NN 是数组中的元素数量。对于每一个元素 x，我们可以 O(1)O(1) 地寻找 target - x。</p>\r\n\r\n<p>空间复杂度：O(N)，其中 NN 是数组中的元素数量。主要为哈希表的开销。</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:42:36', '2023-02-01 17:44:56', 0, NULL);
INSERT INTO `blog` VALUES (103, 1, '01', 1, '算法', '<p><a href=\"http://sunnannan.com/blog/101\" target=\"_blank\">算法-字符串 s 中找出第一个只出现一次的字符</a></p>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/102\" target=\"_blank\">算法- 两数之和</a></p>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/104\" target=\"_blank\">算法-两数相加</a></p>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/105\" target=\"_blank\">算法-无重复字符的最长子串</a></p>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/106\" target=\"_blank\">算法-寻找两个正序数组的中位数</a></p>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/107\" target=\"_blank\">算法： 最长回文子串</a></p>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/108\" target=\"_blank\">算法-整数反转</a></p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:45:00', '2023-02-01 18:04:06', 0, NULL);
INSERT INTO `blog` VALUES (104, 1, '01', 1, '算法-两数相加', '<p>给你两个&nbsp;非空 的链表，表示两个非负的整数。它们每位数字都是按照&nbsp;逆序&nbsp;的方式存储的，并且每个节点只能存储&nbsp;一位&nbsp;数字。</p>\r\n\r\n<p>请你将两个数相加，并以相同形式返回一个表示和的链表。</p>\r\n\r\n<p>你可以假设除了数字 0 之外，这两个数都不会以 0&nbsp;开头。</p>\r\n\r\n<p>方法一：模拟<br />\r\n思路与算法：<strong>由于输入的两个链表都是逆序存储数字的位数的，因此两个链表中同一位置的数字可以直接相加。</strong></p>\r\n\r\n<p>我们同时遍历两个链表，逐位计算它们的和，并与当前位置的进位值相加。具体而言，如果当前两个链表处相应位置的数字为 n1,n2n1,n2，进位值为 \\textit{carry}carry，则它们的和为 n1+n2+\\textit{carry}n1+n2+carry；其中，答案链表处相应位置的数字为 (n1+n2+\\textit{carry}) \\bmod 10(n1+n2+carry)mod10，而新的进位值为 \\lfloor\\frac{n1+n2+\\textit{carry}}{10}\\rfloor&lfloor;&nbsp;<br />\r\n10<br />\r\nn1+n2+carry<br />\r\n&nbsp;&rfloor;。</p>\r\n\r\n<p>如果两个链表的长度不同，则可以认为长度短的链表的后面有若干个 00 。</p>\r\n\r\n<p>此外，如果链表遍历结束后，有 \\textit{carry} &gt; 0carry&gt;0，还需要在答案链表的后面附加一个节点，节点的值为 \\textit{carry}carry。</p>\r\n\r\n<pre>\r\n<code>class Solution {\r\n    public ListNode addTwoNumbers(ListNode l1, ListNode l2) {\r\n        ListNode head = null, tail = null;\r\n        int carry = 0;\r\n        while (l1 != null || l2 != null) {\r\n            int n1 = l1 != null ? l1.val : 0;\r\n            int n2 = l2 != null ? l2.val : 0;\r\n            int sum = n1 + n2 + carry;\r\n            if (head == null) {\r\n                head = tail = new ListNode(sum % 10);\r\n            } else {\r\n                tail.next = new ListNode(sum % 10);\r\n                tail = tail.next;\r\n            }\r\n            carry = sum / 10;\r\n            if (l1 != null) {\r\n                l1 = l1.next;\r\n            }\r\n            if (l2 != null) {\r\n                l2 = l2.next;\r\n            }\r\n        }\r\n        if (carry &gt; 0) {\r\n            tail.next = new ListNode(carry);\r\n        }\r\n        return head;\r\n    }\r\n}\r\n</code></pre>\r\n\r\n<p>复杂度分析</p>\r\n\r\n<p>时间复杂度：O(\\max(m,n))O(max(m,n))，其中 mm 和 nn 分别为两个链表的长度。我们要遍历两个链表的全部位置，而处理每个位置只需要 O(1)O(1) 的时间。</p>\r\n\r\n<p>空间复杂度：O(1)O(1)。注意返回值不计入空间复杂度。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:48:22', '2023-02-01 17:48:22', 0, NULL);
INSERT INTO `blog` VALUES (105, 1, '01', 1, '算法-无重复字符的最长子串', '<pre>\r\n<strong>输入: </strong>s = &quot;abcabcbb&quot;\r\n<strong>输出: </strong>3 \r\n<strong>解释:</strong> 因为无重复字符的最长子串是 <code>&quot;abc&quot;，所以其</code>长度为 3</pre>\r\n\r\n<p>应该左侧指针固定，移动右侧指针，当窗口内最右侧的字符在set中存在时，左侧指针移动并从set中移除原左侧指针对应的字符，这样再取窗口长度的最大值即可</p>\r\n\r\n<pre>\r\n<code>public int lengthOfLongestSubstring(String s) {\r\n    	java.util.Set&lt;Character&gt; set = new java.util.HashSet&lt;Character&gt;();\r\n    	int left = 0;\r\n    	int right = 0;\r\n    	int max = 0;\r\n    	for(;right&lt;s.length();right++) {\r\n    		char ch = s.charAt(right);\r\n    		while(set.contains(ch)) {\r\n    			set.remove(s.charAt(left));\r\n    			left++;\r\n    		}\r\n    		set.add(ch);\r\n    		max = Math.max(max, right-left+1);\r\n    	}\r\n    	return max;\r\n    }</code></pre>\r\n\r\n<p>官方</p>\r\n\r\n<pre>\r\n<code>class Solution {\r\n    public int lengthOfLongestSubstring(String s) {\r\n        // 哈希集合，记录每个字符是否出现过\r\n        Set&lt;Character&gt; occ = new HashSet&lt;Character&gt;();\r\n        int n = s.length();\r\n        // 右指针，初始值为 -1，相当于我们在字符串的左边界的左侧，还没有开始移动\r\n        int rk = -1, ans = 0;\r\n        for (int i = 0; i &lt; n; ++i) {\r\n            if (i != 0) {\r\n                // 左指针向右移动一格，移除一个字符\r\n                occ.remove(s.charAt(i - 1));\r\n            }\r\n            while (rk + 1 &lt; n &amp;&amp; !occ.contains(s.charAt(rk + 1))) {\r\n                // 不断地移动右指针\r\n                occ.add(s.charAt(rk + 1));\r\n                ++rk;\r\n            }\r\n            // 第 i 到 rk 个字符是一个极长的无重复字符子串\r\n            ans = Math.max(ans, rk - i + 1);\r\n        }\r\n        return ans;\r\n    }\r\n}</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:51:34', '2023-02-01 17:51:34', 0, NULL);
INSERT INTO `blog` VALUES (106, 1, '01', 1, '算法-寻找两个正序数组的中位数', '<p>给定两个大小分别为 m 和 n 的正序（从小到大）数组&nbsp;nums1 和&nbsp;nums2。请你找出并返回这两个正序数组的 中位数 。</p>\r\n\r\n<p>算法的时间复杂度应该为 O(log (m+n)) 。</p>\r\n\r\n<p>示例 1：</p>\r\n\r\n<p>输入：nums1 = [1,3], nums2 = [2]<br />\r\n输出：2.00000<br />\r\n解释：合并数组 = [1,2,3] ，中位数 2</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h3>解法一</h3>\r\n\r\n<p>简单粗暴，先将两个数组合并，两个有序数组的合并也是归并排序中的一部分。然后根据奇数，还是偶数，返回中位数。</p>\r\n\r\n<pre>\r\n<code>public double findMedianSortedArrays(int[] nums1, int[] nums2) {\r\n    int[] nums;\r\n    int m = nums1.length;\r\n    int n = nums2.length;\r\n    nums = new int[m + n];\r\n    if (m == 0) {\r\n        if (n % 2 == 0) {\r\n            return (nums2[n / 2 - 1] + nums2[n / 2]) / 2.0;\r\n        } else {\r\n\r\n            return nums2[n / 2];\r\n        }\r\n    }\r\n    if (n == 0) {\r\n        if (m % 2 == 0) {\r\n            return (nums1[m / 2 - 1] + nums1[m / 2]) / 2.0;\r\n        } else {\r\n            return nums1[m / 2];\r\n        }\r\n    }\r\n\r\n    int count = 0;\r\n    int i = 0, j = 0;\r\n    while (count != (m + n)) {\r\n        if (i == m) {\r\n            while (j != n) {\r\n                nums[count++] = nums2[j++];\r\n            }\r\n            break;\r\n        }\r\n        if (j == n) {\r\n            while (i != m) {\r\n                nums[count++] = nums1[i++];\r\n            }\r\n            break;\r\n        }\r\n\r\n        if (nums1[i] &lt; nums2[j]) {\r\n            nums[count++] = nums1[i++];\r\n        } else {\r\n            nums[count++] = nums2[j++];\r\n        }\r\n    }\r\n\r\n    if (count % 2 == 0) {\r\n        return (nums[count / 2 - 1] + nums[count / 2]) / 2.0;\r\n    } else {\r\n        return nums[count / 2];\r\n    }\r\n}\r\n</code></pre>\r\n\r\n<h3>解法二</h3>\r\n\r\n<pre>\r\n<code>public double findMedianSortedArrays(int[] A, int[] B) {\r\n    int m = A.length;\r\n    int n = B.length;\r\n    int len = m + n;\r\n    int left = -1, right = -1;\r\n    int aStart = 0, bStart = 0;\r\n    for (int i = 0; i &lt;= len / 2; i++) {\r\n        left = right;\r\n        if (aStart &lt; m &amp;&amp; (bStart &gt;= n || A[aStart] &lt; B[bStart])) {\r\n            right = A[aStart++];\r\n        } else {\r\n            right = B[bStart++];\r\n        }\r\n    }\r\n    if ((len &amp; 1) == 0)\r\n        return (left + right) / 2.0;\r\n    else\r\n        return right;\r\n}</code></pre>\r\n\r\n<h3>解法三</h3>\r\n\r\n<pre>\r\n<code>public double findMedianSortedArrays(int[] nums1, int[] nums2) {\r\n    int n = nums1.length;\r\n    int m = nums2.length;\r\n    int left = (n + m + 1) / 2;\r\n    int right = (n + m + 2) / 2;\r\n    //将偶数和奇数的情况合并，如果是奇数，会求两次同样的 k 。\r\n    return (getKth(nums1, 0, n - 1, nums2, 0, m - 1, left) + getKth(nums1, 0, n - 1, nums2, 0, m - 1, right)) * 0.5;  \r\n}\r\n    \r\n    private int getKth(int[] nums1, int start1, int end1, int[] nums2, int start2, int end2, int k) {\r\n        int len1 = end1 - start1 + 1;\r\n        int len2 = end2 - start2 + 1;\r\n        //让 len1 的长度小于 len2，这样就能保证如果有数组空了，一定是 len1 \r\n        if (len1 &gt; len2) return getKth(nums2, start2, end2, nums1, start1, end1, k);\r\n        if (len1 == 0) return nums2[start2 + k - 1];\r\n\r\n        if (k == 1) return Math.min(nums1[start1], nums2[start2]);\r\n\r\n        int i = start1 + Math.min(len1, k / 2) - 1;\r\n        int j = start2 + Math.min(len2, k / 2) - 1;\r\n\r\n        if (nums1[i] &gt; nums2[j]) {\r\n            return getKth(nums1, start1, end1, nums2, j + 1, end2, k - (j - start2 + 1));\r\n        }\r\n        else {\r\n            return getKth(nums1, i + 1, end1, nums2, start2, end2, k - (i - start1 + 1));\r\n        }\r\n    }\r\n</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:54:52', '2023-02-01 17:54:52', 0, NULL);
INSERT INTO `blog` VALUES (107, 1, '01', 1, '算法： 最长回文子串', '<p>给你一个字符串&nbsp;<code>s</code>，找到&nbsp;<code>s</code>&nbsp;中最长的回文子串。</p>\r\n\r\n<p>如果字符串的反序与原始字符串相同，则该字符串称为回文字符串。</p>\r\n\r\n<pre>\r\n<strong>输入：</strong>s = &quot;babad&quot;\r\n<strong>输出：</strong>&quot;bab&quot;\r\n<strong>解释：</strong>&quot;aba&quot; 同样是符合题意的答案。</pre>\r\n\r\n<p>方法1:</p>\r\n\r\n<pre>\r\n<code>public boolean isPalindromic(String s) {\r\n		int len = s.length();\r\n		for (int i = 0; i &lt; len / 2; i++) {\r\n			if (s.charAt(i) != s.charAt(len - i - 1)) {\r\n				return false;\r\n			}\r\n		}\r\n		return true;\r\n	}\r\n\r\n// 暴力解法\r\npublic String longestPalindrome(String s) {\r\n    String ans = \"\";\r\n    int max = 0;\r\n    int len = s.length();\r\n    for (int i = 0; i &lt; len; i++)\r\n        for (int j = i + 1; j &lt;= len; j++) {\r\n            String test = s.substring(i, j);\r\n            if (isPalindromic(test) &amp;&amp; test.length() &gt; max) {\r\n                ans = s.substring(i, j);\r\n                max = Math.max(max, ans.length());\r\n            }\r\n        }\r\n    return ans;\r\n}\r\n</code></pre>\r\n\r\n<p>方法2:</p>\r\n\r\n<p>先求：最长公共子串</p>\r\n\r\n<p>我们求出最长公共子串后，并不一定是回文串，我们还需要判断该字符串倒置前的下标和当前的字符串下标是不是匹配。</p>\r\n\r\n<pre>\r\n<code>public String longestPalindrome(String s) {\r\n    if (s.equals(\"\"))\r\n        return \"\";\r\n    String origin = s;\r\n    String reverse = new StringBuffer(s).reverse().toString(); //字符串倒置\r\n    int length = s.length();\r\n    int[][] arr = new int[length][length];\r\n    int maxLen = 0;\r\n    int maxEnd = 0;\r\n    for (int i = 0; i &lt; length; i++)\r\n        for (int j = 0; j &lt; length; j++) {\r\n            if (origin.charAt(i) == reverse.charAt(j)) {\r\n                if (i == 0 || j == 0) {\r\n                    arr[i][j] = 1;\r\n                } else {\r\n                    arr[i][j] = arr[i - 1][j - 1] + 1;\r\n                }\r\n            }\r\n            if (arr[i][j] &gt; maxLen) { \r\n                maxLen = arr[i][j];\r\n                maxEnd = i; //以 i 位置结尾的字符\r\n            }\r\n\r\n        }\r\n	}\r\n	return s.substring(maxEnd - maxLen + 1, maxEnd + 1);\r\n}\r\n</code></pre>\r\n\r\n<p>&nbsp;代码的话，在上边的基础上，保存&nbsp;<code>maxLen</code>&nbsp;前判断一下下标匹不匹配就可以了。</p>\r\n\r\n<pre>\r\n<code>public String longestPalindrome(String s) {\r\n    if (s.equals(\"\"))\r\n        return \"\";\r\n    String origin = s;\r\n    String reverse = new StringBuffer(s).reverse().toString();\r\n    int length = s.length();\r\n    int[][] arr = new int[length][length];\r\n    int maxLen = 0;\r\n    int maxEnd = 0;\r\n    for (int i = 0; i &lt; length; i++)\r\n        for (int j = 0; j &lt; length; j++) {\r\n            if (origin.charAt(i) == reverse.charAt(j)) {\r\n                if (i == 0 || j == 0) {\r\n                    arr[i][j] = 1;\r\n                } else {\r\n                    arr[i][j] = arr[i - 1][j - 1] + 1;\r\n                }\r\n            }\r\n            /**********修改的地方*******************/\r\n            if (arr[i][j] &gt; maxLen) {\r\n                int beforeRev = length - 1 - j;\r\n                if (beforeRev + arr[i][j] - 1 == i) { //判断下标是否对应\r\n                    maxLen = arr[i][j];\r\n                    maxEnd = i;\r\n                }\r\n                /*************************************/\r\n            }\r\n        }\r\n    return s.substring(maxEnd - maxLen + 1, maxEnd + 1);\r\n}\r\n</code></pre>\r\n\r\n<p>方法三：</p>\r\n\r\n<pre>\r\n<code>public class Solution {\r\n\r\n    public String longestPalindrome(String s) {\r\n        int len = s.length();\r\n        if (len &lt; 2) {\r\n            return s;\r\n        }\r\n\r\n        int maxLen = 1;\r\n        int begin = 0;\r\n        // dp[i][j] 表示 s[i..j] 是否是回文串\r\n        boolean[][] dp = new boolean[len][len];\r\n        // 初始化：所有长度为 1 的子串都是回文串\r\n        for (int i = 0; i &lt; len; i++) {\r\n            dp[i][i] = true;\r\n        }\r\n\r\n        char[] charArray = s.toCharArray();\r\n        // 递推开始\r\n        // 先枚举子串长度\r\n        for (int L = 2; L &lt;= len; L++) {\r\n            // 枚举左边界，左边界的上限设置可以宽松一些\r\n            for (int i = 0; i &lt; len; i++) {\r\n                // 由 L 和 i 可以确定右边界，即 j - i + 1 = L 得\r\n                int j = L + i - 1;\r\n                // 如果右边界越界，就可以退出当前循环\r\n                if (j &gt;= len) {\r\n                    break;\r\n                }\r\n\r\n                if (charArray[i] != charArray[j]) {\r\n                    dp[i][j] = false;\r\n                } else {\r\n                    if (j - i &lt; 3) {\r\n                        dp[i][j] = true;\r\n                    } else {\r\n                        dp[i][j] = dp[i + 1][j - 1];\r\n                    }\r\n                }\r\n\r\n                // 只要 dp[i][L] == true 成立，就表示子串 s[i..L] 是回文，此时记录回文长度和起始位置\r\n                if (dp[i][j] &amp;&amp; j - i + 1 &gt; maxLen) {\r\n                    maxLen = j - i + 1;\r\n                    begin = i;\r\n                }\r\n            }\r\n        }\r\n        return s.substring(begin, begin + maxLen);\r\n    }\r\n}</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-01 17:57:44', '2023-02-01 17:59:57', 0, NULL);
INSERT INTO `blog` VALUES (108, 1, '01', 1, '算法-整数反转', '<p>给你一个 32 位的有符号整数 x ，返回将 x 中的数字部分反转后的结果。</p>\r\n\r\n<p>如果反转后整数超过 32 位的有符号整数的范围&nbsp;[&minus;231,&nbsp;&nbsp;231&nbsp;&minus; 1] ，就返回 0。</p>\r\n\r\n<p>假设环境不允许存储 64 位整数（有符号或无符号）。<br />\r\n&nbsp;</p>\r\n\r\n<p>示例 1：</p>\r\n\r\n<p>输入：x = 123<br />\r\n输出：321<br />\r\n示例 2：</p>\r\n\r\n<p>输入：x = -123<br />\r\n输出：-321</p>\r\n\r\n<pre>\r\n<code>class Solution {\r\n    public int reverse(int x) {\r\n        int res = 0;\r\n        while(x!=0) {\r\n            //每次取末尾数字\r\n            int tmp = x%10;\r\n            //判断是否 大于 最大32位整数\r\n            if (res&gt;214748364 || (res==214748364 &amp;&amp; tmp&gt;7)) {\r\n                return 0;\r\n            }\r\n            //判断是否 小于 最小32位整数\r\n            if (res&lt;-214748364 || (res==-214748364 &amp;&amp; tmp&lt;-8)) {\r\n                return 0;\r\n            }\r\n            res = res*10 + tmp;\r\n            x /= 10;\r\n        }\r\n        return res;\r\n    }\r\n}			\r\n</code></pre>\r\n\r\n<table>\r\n	<thead>\r\n		<tr>\r\n			<th>题目</th>\r\n			<th>题解</th>\r\n			<th>难度等级</th>\r\n		</tr>\r\n	</thead>\r\n	<tbody>\r\n		<tr>\r\n			<td><a href=\"https://leetcode-cn.com/problems/reverse-integer/\" target=\"_blank\">整数反转</a></td>\r\n			<td><a href=\"https://leetcode-cn.com/problems/reverse-integer/solution/tu-jie-7-zheng-shu-fan-zhuan-by-wang_ni_ma/\" target=\"_blank\">链接</a></td>\r\n			<td>简单</td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"https://leetcode-cn.com/problems/palindrome-number/\" target=\"_blank\">回文数</a></td>\r\n			<td><a href=\"https://leetcode-cn.com/problems/palindrome-number/solution/chao-xiang-xi-tu-jie-san-chong-jie-fa-9-hui-wen-sh/\" target=\"_blank\">链接</a></td>\r\n			<td>简单</td>\r\n		</tr>\r\n		<tr>\r\n			<td><a href=\"https://leetcode-cn.com/problems/string-to-integer-atoi/\" target=\"_blank\">字符串转换整数 (atoi)</a></td>\r\n			<td><a href=\"https://leetcode-cn.com/problems/string-to-integer-atoi/solution/tu-jie-8-zi-fu-chuan-zhuan-huan-zheng-shu-atoi-by-/\" target=\"_blank\">链接</a></td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n', '', NULL, NULL, 0, '2023-02-01 18:02:27', '2023-02-01 18:02:27', 0, NULL);
INSERT INTO `blog` VALUES (109, 1, '01', 1, '消息中间件-选型', '<p><span style=\"font-size:16px\"><strong><a href=\"#a1\">消息中间件作用</a></strong></span></p>\r\n\r\n<p><span style=\"font-size:16px\"><strong><a href=\"#a2\">用消息队列哪些问题？</a></strong></span></p>\r\n\r\n<p><span style=\"font-size:16px\"><strong><a href=\"#a3\">消息队列技术选型</a></strong></span></p>\r\n\r\n<p><span style=\"font-size:16px\"><strong><a href=\"#a4\">为什么要用RocketMq？</a></strong></span></p>\r\n\r\n<p><a id=\"a1\" name=\"a1\">1. 消息中间件作用</a><br />\r\n设想一个场景：a系统同步调用b系统，b系统收到请求后进行处理，但是a系统并不关注b系统的出来结果，但该调用使得a系统存在并发瓶颈，所以我们需要一个支持a系统可靠异步调用b系统的方案，这个便是消息中间件。</p>\r\n\r\n<p>主要有以下三点用途</p>\r\n\r\n<ul>\r\n	<li>限流削峰：MQ可将系统超量请求暂存在队列中，避免系统因短时超量请求崩溃</li>\r\n	<li>异步解耦：同步调用会大大降低系统吞吐量及并发度，系统耦合度高，在两层间增加MQ层，实现同步至异步的转换，也实现了系统的解耦</li>\r\n	<li>数据收集：分布式系统产生海量的业务日志、监控数据、用户行为等数据，如需对这些数据进行采集，通过MQ可完成此类数据收集</li>\r\n</ul>\r\n\r\n<p><a id=\"a2\" name=\"a2\">2、用消息队列哪些问题？</a></p>\r\n\r\n<ul>\r\n	<li><strong>系统可用性降低：</strong> 系统可用性在某种程度上降低，为什么这样说呢？在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后你就需要去考虑了！</li>\r\n	<li><strong>系统复杂性提高：</strong> 加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！</li>\r\n	<li><strong>一致性问题：</strong> 我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了!</li>\r\n</ul>\r\n\r\n<p><a id=\"a3\" name=\"a3\">3、同类产品对比选型</a></p>\r\n\r\n<ul>\r\n	<li>ActiveMQ：老系统使用较多，目前项目使用较少，使用Java开发</li>\r\n	<li>RabbitMQ：吞吐量比Kafka与RocketMQ低，使用ErLang语言开发，如是Java团队，定制化开发难度较大</li>\r\n	<li>Kafka：高吞吐量，常用于大数据领域的实时计算、日志采集等场景，使用Java开发</li>\r\n	<li>RocketMQ：经过数年阿里双11考验，性能及稳定性非常高，使用Java开发</li>\r\n</ul>\r\n\r\n<p><a id=\"a4\" name=\"a4\"><strong>为什么要用RocketMq？</strong></a><br />\r\n总得来说，RocketMq具有以下几个优势：</p>\r\n\r\n<ul>\r\n	<li>吞吐量高：单机吞吐量可达十万级</li>\r\n	<li>可用性高：分布式架构</li>\r\n	<li>消息可靠性高：经过参数优化配置，消息可以做到0丢失</li>\r\n	<li>功能支持完善：MQ功能较为完善，还是分布式的，扩展性好</li>\r\n	<li>支持10亿级别的消息堆积：不会因为堆积导致性能下降</li>\r\n	<li>源码是java：方便我们查看源码了解它的每个环节的实现逻辑，并针对不同的业务场景进行扩展</li>\r\n	<li>可靠性高：天生为金融互联网领域而生，对于要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况</li>\r\n	<li>稳定性高：RoketMQ在上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-02 11:31:46', '2023-02-08 19:05:45', 0, NULL);
INSERT INTO `blog` VALUES (110, 0, '01', 1, 'rocketmq-QA', '<p><span style=\"font-size:18px\"><strong>Broker中的消息被消费后会立即删除吗？</strong></span></p>\r\n\r\n<p>不会，每条消息都会持久化到CommitLog中，每个Consumer连接到Broker后会维持消费进度信息，当有消息消费后只是当前Consumer的消费进度（CommitLog的offset）更新了。</p>\r\n\r\n<p>追问：那么消息会堆积吗？什么时候清理过期消息？<br />\r\n默认72小时后会删除不再使用的CommitLog文件</p>\r\n\r\n<p>检查这个文件最后访问时间<br />\r\n判断是否大于过期时间<br />\r\n指定时间删除，默认凌晨4点</p>\r\n\r\n<h1><span style=\"font-size:18px\"><strong>RocketMQ由哪些角色组成，每个角色作用和特点是什么？</strong></span></h1>\r\n\r\n<p>Nameserver 无状态，动态列表；这也是和zookeeper的重要区别之一。zookeeper是有状态的。<br />\r\nProducer 消息生产者，负责发消息到Broker。<br />\r\nBroker 就是MQ本身，负责收发消息、持久化消息等。<br />\r\nConsumer 消息消费者，负责从Broker上拉取消息进行消费，消费完进行ack。</p>\r\n\r\n<p><span style=\"font-size:18px\"><strong>为什么要用RocketMq？</strong></span><br />\r\n总得来说，RocketMq具有以下几个优势：</p>\r\n\r\n<p>吞吐量高：单机吞吐量可达十万级<br />\r\n可用性高：分布式架构<br />\r\n消息可靠性高：经过参数优化配置，消息可以做到0丢失<br />\r\n功能支持完善：MQ功能较为完善，还是分布式的，扩展性好<br />\r\n支持10亿级别的消息堆积：不会因为堆积导致性能下降<br />\r\n源码是java：方便我们查看源码了解它的每个环节的实现逻辑，并针对不同的业务场景进行扩展<br />\r\n可靠性高：天生为金融互联网领域而生，对于要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况<br />\r\n稳定性高：RoketMQ在上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验<br />\r\n&nbsp;</p>\r\n\r\n<p><span style=\"font-size:18px\"><strong>RocketMQ消费模式有几种？</strong></span></p>\r\n\r\n<p><span style=\"color:#e74c3c\">集群消费</span><br />\r\n一条消息只会被同Group中的一个Consumer消费<br />\r\n多个Group同时消费一个Topic时，每个Group都会有一个Consumer消费到数据<br />\r\n<span style=\"color:#e74c3c\">广播消费</span><br />\r\n消息将对一个Consumer Group下的各个Consumer实例都消费一遍。即使这些Consumer属于同一个Consumer Group，消息也会被Consumer Group中的每个Consumer都消费一次。<br />\r\n&nbsp;</p>\r\n\r\n<pre>\r\n<code>  /**\r\n     * 3. 设置消息模式，默认是CLUSTERING\r\n     * MessageModel.BROADCASTING 广播消费模式\r\n     * MessageModel.CLUSTERING   集群消费模式\r\n     */\r\n    consumer.setMessageModel(MessageModel.BROADCASTING);\r\n</code></pre>\r\n\r\n<h1><span style=\"font-size:18px\"><strong>消费消息是push还是pull？</strong></span></h1>\r\n\r\n<p>RocketMQ没有真正意义的push，都是pull，虽然有push类，但实际底层实现采用的是长轮询机制，即拉取方式。</p>\r\n\r\n<p>broker端属性 longPollingEnable 标记是否开启长轮询。默认开启</p>\r\n\r\n<p>追问：为什么要主动拉取消息而不使用事件监听方式？<br />\r\n事件驱动方式是建立好长连接，由事件（发送数据）的方式来实时推送。</p>\r\n\r\n<p>如果broker主动推送消息的话有可能push速度快，消费速度慢的情况，那么就会造成消息在consumer端堆积过多，同时又不能被其他consumer消费的情况。而pull的方式可以根据当前自身情况来pull，不会造成过多的压力而造成瓶颈。所以采取了pull的方式。</p>\r\n\r\n<pre>\r\n<code>// 1. 创建消费者（Pull）对象\r\nDefaultMQPullConsumer consumer = new DefaultMQPullConsumer(\"GROUP_TEST\");\r\n\r\n\r\n// 1. 创建消费者（Push）对象\r\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"GROUP_TEST\");\r\n</code></pre>\r\n\r\n<h1><span style=\"font-size:18px\"><strong>broker如何处理拉取请求的？ ----？？？</strong></span></h1>\r\n\r\n<p>Consumer首次请求Broker</p>\r\n\r\n<p>Broker中是否有符合条件的消息<br />\r\n有 -&gt;响应Consumer<br />\r\n等待下次Consumer的请求<br />\r\n没有<br />\r\nPullRequestHoldService 来Hold连接，每个5s执行一次检查pullRequestTable有没有消息，有的话立即推送<br />\r\n每隔1ms检查commitLog中是否有新消息，有的话写入到pullRequestTable<br />\r\n当有新消息的时候返回请求<br />\r\n挂起consumer的请求，即不断开连接，也不返回数据使用consumer的offset。</p>\r\n\r\n<h1><span style=\"font-size:18px\"><strong>RocketMQ如何做负载均衡？ ----？？？</strong></span></h1>\r\n\r\n<p><span style=\"font-size:11px\">1）producer发送消息的负载均衡：默认会轮询向Topic的所有queue发送消息，以达到消息平均落到不同的queue上；而由于queue可以落在不同的broker上，就可以发到不同broker上（当然也可以指定发送到某个特定的queue上）</span></p>\r\n\r\n<p><span style=\"font-size:11px\">2）consumer订阅消息的负载均衡：假设有5个队列，两个消费者，则第一个消费者消费3个队列，第二个则消费2个队列，以达到平均消费的效果。而需要注意的是，当consumer的数量大于队列的数量的话，根据rocketMq的机制，多出来的Consumer 不会去消费数据，因此建议consumer的数量小于或者等于queue的数量，避免不必要的浪费</span></p>\r\n\r\n<p><span style=\"font-size:11px\">通过Topic在多Broker中分布式存储实现。</span></p>\r\n\r\n<p><span style=\"font-size:11px\">producer端<br />\r\n发送端指定message queue发送消息到相应的broker，来达到写入时的负载均衡</span></p>\r\n\r\n<p><span style=\"font-size:11px\">提升写入吞吐量，当多个producer同时向一个broker写入数据的时候，性能会下降<br />\r\n消息分布在多broker中，为负载消费做准备<br />\r\n默认策略是随机选择：</span></p>\r\n\r\n<p><span style=\"font-size:11px\">producer维护一个index<br />\r\n每次取节点会自增<br />\r\nindex向所有broker个数取余<br />\r\n自带容错策略<br />\r\n其他实现：</span></p>\r\n\r\n<p><span style=\"font-size:11px\">SelectMessageQueueByHash<br />\r\nhash的是传入的args<br />\r\nSelectMessageQueueByRandom<br />\r\nSelectMessageQueueByMachineRoom 没有实现<br />\r\n也可以自定义实现MessageQueueSelector接口中的select方法</span></p>\r\n\r\n<p><span style=\"font-size:11px\">MessageQueue select(final List mqs, final Message msg, final Object arg);</span></p>\r\n\r\n<p><span style=\"font-size:11px\">consumer端<br />\r\n采用的是平均分配算法来进行负载均衡。</span></p>\r\n\r\n<p><span style=\"font-size:11px\">其他负载均衡算法</span></p>\r\n\r\n<p><span style=\"font-size:11px\">平均分配策略(默认)(AllocateMessageQueueAveragely) 环形分配策略(AllocateMessageQueueAveragelyByCircle) 手动配置分配策略(AllocateMessageQueueByConfig) 机房分配策略(AllocateMessageQueueByMachineRoom) 一致性哈希分配策略(AllocateMessageQueueConsistentHash) 靠近机房策略(AllocateMachineRoomNearby)</span></p>\r\n\r\n<p><span style=\"font-size:11px\">追问：当消费负载均衡consumer和queue不对等的时候会发生什么？<br />\r\nConsumer和queue会优先平均分配，如果Consumer少于queue的个数，则会存在部分Consumer消费多个queue的情况，如果Consumer等于queue的个数，那就是一个Consumer消费一个queue，如果Consumer个数大于queue的个数，那么会有部分Consumer空余出来，白白的浪费了。</span><br />\r\n<span style=\"font-size:18px\"><strong>消息重复消费</strong></span></p>\r\n\r\n<p><span style=\"font-size:12px\">影响消息正常发送和消费的重要原因是网络的不确定性。</span></p>\r\n\r\n<p><span style=\"font-size:12px\">引起重复消费的原因</span></p>\r\n\r\n<p><span style=\"font-size:12px\">ACK<br />\r\n正常情况下在consumer真正消费完消息后应该发送ack，通知broker该消息已正常消费，从queue中剔除<br />\r\n当ack因为网络原因无法发送到broker，broker会认为此条消息没有被消费，此后会开启消息重投机制把消息再次投递到consumer</span></p>\r\n\r\n<p><span style=\"font-size:12px\">消费模式<br />\r\n在CLUSTERING模式下，消息在broker中会保证相同group的consumer消费一次，但是针对不同group的consumer会推送多次</span></p>\r\n\r\n<p><span style=\"font-size:12px\">解决方案<br />\r\n去重操作直接放在了消费端，消费端处理消息的业务逻辑保持幂等性。那么不管来多少条重复消息，可以实现处理的结果都一样。<br />\r\n数据库表<br />\r\n处理消息前，使用消息主键在表中带有约束的字段中insert。建立一张日志表，使用消息主键作为表的主键，在处理消息前，先insert表，再做消息处理。这样可以避免消息重复消费</span></p>\r\n\r\n<p><span style=\"font-size:12px\">Map<br />\r\n单机时可以使用map ConcurrentHashMap -&gt; putIfAbsent guava cache</span></p>\r\n\r\n<p><span style=\"font-size:12px\">Redis<br />\r\n分布式锁搞起来。</span></p>\r\n\r\n<h1><span style=\"font-size:18px\"><strong>如何让RocketMQ保证消息的顺序消费</strong></span></h1>\r\n\r\n<p><code>首先多个queue只能保证单个queue里的顺序，queue是典型的FIFO，天然顺序。多个queue同时消费是无法绝对保证消息的有序性的。所以总结如下：</code></p>\r\n\r\n<p><code>同一topic，同一个QUEUE，发消息的时候一个线程去发送消息，消费的时候 一个线程去消费一个queue里的消息。</code></p>\r\n\r\n<p><code>追问：怎么保证消息发到同一个queue？<br />\r\nRocket MQ给我们提供了MessageQueueSelector接口，可以自己重写里面的接口，实现自己的算法，举个最简单的例子：判断i % 2 == 0，那就都放到queue1里，否则放到queue2里。</code></p>\r\n\r\n<p><span style=\"font-size:18px\"><strong>RocketMQ如何保证消息不丢失 ----？？？</strong></span><br />\r\n首先在如下三个部分都可能会出现丢失消息的情况：</p>\r\n\r\n<p>Producer端<br />\r\nBroker端<br />\r\nConsumer端</p>\r\n\r\n<p>8.1、Producer端如何保证消息不丢失<br />\r\n采取send()同步发消息，发送结果是同步感知的。<br />\r\n发送失败后可以重试，设置重试次数。默认3次。<br />\r\nproducer.setRetryTimesWhenSendFailed(10);</p>\r\n\r\n<p>集群部署，比如发送失败了的原因可能是当前Broker宕机了，重试的时候会发送到其他Broker上。</p>\r\n\r\n<p>8.2、Broker端如何保证消息不丢失<br />\r\n修改刷盘策略为同步刷盘。默认情况下是异步刷盘的。<br />\r\nflushDiskType = SYNC_FLUSH</p>\r\n\r\n<p>集群部署，主从模式，高可用。</p>\r\n\r\n<p>8.3、Consumer端如何保证消息不丢失<br />\r\n完全消费正常后在进行手动ack确认<br />\r\n<span style=\"font-size:16px\"><strong>如果动手实现一个分布式消息中间件，整体架构你会如何设计实现?</strong></span></p>\r\n\r\n<p>需要考虑能快速扩容、天然支持集群<br />\r\n持久化的姿势<br />\r\n高可用性<br />\r\n数据0丢失的考虑<br />\r\n服务端部署简单、client端使用简单</p>\r\n\r\n<p><span style=\"font-size:16px\"><strong>看过RocketMQ 的源码没有。如果看过，说说你对RocketMQ 源码的理解?</strong></span><br />\r\n里面比较典型的设计模式有单例、工厂、策略、门面模式。单例工厂无处不在，策略印象深刻比如发消息和消费消息的时候queue的负载均衡就是N个策略算法类，有随机、hash等，这也是能够快速扩容天然支持集群的必要原因之一。持久化做的也比较完善，采取的CommitLog来落盘，同步异步两种方式。</p>\r\n\r\n<h1><span style=\"font-size:16px\"><strong>高吞吐量下如何优化生产者和消费者的性能?</strong></span></h1>\r\n\r\n<p>开发<br />\r\n同一group下，多机部署，并行消费<br />\r\n单个Consumer提高消费线程个数<br />\r\n批量消费<br />\r\n消息批量拉取<br />\r\n业务逻辑批量处理<br />\r\n运维<br />\r\n网卡调优<br />\r\njvm调优<br />\r\n多线程与cpu调优<br />\r\nPage Cache</p>\r\n\r\n<p><span style=\"font-size:16px\"><strong>rocketmq的工作流程是怎样的？</strong></span><br />\r\nRocketMq的工作流程如下：<br />\r\n1）首先启动NameServer。NameServer启动后监听端口，等待Broker、Producer以及Consumer连上来<br />\r\n2）启动Broker。启动之后，会跟所有的NameServer建立并保持一个长连接，定时发送心跳包。心跳包中包含当前Broker信息(ip、port等)、Topic信息以及Borker与Topic的映射关系<br />\r\n3）创建Topic。创建时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic<br />\r\n4）Producer发送消息。启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic所在的Broker；然后从队列列表中轮询选择一个队列，与队列所在的Broker建立长连接，进行消息的发送<br />\r\n5）Consumer消费消息。跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，进行消息的消费</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-02 11:50:46', '2023-02-02 11:50:46', 1, NULL);
INSERT INTO `blog` VALUES (111, 1, '02', 1, 'SpringCloud', '<h3><a href=\"#a\">1.&nbsp;Eureka原理</a></h3>\r\n\r\n<ul>\r\n	<li><a href=\"#a1\">1.Eureka与Zookeeper、Nacos的区别在哪？</a></li>\r\n</ul>\r\n\r\n<h3><a href=\"#b\">2.Ribbon与Feign</a></h3>\r\n\r\n<ul>\r\n	<li><a href=\"#b1\">1.负载均衡算法有哪些？</a></li>\r\n	<li><a href=\"#b2\">2.Ribbon和Feign的区别？</a></li>\r\n</ul>\r\n\r\n<h3><a href=\"#c\">3.Hystix</a></h3>\r\n\r\n<ul>\r\n	<li><a href=\"#c1\">1、什么是服务雪崩？</a></li>\r\n	<li><a href=\"#c2\">2、Hystix和Sentinel的区别？</a></li>\r\n	<li><a href=\"#c3\">3、Hystix的限流两种方式</a></li>\r\n	<li><a href=\"#c4\">4、限流算法有几种？</a></li>\r\n</ul>\r\n\r\n<h3><a href=\"#d\">4.Zuul</a></h3>\r\n\r\n<h3><a href=\"#e\">5.Config</a></h3>\r\n\r\n<h3><a href=\"#f\">6.SpringCloud升级对比图</a></h3>\r\n\r\n<p><a id=\"a\" name=\"a\">1. Eureka原理</a><br />\r\nEureka作为微服务中的注册中心，其服务注册与发现的原理如下：<br />\r\n首先有两个角色，一个服务端和客户端，服务端就是Eureka本身，客户端就是服务提供者和消费者，当服务提供者启动会将自己的信息注册到Eureka去，消费者启动会去注册中心拉取服务列表缓存到本地，消费者就可以远程调用服务提供者。客户端会与注册中心保持心跳来证明自己存活，每隔30s客户端会发送心跳给注册中心，默认情况下，每隔90s注册中心会检查是否有收到心跳，如果没有收到心跳会将客户端从服务列表剔除。<br />\r\n但是由于服务之间的调用常常会受网络延迟的影响导致心跳没有及时的收到，从而误将客户端剔除，所以Eureka会有自我保护机制来应对这种情况。<br />\r\n默认情况下，Eureka的自我保护机制是开启的。<br />\r\n自我保护机制的触发：在15分钟内，Eureka收到的心跳总数低于总数的85%，就会开启。<br />\r\n自我保护机制的退出：当收到心跳数达到阈值之后，会自动退出自我保护机制<br />\r\n<a id=\"a1\" name=\"a1\">1.Eureka与Zookeeper、Nacos</a>的区别在哪？</p>\r\n\r\n<p>zookeeper保证的是CP，在Zookeeper集群中，当发生网络故障导致master节点和slave节点失联时，剩余的slave节点会进行leader选举，而在选举的过程中，zookeeper集群不可用，不能对外提供注册和查询的服务。主从节点数据同步的时候不能对外提供服务。</p>\r\n\r\n<p>Eureka保证的是AP，在Eureka集群中，某些节点挂掉，只要有一个Eureka节点存在，就可以对外提供注册和查询服务，但是可能注册信息不是最新的(不保证强一致性)。</p>\r\n\r\n<p>Nacos既支持AP也支持CP，默认使用AP和Eureka一样。</p>\r\n\r\n<h3><a id=\"b\" name=\"b\">2.Ribbon与Feign</a></h3>\r\n\r\n<ul>\r\n	<li>Ribbon是一个Http和Tcp的客户端负载均衡工具，它可以在客户端配置服务端列表，，它使用RestTemplate模拟客户端请求，过程相对繁琐。</li>\r\n	<li>Feign继承了Ribbon，使用接口的方式进行服务调用。</li>\r\n</ul>\r\n\r\n<p><a id=\"b1\" name=\"b1\">1.负载均衡算法有哪些？</a><br />\r\n随机、轮询、响应时间权重、重试等，还可以实现IRule接口，自定义负载均衡算法。</p>\r\n\r\n<p><a id=\"b2\" name=\"b2\">2.Ribbon和Feign的区别？</a></p>\r\n\r\n<p>启动类上加的注解不同，Ribbon用的是@RibbonClients；Feign用的是@EnableFeignClients<br />\r\n服务的指定位置不同，Ribbon是在@RibbonClient上指定服务名称；Feign是在接上的@FeignClient上指定。<br />\r\n调用方式不同，Ribbon需要自己构建http请求，模拟http请求，然后使用RestTempate进行调用；Feign采用接口的方式调用。</p>\r\n\r\n<p>3.Ribbon原理<br />\r\n先去本地获取从Eureka缓存下来的服务列表，然后使用负载均衡算法选取一个服务，使用HttpClient进行调用。</p>\r\n\r\n<p>4.Feign的原理<br />\r\n在配置类上，加上@EnableFeginClients，那么该注解是基于@Import注解，注册有关Fegin的解析注册类，这个类是实现 ImportBeanDefinitionRegistrar 这个接口，重写registryBeanDefinition 方法。他会扫描所有加了@FeginClient 的接口，然后针对这个注解的接口生成动态代理，然后你针对fegin的动态代理去调用他方法的时候，此时会在底层生成http协议格式的请求，使用HttpURLConnection进行调用。</p>\r\n\r\n<p>5.Feign和OpenFeign的区别？<br />\r\nOpenFeign在feign的基础上支持了SpringMVC的注解，如@RequestMapping等等，OpenFeign的@FeignClient可以解析SpringMVC的@RequestMapping注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务<br />\r\n<a id=\"c\" name=\"c\">3.Hystix</a></p>\r\n\r\n<p>Hystix是分布式系统的一个延迟和容错的开源库，它可以进行熔断、降级、限流、监控，可以避免分布式系统的级联故障和雪崩效应。</p>\r\n\r\n<p>服务熔断：熔断是直接调用降级方法。不调用目标方法，无需等待接口调用超时才返回结果。<br />\r\n服务降级：降级是调用目标方法，由于目标方法调用超时或者异常，才调用降级方法。<br />\r\n使用：服务降级是在消费端和feign一起使用，默认降级的配置不是开启的(feign.hystrix.enabled=false)，服务熔断是在服务端使用，对服务端的controller进行熔断，默认熔断的配置是开启的(spring.cloud.circuit.breaker.enabled=true)。</p>\r\n\r\n<p><a id=\"c1\" name=\"c1\">1、什么是服务雪崩？</a><br />\r\n服务雪崩就是服务A调用服务B，服务B调用服务C，服务C挂掉了，导致服务B、C超时受影响，导致服务A也超时，对服务造成级联的影响。即下游服务挂掉或者超时，导致上游调用服务大面积受到影响，阻塞、超时，进而导致雪崩效应。</p>\r\n\r\n<p><a id=\"c2\" name=\"c2\">2、Hystix和Sentinel的区别？</a></p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202302/1_20230202120420.png\" /><img alt=\"\" src=\"/blog/202302/1_20230202124133.png\" /></p>\r\n\r\n<p><a id=\"c3\" name=\"c3\">3、Hystix的限流两种方式</a><br />\r\n线程池和信号量，信号量没有timeout机制。</p>\r\n\r\n<p><a id=\"c4\" name=\"c4\">4、限流算法有几种？</a><br />\r\n计数器、滑动窗口计数器、漏桶法、令牌桶</p>\r\n\r\n<h3><a id=\"d\" name=\"d\">4.Zuul</a></h3>\r\n\r\n<p>Zuul作为微服务的网关，对微服务的访问进行控制，它可以进行路由、过滤、鉴权、代理请求，</p>\r\n\r\n<p>面试题：<br />\r\n1、Zuul和gateway的区别？</p>\r\n\r\n<p>Zuul1.0是阻塞式的api，不支持长连接，而gateway支持异步。<br />\r\nZuul没有提供限流、负载均衡等支持，而gateway支持。<br />\r\n它们都是web网关，处理http请求，底层都是servlet。<br />\r\n<a id=\"e\" name=\"e\">5.Config</a></p>\r\n\r\n<p>SpringcloudConfig是微服务中的配置中心，对微服务中多个自服务的配置进行统一的管理，可以对配置的读取、加密、解密等操作。</p>\r\n\r\n<p>面试题：<br />\r\n1、Config和Nacos的区别？</p>\r\n\r\n<p>Config大部分集合git使用，配置动态变更需要依赖SpringCloudBus消息总线来通知所有Client变化；并且没有可视化界面。<br />\r\nNacos采用长连接，一旦配置变更，会迅速通知Client进行变更，速度较快；提供可视化界面。<br />\r\n&nbsp;</p>\r\n\r\n<h3><a id=\"f\" name=\"f\">6.SpringCloud升级对比图</a></h3>\r\n\r\n<p><img alt=\"\" src=\"/blog/202302/1_20230202120311.png\" style=\"width:500px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-02 12:01:45', '2023-02-08 20:03:03', 0, NULL);
INSERT INTO `blog` VALUES (112, 1, '01', 1, 'SpringMVC', '<p><strong>SpringMVC的工作流程</strong></p>\r\n\r\n<p>1、用户发送请求至前端控制器DispatcherServlet&nbsp;<br />\r\n2、DispatcherServlet收到请求调用HandlerMapping处理器映射器。&nbsp;<br />\r\n3、处理器映射器找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。&nbsp;<br />\r\n4、DispatcherServlet调用HandlerAdapter处理器适配器&nbsp;<br />\r\n5、HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。&nbsp;<br />\r\n6、Controller执行完成返回ModelAndView&nbsp;<br />\r\n7、HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet&nbsp;<br />\r\n8、DispatcherServlet将ModelAndView传给ViewReslover视图解析器&nbsp;<br />\r\n9、ViewReslover解析后返回具体View&nbsp;<br />\r\n10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。&nbsp;<br />\r\n11、DispatcherServlet响应用户</p>\r\n\r\n<p><br />\r\n&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-07 11:48:23', '2023-02-08 20:02:22', 0, NULL);
INSERT INTO `blog` VALUES (113, 1, '01', 1, '数据库设计步骤', '<ol>\r\n	<li><strong>需求分析</strong> : 分析用户的需求，包括数据、功能和性能需求。</li>\r\n	<li><strong>概念结构设计</strong> : 主要采用 E-R 模型进行设计，包括画 E-R 图。</li>\r\n	<li><strong>逻辑结构设计</strong> : 通过将 E-R 图转换成表，实现从 E-R 模型到关系模型的转换。</li>\r\n	<li><strong>物理结构设计</strong> : 主要是为所设计的数据库选择合适的存储结构和存取路径。</li>\r\n	<li><strong>数据库实施</strong> : 包括编程、测试和试运行</li>\r\n	<li><strong>数据库的运行和维护</strong> : 系统的运行与数据库的日常维护。</li>\r\n</ol>\r\n', '', NULL, NULL, 0, '2023-02-08 16:26:35', '2023-02-08 16:26:35', 0, NULL);
INSERT INTO `blog` VALUES (114, 1, '01', 1, '一条 SQL 语句在 MySQL 中如何执行的?', '<p><strong>一条 SQL 语句在 MySQL 中如何执行的?</strong></p>\r\n\r\n<p>查询语句:</p>\r\n\r\n<ul>\r\n	<li>&nbsp;先检查该语句是否有权限</li>\r\n	<li>&nbsp;如果没有权限，直接返回错误信息</li>\r\n	<li>&nbsp;如果有权限，在 MySQL8.0 版本以前，会先查询缓存。</li>\r\n	<li>&nbsp;如果没有缓存，分析器进行词法分析，提取 sql 语句 select 等的关键元素。然后判断 sql 语句是否有语法错误，比如关键词是否正确。</li>\r\n	<li>&nbsp;优化器进行确定执行方案</li>\r\n	<li>&nbsp;进行权限校验，如果没有权限就直接返回错误信息，如果有权限就会调用数据库引擎接口，返回执行结果。</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<ul>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-08 16:27:09', '2023-02-08 16:27:09', 0, NULL);
INSERT INTO `blog` VALUES (115, 1, '01', 1, 'InnoDB 与 MyISAM 的区别', '<p><strong>InnoDB 与 MyISAM 的区别</strong></p>\r\n\r\n<ul>\r\n	<li>InnoDB 支持事务，MyISAM 不支持事务</li>\r\n	<li>InnoDB 支持外键，MyISAM 不支持外键</li>\r\n	<li>InnoDB 支持 MVCC(多版本并发控制)，MyISAM 不支持</li>\r\n	<li>select count(*) from table 时，MyISAM 更快，因为它有一个变量保存了整个</li>\r\n	<li>表的总行数，可以直接读取，InnoDB 就需要全表扫描。</li>\r\n	<li>Innodb 不支持全文索引，而 MyISAM 支持全文索引(5.7 以后的 InnoDB 也支持</li>\r\n	<li>全文索引)</li>\r\n	<li>InnoDB 支持表、行级锁，而 MyISAM 支持表级锁。</li>\r\n	<li>InnoDB 表必须有主键，而 MyISAM 可以没有主键</li>\r\n	<li>Innodb 表需要更多的内存和存储，而 MyISAM 可被压缩，存储空间较小，。</li>\r\n	<li>Innodb 按主键大小有序插入，MyISAM 记录插入顺序是，按记录插入顺序保存。</li>\r\n	<li>InnoDB 存储引擎提供了具有提交、回滚、崩溃恢复能力的事务安全，与</li>\r\n	<li>MyISAM 比 InnoDB 写的效率差一些，并且会占用更多的磁盘空间以保留数据和 索引</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-08 16:27:15', '2023-02-08 16:27:15', 0, NULL);
INSERT INTO `blog` VALUES (116, 1, '02', 1, '高性能：消息中间件', '<table>\r\n	<tbody>\r\n		<tr>\r\n			<td><a href=\"http://sunnannan.com/blog/109\" target=\"_blank\">消息中间件-选型</a></td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p><span style=\"font-size:16px\"><strong>RocketMQ</strong></span></p>\r\n\r\n<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/83\" target=\"_blank\">RocketMQ组成</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/117\" target=\"_blank\">&nbsp;RocketMQ部署</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/119\" target=\"_blank\">RocketMQ-Broker/NameServer</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/120\" target=\"_blank\">RocketMQ-Topic</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/118\" target=\"_blank\">RocketMQ-路由问题</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/124\" target=\"_blank\">RocketMQ-Consumer</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/123\" target=\"_blank\">RocketMQ-如何做负载均衡</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/128\" target=\"_blank\">RocketMQ-高吞吐量下如何优化生产者和消费者的性能</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/126\" target=\"_blank\">实现一个分布式消息中间件，整体架构</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/127\" target=\"_blank\">RocketMQ-源码的理解</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/129\" target=\"_blank\">RocketMQ-基础知识总结</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/130\" target=\"_blank\">RocketMQ-单机版消息中心</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/131\" target=\"_blank\">RocketMQ-分布式消息中心</a></li>\r\n</ul>\r\n\r\n<p>未使用RabbitMQ、Kafka</p>\r\n', '', NULL, NULL, 0, '2023-02-08 16:45:56', '2023-02-08 19:06:17', 0, NULL);
INSERT INTO `blog` VALUES (117, 1, '01', 1, ' RocketMQ部署', '<p style=\"margin-left:40px\"><strong>RocketMq的工作流程如下：</strong><br />\r\n1）首先启动NameServer。NameServer启动后监听端口，等待Broker、Producer以及Consumer连上来<br />\r\n2）启动Broker。启动之后，会跟所有的NameServer建立并保持一个长连接，定时发送心跳包。心跳包中包含当前Broker信息(ip、port等)、Topic信息以及Borker与Topic的映射关系<br />\r\n3）创建Topic。创建时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic<br />\r\n4）Producer发送消息。启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic所在的Broker；然后从队列列表中轮询选择一个队列，与队列所在的Broker建立长连接，进行消息的发送<br />\r\n5）Consumer消费消息。跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，进行消息的消费</p>\r\n\r\n<p>修改broker.conf</p>\r\n\r\n<pre>\r\n<code>brokerIP1= 外网IP</code></pre>\r\n\r\n<pre>\r\n<code>nohup ./bin/mqnamesrv -n IP:9876 &amp;\r\nnohup sh bin/mqbroker -n IP:9876 -c conf/broker.conf autoCreateTopicEnable=true &amp;\r\n在conf/broker.conf 中 加入以下信息：\r\nbrokerIP1=你的公网IP\r\nnamesrvAddr=你的公网IP:9876\r\nautoCreateTopicEnable = true</code></pre>\r\n\r\n<pre>\r\n<code>nohup ./bin/mqnamesrv -n 175.27.171.58:9876 &amp;\r\nnohup sh bin/mqbroker -n 175.27.171.58:9876 -c conf/broker.conf autoCreateTopicEnable=true &amp;\r\n\r\nsh bin/mqshutdown broker\r\nsh bin/mqshutdown namesrv\r\n\r\n\r\ntail -f ~/logs/rocketmqlogs/broker.log \r\ntail -f ~/logs/rocketmqlogs/namesrv.log</code></pre>\r\n', '', NULL, NULL, 0, '2023-02-08 16:48:34', '2023-02-08 17:07:33', 0, NULL);
INSERT INTO `blog` VALUES (118, 1, '01', 1, 'RocketMQ-路由问题', '<p><strong>Q：什么是路由注册？RocketMQ如何进行路由注册？</strong><br />\r\nA：Broker为证明自己存活，会将最新信息以心跳包的方式上报给NameServer，每30秒将BrokerId， Broker地址，Broker名称，所属集群名称等信息发送给NameServer，NameServer收到心跳包后会记录Broker的最新存活时间</p>\r\n\r\n<p><strong>Q：什么是路由剔除？RocketMQ如何进行路由剔除？</strong><br />\r\nA：由于Broker关机，宕机或网络抖动等原因，NameServer会没有收到Broker的心跳，NameServer中有一个定时任务，每隔10秒扫描一次Broker表，查看每一个Broker的最新心跳时间戳距离当前时间是否超过120秒，如果超过，则会判定Broker时效，将该Broker从列表中剔除</p>\r\n\r\n<p><strong>Q：什么是路由发现？RocketMQ如何进行路由发现？</strong></p>\r\n\r\n<p>A：RocketMQ的路由发现采用的是PULL模型，当Topic路由信息出现变化时，NameServer不会主动推送给客户端，客户端默认每30秒会从NameServer中拉取一次最新的路由</p>\r\n', '', NULL, NULL, 0, '2023-02-08 16:49:35', '2023-02-08 17:14:39', 0, NULL);
INSERT INTO `blog` VALUES (119, 1, '01', 1, 'RocketMQ-Broker/NameServer', '<h3><strong>Q：客户端NameServer选择策略</strong></h3>\r\n\r\n<p>A：客户端首先产生一个随机数，与NameServer节点数量取模，然后进行连接，如果连接失败，则会采用round-robin策略，逐个尝试与其他节点连接</p>\r\n\r\n<h3><strong>Q：Broker的部署方式</strong></h3>\r\n\r\n<p>1）单Master: 单机模式, 即只有一个Broker</p>\r\n\r\n<p>2）多Master模式: 组成一个集群, 集群每个节点都是Master节点</p>\r\n\r\n<p>3）多Master多Slave模式: 每个Master配置一个Slave，集群中存在多对Master-Slave，生产常用该部署方式。</p>\r\n\r\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\">\r\n	<tbody>\r\n		<tr>\r\n			<td>&nbsp;</td>\r\n			<td>单Master</td>\r\n			<td>多Master</td>\r\n			<td>多Master多Slave模式</td>\r\n		</tr>\r\n		<tr>\r\n			<td>优点</td>\r\n			<td>成本低</td>\r\n			<td>性能高</td>\r\n			<td>节点宕机可切换至Slave继续消费，保证可用性</td>\r\n		</tr>\r\n		<tr>\r\n			<td>缺点</td>\r\n			<td>存在单点问题，不推荐</td>\r\n			<td>宕机节点消息不能被消费</td>\r\n			<td>成本高，性能较低</td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<h3><strong>Q：Broker的刷盘策略有哪些？</strong></h3>\r\n\r\n<p>生产者将消息发送给Broker，此时Broker是将消息写入内存中，然后根据不同的刷盘策略，将消息持久化到磁盘中。</p>\r\n\r\n<p>同步刷盘：当消息持久化当Broker磁盘后，消息才算是写入成功，Broker返回成功标识给到客户端</p>\r\n\r\n<p>异步刷盘：当消息写入内存中，消息就算是写入成功，Broker返回成功标识给到客户端，不等待消息持久化到磁盘</p>\r\n\r\n<table border=\"1\" cellpadding=\"1\" cellspacing=\"1\">\r\n	<tbody>\r\n		<tr>\r\n			<td>同步刷盘</td>\r\n			<td>异步刷盘</td>\r\n		</tr>\r\n		<tr>\r\n			<td>优点</td>\r\n			<td>保证消息持久化成功</td>\r\n			<td>吞吐量较高</td>\r\n		</tr>\r\n		<tr>\r\n			<td>缺点</td>\r\n			<td>吞吐量较低</td>\r\n			<td>宕机可能引起消息丢失</td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p><strong>Q：Broker的复制策略有哪些？</strong></p>\r\n\r\n<p>复制策略是Broker的master和slave之间的数据同步方式，分同步双写和异步复制</p>\r\n\r\n<p>同步双写：只有master和slave都写成功以后，才会向客户端返回成功</p>\r\n\r\n<p>异步复制：消息写入master成功后，就返回给客户端成功，不会等待Slave写入成功</p>\r\n\r\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;同步双写&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 异步复制<br />\r\n优点&nbsp;&nbsp; &nbsp;slave消息不会丢失&nbsp;&nbsp; &nbsp;性能较同步双写高<br />\r\n缺点&nbsp;&nbsp; &nbsp;吞吐量、性能较异步复制低10%&nbsp;&nbsp; &nbsp;节点宕机可能导致消息丢失</p>\r\n\r\n<h3><strong>Q：broker如何处理拉取请求的</strong></h3>\r\n\r\n<p>Consumer首次请求Broker</p>\r\n\r\n<p>Broker中是否有符合条件的消息<br />\r\n有 -&gt;响应Consumer<br />\r\n等待下次Consumer的请求<br />\r\n没有<br />\r\nPullRequestHoldService 来Hold连接，每个5s执行一次检查pullRequestTable有没有消息，有的话立即推送<br />\r\n每隔1ms检查commitLog中是否有新消息，有的话写入到pullRequestTable<br />\r\n当有新消息的时候返回请求<br />\r\n挂起consumer的请求，即不断开连接，也不返回数据使用consumer的offset。</p>\r\n\r\n<p><strong>Q：&nbsp;Broker中的消息被消费后会立即删除吗？</strong></p>\r\n\r\n<p>不会，每条消息都会持久化到<strong>CommitLog</strong>中，每个Consumer连接到Broker后会维持消费进度信息，当有消息消费后只是当前Consumer的消费进度（CommitLog的offset）更新了。</p>\r\n\r\n<p><strong>消息会堆积吗？什么时候清理过期消息？</strong><br />\r\n默认72小时后会删除不再使用的CommitLog文件</p>\r\n\r\n<p>检查这个文件最后访问时间<br />\r\n判断是否大于过期时间<br />\r\n指定时间删除，默认凌晨4点</p>\r\n', '', NULL, NULL, 0, '2023-02-08 16:50:29', '2023-02-08 17:14:35', 0, NULL);
INSERT INTO `blog` VALUES (120, 1, '01', 1, 'RocketMQ-Topic', '<p><strong>Q：Topic的配置信息</strong><br />\r\nTopic有两种模式进行创建，创建Topic时除TopicName外，还需配置读写队列数量及perm</p>\r\n\r\n<p>创建模式</p>\r\n\r\n<p style=\"margin-left:40px\">集群模式：创建的Topic在集群所有Broker中的Queue数量相同</p>\r\n\r\n<p style=\"margin-left:40px\">Broker模式：创建的Topic指定存在哪些Broker中，并进行Queue数量设置</p>\r\n\r\n<p>读写队列</p>\r\n\r\n<p style=\"margin-left:40px\">物理上讲读写队列是同一个队列，读写队列是逻辑上进行区分，一般读写队列数量是相同的。</p>\r\n\r\n<p style=\"margin-left:40px\"><strong>读写队列如设置不同数量</strong>，会存在消息不被消费或消费不到的问题，之所以如此设计，<strong>是为了方便Topic的缩容</strong>。</p>\r\n\r\n<p>例如16个Queue的Topic如何缩容为8个Queue的Topic，如果读写队列同时减少为8，此时剩余的8个Queue里的消息将不被消费，如果先将写队列改为8，消费队列继续为16，等到剩下的8个队列都消费完了，再将消费队列改为8，这样就不会丢失消息。</p>\r\n\r\n<p>perm：2表示只写，4表示只读，6表示读写</p>\r\n', '', NULL, NULL, 0, '2023-02-08 16:51:48', '2023-02-08 17:16:23', 0, NULL);
INSERT INTO `blog` VALUES (121, 0, '01', 1, '使用RocketMQ过程中遇到问题', '<h3><strong>Q：Consumer不消费消息问题</strong></h3>\r\n\r\n<p>解决方案：Consumer数量应该小于等于订阅Topic的Queue数量，如果超出Queue数量，多出的Consumer将不能消费消息</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-08 16:52:11', '2023-02-08 17:52:49', 1, NULL);
INSERT INTO `blog` VALUES (122, 0, '01', 1, 'RocketMQ消费模式：集群消费/广播消费', '<p>集群消费：一条消息只会被同Group中的一个Consumer消费；多个Group同时消费一个Topic时，每个Group都会有一个Consumer消费到数据<br />\r\n广播消费：消息将对一个Consumer Group下的各个Consumer实例都消费一遍。即使这些Consumer属于同一个Consumer Group，消息也会被Consumer Group中的每个Consumer都消费一次。</p>\r\n\r\n<pre>\r\n<code> /**\r\n     * 3. 设置消息模式，默认是CLUSTERING\r\n     * MessageModel.BROADCASTING 广播消费模式\r\n     * MessageModel.CLUSTERING   集群消费模式\r\n     */\r\n    consumer.setMessageModel(MessageModel.BROADCASTING);\r\n</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-08 17:00:01', '2023-02-08 17:35:39', 1, NULL);
INSERT INTO `blog` VALUES (123, 1, '01', 1, 'RocketMQ如何做负载均衡', '<p><strong>1）producer发送消息的负载均衡：</strong><br />\r\n默认会轮询向Topic的所有queue发送消息，以达到消息平均落到不同的queue上；<br />\r\n而由于queue可以落在不同的broker上，就可以发到不同broker上（当然也可以指定发送到某个特定的queue上）</p>\r\n\r\n<p><strong>2）consumer订阅消息的负载均衡：</strong><br />\r\n假设有5个队列，两个消费者，则第一个消费者消费3个队列，第二个则消费2个队列，以达到平均消费的效果。<br />\r\n而需要注意的是，当consumer的数量大于队列的数量的话，根据rocketMq的机制，多出来的Consumer 不会去消费数据，因此建议consumer的数量小于或者等于queue的数量，避免不必要的浪费</p>\r\n\r\n<p><strong>3）通过Topic在多Broker中分布式存储实现。</strong></p>\r\n\r\n<p><strong>producer端：</strong><br />\r\n发送端指定message queue发送消息到相应的broker，来达到写入时的负载均衡提升写入吞吐量，当多个producer同时向一个broker写入数据的时候，性能会下降<br />\r\n消息分布在多broker中，为负载消费做准备</p>\r\n\r\n<p><strong>consumer端</strong><br />\r\n采用的是平均分配算法来进行负载均衡。</p>\r\n\r\n<p><strong>默认策略是随机选择：</strong></p>\r\n\r\n<p>producer维护一个index<br />\r\n每次取节点会自增<br />\r\nindex向所有broker个数取余<br />\r\n自带容错策略</p>\r\n\r\n<p><strong>其他实现：</strong></p>\r\n\r\n<p>SelectMessageQueueByHash<br />\r\nhash的是传入的args<br />\r\nSelectMessageQueueByRandom<br />\r\nSelectMessageQueueByMachineRoom 没有实现<br />\r\n也可以自定义实现MessageQueueSelector接口中的select方法</p>\r\n\r\n<p>MessageQueue select(final List mqs, final Message msg, final Object arg);</p>\r\n\r\n<p><strong>其他负载均衡算法</strong></p>\r\n\r\n<ul>\r\n	<li>平均分配策略(默认)(AllocateMessageQueueAveragely)</li>\r\n	<li>环形分配策略(AllocateMessageQueueAveragelyByCircle)</li>\r\n	<li>手动配置分配策略(AllocateMessageQueueByConfig)</li>\r\n	<li>机房分配策略(AllocateMessageQueueByMachineRoom)</li>\r\n	<li>一致性哈希分配策略(AllocateMessageQueueConsistentHash)</li>\r\n	<li>靠近机房策略(AllocateMachineRoomNearby)</li>\r\n</ul>\r\n\r\n<p><strong>消费负载均衡consumer和queue不对等的时候会发生什么？</strong><br />\r\nConsumer和queue会优先平均分配，<br />\r\n如果Consumer少于queue的个数，则会存在部分Consumer消费多个queue的情况，<br />\r\n如果Consumer等于queue的个数，那就是一个Consumer消费一个queue，<br />\r\n如果Consumer个数大于queue的个数，那么会有部分Consumer空余出来，白白的浪费了。<br />\r\n<strong>消息重复消费</strong>：影响消息正常发送和消费的重要原因是网络的不确定性。</p>\r\n', '', NULL, NULL, 0, '2023-02-08 17:04:44', '2023-02-08 17:46:23', 0, NULL);
INSERT INTO `blog` VALUES (124, 1, '01', 1, 'RocketMQ-Consumer', '<p><a href=\"#a1\">RocketMQ-消费模式：集群消费/广播消费</a></p>\r\n\r\n<p><a href=\"#a2\"><strong>Q：Consumer 不消费消息问题</strong></a></p>\r\n\r\n<p><a href=\"#a3\"><strong>Q：Consumer 引起重复消费的原因</strong></a></p>\r\n\r\n<p><a href=\"#a4\"><strong>Q：如何让保证消息的顺序消费</strong></a></p>\r\n\r\n<p><a href=\"#a5\"><strong>Q：RocketMQ如何保证消息不丢失?</strong></a></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p><a id=\"a1\" name=\"a1\"><strong>RocketMQ-消费模式：集群消费/广播消费</strong></a></p>\r\n\r\n<p>集群消费：一条消息只会被同Group中的一个Consumer消费；多个Group同时消费一个Topic时，每个Group都会有一个Consumer消费到数据<br />\r\n广播消费：消息将对一个Consumer Group下的各个Consumer实例都消费一遍。即使这些Consumer属于同一个Consumer Group，消息也会被Consumer Group中的每个Consumer都消费一次。</p>\r\n\r\n<pre>\r\n<code> /**\r\n     * 3. 设置消息模式，默认是CLUSTERING\r\n     * MessageModel.BROADCASTING 广播消费模式\r\n     * MessageModel.CLUSTERING   集群消费模式\r\n     */\r\n    consumer.setMessageModel(MessageModel.BROADCASTING);\r\n</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h3><a id=\"a2\" name=\"a2\"><strong>Q：Consumer 不消费消息问题</strong></a></h3>\r\n\r\n<p>解决方案：Consumer数量应该小于等于订阅Topic的Queue数量，如果超出Queue数量，多出的Consumer将不能消费消息</p>\r\n\r\n<p><a id=\"a3\" name=\"a3\"><strong>Q：Consumer 引起重复消费的原因</strong></a></p>\r\n\r\n<p>原因：<strong>ACK/消费模式</strong></p>\r\n\r\n<p><strong>ACK：</strong>正常情况下在consumer真正消费完消息后应该发送ack，通知broker该消息已正常消费，从queue中剔除，当ack因为网络原因无法发送到broker，broker会认为此条消息没有被消费，此后会开启消息重投机制把消息再次投递到consumer</p>\r\n\r\n<p><strong>消费模式：</strong>在CLUSTERING模式下，消息在broker中会保证相同group的consumer消费一次，但是针对不同group的consumer会推送多次</p>\r\n\r\n<p><strong>解决方案</strong></p>\r\n\r\n<ul>\r\n	<li>去重操作直接放在了消费端，消费端处理消息的业务逻辑保持幂等性。那么不管来多少条重复消息，可以实现处理的结果都一样。</li>\r\n	<li>数据库表处理消息前，使用消息主键在表中带有约束的字段中insert。建立一张日志表，使用消息主键作为表的主键，在处理消息前，先insert表，再做消息处理。这样可以避免消息重复消费</li>\r\n	<li>Map：单机时可以使用map ConcurrentHashMap -&gt; putIfAbsent guava cache</li>\r\n	<li>Redis：分布式锁。</li>\r\n</ul>\r\n\r\n<h3><a id=\"a4\" name=\"a4\"><strong>Q：如何让保证消息的顺序消费</strong></a></h3>\r\n\r\n<p>首先多个queue只能保证单个queue里的顺序，queue是典型的FIFO，天然顺序。多个queue同时消费是无法绝对保证消息的有序性的。</p>\r\n\r\n<p>所以：<strong>同一topic，同一个QUEUE，发消息的时候一个线程去发送消息，消费的时候 一个线程去消费一个queue里的消息。</strong></p>\r\n\r\n<p><strong>怎么保证消息发到同一个queue？</strong></p>\r\n\r\n<p style=\"margin-left:40px\">MessageQueueSelector接口，可以自己重写里面的接口，实现自己的算法，举个最简单的例子：判断i % 2 == 0，那就都放到queue1里，否则放到queue2里。</p>\r\n\r\n<p><a id=\"a5\" name=\"a5\"><strong>Q：RocketMQ如何保证消息不丢失?</strong></a></p>\r\n\r\n<p>如下三个部分都可能会出现丢失消息的情况：</p>\r\n\r\n<p>Producer端：</p>\r\n\r\n<p style=\"margin-left:40px\">采取send()同步发消息，发送失败后可以重试，设置重试次数。默认3次，producer.setRetryTimesWhenSendFailed(10);</p>\r\n\r\n<p style=\"margin-left:40px\">集群部署，比如发送失败了的原因可能是当前Broker宕机了，重试的时候会发送到其他Broker上。</p>\r\n\r\n<p>Broker端</p>\r\n\r\n<p style=\"margin-left:40px\">修改刷盘策略为同步刷盘。默认情况下是异步刷盘的。flushDiskType = SYNC_FLUSH</p>\r\n\r\n<p style=\"margin-left:40px\">集群部署，主从模式，高可用。</p>\r\n\r\n<p>Consumer端：完全消费正常后在进行手动ack确认</p>\r\n', '', NULL, NULL, 0, '2023-02-08 17:07:10', '2023-02-08 17:57:35', 0, NULL);
INSERT INTO `blog` VALUES (125, 0, '01', 1, 'RocketMQ-引起重复消费的原因', '<p>原因：<strong>ACK/消费模式</strong></p>\r\n\r\n<p><strong>ACK：</strong>正常情况下在consumer真正消费完消息后应该发送ack，通知broker该消息已正常消费，从queue中剔除，当ack因为网络原因无法发送到broker，broker会认为此条消息没有被消费，此后会开启消息重投机制把消息再次投递到consumer</p>\r\n\r\n<p><strong>消费模式：</strong>在CLUSTERING模式下，消息在broker中会保证相同group的consumer消费一次，但是针对不同group的consumer会推送多次</p>\r\n\r\n<p><strong>解决方案</strong></p>\r\n\r\n<ul>\r\n	<li>去重操作直接放在了消费端，消费端处理消息的业务逻辑保持幂等性。那么不管来多少条重复消息，可以实现处理的结果都一样。</li>\r\n	<li>数据库表处理消息前，使用消息主键在表中带有约束的字段中insert。建立一张日志表，使用消息主键作为表的主键，在处理消息前，先insert表，再做消息处理。这样可以避免消息重复消费</li>\r\n	<li>Map：单机时可以使用map ConcurrentHashMap -&gt; putIfAbsent guava cache</li>\r\n	<li>Redis：分布式锁。</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-08 17:46:15', '2023-02-08 17:46:57', 1, NULL);
INSERT INTO `blog` VALUES (126, 1, '01', 1, '实现一个分布式消息中间件，整体架构', '<p>需要考虑能快速扩容、天然支持集群<br />\r\n持久化的姿势<br />\r\n高可用性<br />\r\n数据0丢失的考虑<br />\r\n服务端部署简单、client端使用简单</p>\r\n', '', NULL, NULL, 0, '2023-02-08 17:50:01', '2023-02-08 17:50:01', 0, NULL);
INSERT INTO `blog` VALUES (127, 1, '01', 1, 'RocketMQ-源码的理解', '<p>里面比较典型的设计模式有单例、工厂、策略、门面模式。单例工厂无处不在，策略印象深刻比如发消息和消费消息的时候queue的负载均衡就是N个策略算法类，有随机、hash等，这也是能够快速扩容天然支持集群的必要原因之一。持久化做的也比较完善，采取的CommitLog来落盘，同步异步两种方式。</p>\r\n', '', NULL, NULL, 0, '2023-02-08 17:50:35', '2023-02-08 17:50:35', 0, NULL);
INSERT INTO `blog` VALUES (128, 1, '01', 1, 'RocketMQ-高吞吐量下如何优化生产者和消费者的性能', '<p><strong>开发</strong></p>\r\n\r\n<ul>\r\n	<li>同一group下，多机部署，并行消费</li>\r\n	<li>单个Consumer提高消费线程个数</li>\r\n	<li>批量消费</li>\r\n	<li>消息批量拉取</li>\r\n	<li>业务逻辑批量处理</li>\r\n</ul>\r\n\r\n<p><strong>运维</strong></p>\r\n\r\n<ul>\r\n	<li>网卡调优</li>\r\n	<li>jvm调优</li>\r\n	<li>多线程与cpu调优</li>\r\n	<li>Page Cache</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-08 17:51:28', '2023-02-08 17:51:28', 0, NULL);
INSERT INTO `blog` VALUES (129, 1, '01', 1, 'RocketMQ-基础知识总结', '<ul>\r\n	<li><a href=\"#a1\">消息队列出现的原因</a></li>\r\n	<li><a href=\"#a2\">消息队列的作用(异步，解耦，削峰)</a></li>\r\n	<li><a href=\"#a3\">消息队列带来的一系列问题(消息堆积、重复消费、顺序消费、分布式事务等等)</a></li>\r\n	<li><a href=\"#a4\">消息队列的两种消息模型&mdash;&mdash;队列和主题模式</a></li>\r\n	<li><a href=\"#a5\"><code>RocketMQ</code> 的技术架构(<code>NameServer</code> 、<code>Broker</code> 、<code>Producer</code> 、<code>Comsumer</code>)</a></li>\r\n	<li><a href=\"#a6\">消息队列副作用的解决方案</a></li>\r\n	<li><a href=\"#a7\"><code>RocketMQ</code> 的存储机制和刷盘策略</a></li>\r\n	<li><a href=\"#a8\">同步复制和异步复制</a></li>\r\n</ul>\r\n\r\n<h2><a id=\"a1\" name=\"a1\">消息队列扫盲</a></h2>\r\n\r\n<p>消费消息队列顾名思义就是存放消息的队列，</p>\r\n\r\n<p>消息队列为什么会出现？消息队列能用来干什么？用它来干这些事会带来什么好处？消息队列会带来副作用吗？</p>\r\n\r\n<h2><a id=\"a2\" name=\"a2\">消息队列的作用(异步，解耦，削峰)</a></h2>\r\n\r\n<ul>\r\n	<li>\r\n	<h3>消息队列为什么会出现？</h3>\r\n	</li>\r\n</ul>\r\n\r\n<h3 style=\"margin-left:40px\"><strong>分布式应用必定涉及到各个系统之间的通信问题，&nbsp;</strong>可以说分布式的产生是消息队列的基础</h3>\r\n\r\n<ul>\r\n	<li>\r\n	<h3>消息队列能用来干什么？</h3>\r\n	</li>\r\n</ul>\r\n\r\n<p style=\"margin-left:40px\"><strong>异步、解耦、削峰</strong></p>\r\n\r\n<h2><a id=\"a3\" name=\"a3\">消息队列带来的一系列问题</a></h2>\r\n\r\n<p>重复消费，顺序消费，分布式事务，消息堆积</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<h2><a id=\"a4\" name=\"a4\">消息队列的两种消息模型&mdash;&mdash;队列和主题模式</a></h2>\r\n\r\n<h3>队列模型</h3>\r\n\r\n<p><img alt=\"\" src=\"/blog/202302/1_20230208181304.jpg\" /></p>\r\n\r\n<h3>主题模型</h3>\r\n\r\n<p><img alt=\"\" src=\"/blog/202302/1_20230208181339.jpg\" style=\"height:224px; width:500px\" /></p>\r\n\r\n<h3>RocketMQ中的消息模型是按照&nbsp;<strong>主题模型</strong>&nbsp;所实现的</h3>\r\n\r\n<p>对于主题模型的实现来说每个消息中间件的底层设计都是不一样的，</p>\r\n\r\n<p>就比如&nbsp;<code>Kafka</code>&nbsp;中的&nbsp;<strong>分区</strong>&nbsp;，<code>RocketMQ</code>&nbsp;中的&nbsp;<strong>队列</strong>&nbsp;，<code>RabbitMQ</code>&nbsp;中的&nbsp;<code>Exchange</code></p>\r\n\r\n<p>我们可以理解为&nbsp;<strong>主题模型/发布订阅模型</strong>&nbsp;就是一个标准，那些中间件只不过照着这个标准去实现而已。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202302/1_20230208181621.jpg\" style=\"height:199px; width:500px\" /></p>\r\n\r\n<p><strong>为什么一个主题中需要维护多个队列</strong> ？</p>\r\n\r\n<p style=\"margin-left:40px\"><strong>提高并发能力</strong>&nbsp;</p>\r\n\r\n<p style=\"margin-left:40px\">每个主题中只存在一个队列也是可行的。</p>\r\n\r\n<p style=\"margin-left:40px\">如果每个主题中只存在一个队列，这个队列中也维护着每个消费者组的消费位置，这样也可以做到 <strong>发布订阅模式</strong></p>\r\n\r\n<h2><a id=\"a5\" name=\"a5\"><code>RocketMQ</code> 的技术架构</a></h2>\r\n\r\n<p><code>RocketMQ</code>&nbsp;技术架构中有四大角色&nbsp;<code>NameServer</code>&nbsp;、<code>Broker</code>&nbsp;、<code>Producer</code>&nbsp;、<code>Consumer</code>&nbsp;</p>\r\n\r\n<ul>\r\n	<li><code>Broker</code>： 主要负责消息的存储、投递和查询以及服务高可用保证。(<span style=\"color:#e74c3c\"><strong>消息队列服务器</strong>)</span>，生产者生产消息到&nbsp;<code>Broker</code>&nbsp;，消费者从&nbsp;<code>Broker</code>&nbsp;拉取消息并消费。<strong>一个&nbsp;<code>Topic</code>&nbsp;分布在多个&nbsp;<code>Broker</code>上，一个&nbsp;<code>Broker</code>&nbsp;可以配置多个&nbsp;<code>Topic</code>&nbsp;，它们是多对多的关系</strong></li>\r\n	<li>NameServer：类似<code>ZooKeeper</code>&nbsp;和&nbsp;<code>Spring Cloud</code>&nbsp;中的&nbsp;<code>Eureka。（</code><span style=\"color:#e74c3c\"><strong>注册中心</strong></span><code>）</code>主要提供两个功能：<strong>Broker管理</strong> 和 <strong>路由信息管理</strong>&nbsp;就是 <code>Broker</code> 会将自己的信息注册到 <code>NameServer</code> 中，此时 <code>NameServer</code> 就存放了很多 <code>Broker</code> 的信息(Broker的路由表)，消费者和生产者就从 <code>NameServer</code> 中获取路由表然后照着路由表的信息和对应的 <code>Broker</code> 进行通信(生产者和消费者定期会向 <code>NameServer</code> 去查询相关的 <code>Broker</code> 的信息)。</li>\r\n	<li><code>Producer</code>： 消息发布的角色，支持分布式集群方式部署（<span style=\"color:#e74c3c\"><strong>生产者</strong></span>）</li>\r\n	<li><code>Consumer</code>： 消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制（<span style=\"color:#e74c3c\">消费<strong>者</strong></span>）</li>\r\n</ul>\r\n\r\n<h2><a id=\"a6\" name=\"a6\">消息队列副作用的解决方案</a></h2>\r\n\r\n<p>顺序消费、重复消费、不消费、分布式事务、回溯消费</p>\r\n\r\n<ul>\r\n	<li>顺序消费：<strong><code>RocketMQ</code>&nbsp;在主题上是无序的、它只有在队列层面才是保证有序</strong>的，一般而言，我们的&nbsp;<code>MQ</code>&nbsp;都是能容忍短暂的乱序，所以推荐使用普通顺序模式。我们需要处理的仅仅是将同一语义下的消息放入同一个队列</li>\r\n	<li>\r\n	<p>重复消费（<strong>幂等</strong>）：</p>\r\n\r\n	<ul>\r\n		<li>\r\n		<p>可以使用&nbsp;<strong>写入&nbsp;<code>Redis</code></strong>&nbsp;来保证，因为&nbsp;<code>Redis</code>&nbsp;的&nbsp;<code>key</code>&nbsp;和&nbsp;<code>value</code>&nbsp;就是天然支持幂等的。</p>\r\n		</li>\r\n		<li>\r\n		<p>可以使用<strong>数据库插入法</strong>&nbsp;，基于数据库的唯一键来保证重复数据不会被插入多条</p>\r\n		</li>\r\n	</ul>\r\n	</li>\r\n	<li>\r\n	<p>不消费、消息堆积（<strong>削峰</strong>）：</p>\r\n\r\n	<ul>\r\n		<li>\r\n		<p>原因是：生产者生产太快或者消费者消费太慢</p>\r\n		</li>\r\n		<li>\r\n		<p>Consumer数量应该小于等于订阅Topic的Queue数量，如果超出Queue数量，多出的Consumer将不能消费消息</p>\r\n		</li>\r\n	</ul>\r\n	</li>\r\n	<li>\r\n	<p>分布式事务：比较常见的分布式事务实现有 2PC、TCC 和事务消息(half 半消息机制)。每一种实现都有其特定的使用场景，但是也有各自的问题，<strong>都不是完美的解决方案</strong></p>\r\n\r\n	<ul>\r\n		<li>\r\n		<p>在&nbsp;<code>RocketMQ</code>&nbsp;中使用的是&nbsp;<strong>事务消息加上事务反查机制</strong>&nbsp;来解决分布式事务问题的</p>\r\n		</li>\r\n	</ul>\r\n	</li>\r\n	<li>\r\n	<p>回溯消费：回溯消费是指 <code>Consumer</code> 已经消费成功的消息，由于业务上需求需要重新消费，在<code>RocketMQ</code> 中， <code>Broker</code> 在向<code>Consumer</code> 投递成功消息后，<strong>消息仍然需要保留</strong> 。并且重新消费一般是按照时间维度，例如由于 <code>Consumer</code> 系统故障，恢复后需要重新消费1小时前的数据，那么 <code>Broker</code> 要提供一种机制，可以按照时间维度来回退消费进度。<code>RocketMQ</code> 支持按照时间回溯消费，时间维度精确到毫</p>\r\n	</li>\r\n</ul>\r\n\r\n<h2><a id=\"a7\" name=\"a7\"><code>RocketMQ</code> 的存储机制和刷盘策略</a></h2>\r\n\r\n<p>在&nbsp;<code>Topic</code>&nbsp;中的&nbsp;<strong>队列是以什么样的形式存在的？队列中的消息又是如何进行存储持久化的呢？</strong></p>\r\n\r\n<ul>\r\n	<li><strong>同步刷盘</strong>&nbsp;和&nbsp;<strong>异步刷盘</strong>&nbsp;</li>\r\n</ul>\r\n\r\n<p>在同步刷盘中需要等待一个刷盘成功的&nbsp;<code>ACK</code>&nbsp;，同步刷盘对&nbsp;<code>MQ</code>&nbsp;消息可靠性来说是一种不错的保障，但是&nbsp;<strong>性能上会有较大影响</strong>&nbsp;，一般地适用于金融等特定业务场景。</p>\r\n\r\n<p>异步刷盘往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行，&nbsp;<strong>降低了读写延迟</strong>&nbsp;，提高了&nbsp;<code>MQ</code>&nbsp;的性能和吞吐量，一般适用于如发验证码等对于消息保证要求不太高的业务场景</p>\r\n\r\n<p>一般地，<strong>异步刷盘只有在 <code>Broker</code> 意外宕机的时候会丢失部分数据</strong>，可以设置 <code>Broker</code> 的参数 <code>FlushDiskType</code> 来调整你的刷盘策略(ASYNC_FLUSH 或者 SYNC_FLUSH)</p>\r\n\r\n<ul>\r\n	<li>\r\n	<h3><strong>存储机制</strong></h3>\r\n	</li>\r\n</ul>\r\n\r\n<p><code>RocketMQ</code>&nbsp;消息存储架构中的三大角色&mdash;&mdash;<code>CommitLog</code>&nbsp;、<code>ConsumeQueue</code>&nbsp;和&nbsp;<code>IndexFile</code></p>\r\n\r\n<ul>\r\n	<li><code>CommitLog</code>： <strong>消息主体以及元数据的存储主体</strong>，存储 <code>Producer</code> 端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是<strong>顺序写入日志文件</strong>，当文件满了，写入下一个文件。</li>\r\n	<li><code>ConsumeQueue</code>： 消息消费队列，<strong>引入的目的主要是提高消息消费的性能</strong>，由于<code>RocketMQ</code> 是基于主题 <code>Topic</code> 的订阅模式，消息消费是针对主题进行的，如果要遍历 <code>commitlog</code> 文件中根据 <code>Topic</code> 检索消息是非常低效的。<code>Consumer</code> 即可根据 <code>ConsumeQueue</code> 来查找待消费的消息。其中，<code>ConsumeQueue</code>（逻辑消费队列）<strong>作为消费消息的索引</strong>，保存了指定 <code>Topic</code> 下的队列消息在 <code>CommitLog</code> 中的<strong>起始物理偏移量 <code>offset</code> <strong>，消息大小 <code>size</code> 和消息 <code>Tag</code> 的 <code>HashCode</code> 值。</strong><code>consumequeue</code> 文件可以看成是基于 <code>topic</code> 的 <code>commitlog</code> 索引文件</strong>，故 <code>consumequeue</code> 文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样 <code>consumequeue</code> 文件采取定长设计，每一个条目共20个字节，分别为8字节的 <code>commitlog</code> 物理偏移量、4字节的消息长度、8字节tag <code>hashcode</code>，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个 <code>ConsumeQueue</code>文件大小约5.72M；</li>\r\n	<li><code>IndexFile</code>： <code>IndexFile</code>（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。</li>\r\n</ul>\r\n\r\n<p>总结来说，整个消息存储的结构，最主要的就是&nbsp;<code>CommitLoq</code>&nbsp;和&nbsp;<code>ConsumeQueue</code>&nbsp;。而&nbsp;<code>ConsumeQueue</code>&nbsp;可以大概理解为&nbsp;<code>Topic</code>&nbsp;中的队列</p>\r\n\r\n<p><code>RocketMQ</code>&nbsp;采用的是&nbsp;<strong>混合型的存储结构、</strong>原因是&nbsp;<strong>提高数据的写入效率</strong></p>\r\n\r\n<p>在 <code>RocketMQ</code> 中又使用了 <code>ConsumeQueue</code> 作为每个队列的索引文件来 <strong>提升读取消息的效率</strong>。我们可以直接根据队列的消息序号，计算出索引的全局位置（索引序号*索引固定⻓度20），然后直接读取这条索引，再根据索引中记录的消息的全局位置，找到消息。</p>\r\n\r\n<p><img alt=\"\" src=\"/blog/202302/1_20230208184109.png\" /></p>\r\n\r\n<h2><a id=\"a8\" name=\"a8\">同步复制和异步复制</a></h2>\r\n\r\n<p>理解：同步复制和异步复制主要是指的&nbsp;<code>Borker</code>&nbsp;主从模式下，主节点返回消息给客户端的时候是否需要同步从节点</p>\r\n\r\n<ul>\r\n	<li>同步复制： <strong>只有消息同步双写到主从节点上时才返回写入成功</strong>&nbsp;。</li>\r\n	<li>异步复制：&nbsp;<strong>消息写入主节点之后就直接返回写入成功</strong>&nbsp;。</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-08 18:03:40', '2023-02-08 18:42:11', 0, NULL);
INSERT INTO `blog` VALUES (130, 1, '01', 1, 'RocketMQ-单机版消息中心', '<h2>支持多生产者、多消费者</h2>\r\n\r\n<pre>\r\n<code>class Scratch {\r\n\r\n    public static void main(String[] args) {\r\n        // 实际中会有 nameserver 服务来找到 broker 具体位置以及 broker 主从信息\r\n        Broker broker = new Broker();\r\n        Producer producer1 = new Producer();\r\n        producer1.connectBroker(broker);\r\n        Producer producer2 = new Producer();\r\n        producer2.connectBroker(broker);\r\n\r\n        Consumer consumer1 = new Consumer();\r\n        consumer1.connectBroker(broker);\r\n        Consumer consumer2 = new Consumer();\r\n        consumer2.connectBroker(broker);\r\n\r\n        for (int i = 0; i &lt; 2; i++) {\r\n            producer1.asyncSendMsg(\"producer1 send msg\" + i);\r\n            producer2.asyncSendMsg(\"producer2 send msg\" + i);\r\n        }\r\n        System.out.println(\"broker has msg:\" + broker.getAllMagByDisk());\r\n\r\n        for (int i = 0; i &lt; 1; i++) {\r\n            System.out.println(\"consumer1 consume msg：\" + consumer1.syncPullMsg());\r\n        }\r\n        for (int i = 0; i &lt; 3; i++) {\r\n            System.out.println(\"consumer2 consume msg：\" + consumer2.syncPullMsg());\r\n        }\r\n    }\r\n\r\n}\r\n\r\nclass Producer {\r\n\r\n    private Broker broker;\r\n\r\n    public void connectBroker(Broker broker) {\r\n        this.broker = broker;\r\n    }\r\n\r\n    public void asyncSendMsg(String msg) {\r\n        if (broker == null) {\r\n            throw new RuntimeException(\"please connect broker first\");\r\n        }\r\n        new Thread(() -&gt; {\r\n            broker.sendMsg(msg);\r\n        }).start();\r\n    }\r\n}\r\n\r\nclass Consumer {\r\n    private Broker broker;\r\n\r\n    public void connectBroker(Broker broker) {\r\n        this.broker = broker;\r\n    }\r\n\r\n    public String syncPullMsg() {\r\n        return broker.getMsg();\r\n    }\r\n\r\n}\r\n\r\nclass Broker {\r\n\r\n    // 对应 RocketMQ 中 MessageQueue，默认情况下 1 个 Topic 包含 4 个 MessageQueue\r\n    private LinkedBlockingQueue&lt;String&gt; messageQueue = new LinkedBlockingQueue(Integer.MAX_VALUE);\r\n\r\n    // 实际发送消息到 broker 服务器使用 Netty 发送\r\n    public void sendMsg(String msg) {\r\n        try {\r\n            messageQueue.put(msg);\r\n            // 实际会同步或异步落盘，异步落盘使用的定时任务定时扫描落盘\r\n        } catch (InterruptedException e) {\r\n\r\n        }\r\n    }\r\n\r\n    public String getMsg() {\r\n        try {\r\n            return messageQueue.take();\r\n        } catch (InterruptedException e) {\r\n\r\n        }\r\n        return null;\r\n    }\r\n\r\n    public String getAllMagByDisk() {\r\n        StringBuilder sb = new StringBuilder(\"\\n\");\r\n        messageQueue.iterator().forEachRemaining((msg) -&gt; {\r\n            sb.append(msg + \"\\n\");\r\n        });\r\n        return sb.toString();\r\n    }\r\n}</code></pre>\r\n\r\n<p>问题：</p>\r\n\r\n<ol>\r\n	<li>没有实现真正执行消息存储落盘</li>\r\n	<li>没有实现 NameServer 去作为注册中心，定位服务</li>\r\n	<li>使用 LinkedBlockingQueue 作为消息队列，注意，参数是无限大，在真正 RocketMQ 也是如此是无限大，理论上不会出现对进来的数据进行抛弃，但是会有内存泄漏问题（阿里巴巴开发手册也因为这个问题，建议我们使用自制线程池）</li>\r\n	<li>没有使用多个队列（即多个 LinkedBlockingQueue），RocketMQ 的顺序消息是通过生产者和消费者同时使用同一个 MessageQueue 来实现，但是如果我们只有一个 MessageQueue，那我们天然就支持顺序消息</li>\r\n	<li>没有使用 MappedByteBuffer 来实现文件映射从而使消息数据落盘非常的快（实际 RocketMQ 使用的是 FileChannel+DirectBuffer）</li>\r\n</ol>\r\n', '', NULL, NULL, 0, '2023-02-08 18:46:23', '2023-02-08 18:46:23', 0, NULL);
INSERT INTO `blog` VALUES (131, 1, '01', 1, 'RocketMQ-分布式消息中心', '<h4><strong>消息丢失的问题</strong></h4>\r\n\r\n<p style=\"margin-left:40px\">可以使用生产者每发送一个消息，Broker 同步返回一个消息发送成功的反馈消息<br />\r\n即每发送一个消息，同步落盘后才返回生产者消息发送成功，这样只要生产者得到了消息发送生成的返回，事后除了硬盘损坏，都可以保证不会消息丢失</p>\r\n\r\n<h4><strong>同步落盘怎么才能快</strong></h4>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<ul>\r\n	<li>使用 FileChannel + DirectBuffer 池，使用堆外内存，加快内存拷贝</li>\r\n	<li>使用数据和索引分离，当消息需要写入时，使用 commitlog 文件顺序写，当需要定位某个消息时，查询index 文件来定位，从而减少文件IO随机读写的性能损耗</li>\r\n</ul>\r\n\r\n<h4><strong>消息堆积的问题</strong></h4>\r\n\r\n<ol>\r\n	<li>后台定时任务每隔72小时，删除旧的没有使用过的消息信息</li>\r\n	<li>根据不同的业务实现不同的丢弃任务，具体参考线程池的 AbortPolicy，例如FIFO/LRU等（RocketMQ没有此策略）</li>\r\n	<li>消息定时转移，或者对某些重要的 TAG 型（支付型）消息真正落库</li>\r\n</ol>\r\n\r\n<h4><strong>定时消息的实现</strong></h4>\r\n\r\n<p style=\"margin-left:40px\">实现定时消息的原理是：创建特定时间精度的 MessageQueue，例如生产者需要定时1s之后被消费者消费，你只需要将此消息发送到特定的 Topic，例如：MessageQueue-1 表示这个 MessageQueue 里面的消息都会延迟一秒被消费，然后 Broker 会在 1s 后发送到消费者消费此消息，使用 newSingleThreadScheduledExecutor 实现</p>\r\n\r\n<h4><strong>顺序消息的实现</strong></h4>\r\n\r\n<p>与定时消息同原理，生产者生产消息时指定特定的 MessageQueue ，消费者消费消息时，消费特定的 MessageQueue，其实单机版的消息中心在一个 MessageQueue 就天然支持了顺序消息</p>\r\n\r\n<h4><strong>分布式消息的实现</strong></h4>\r\n\r\n<ul>\r\n	<li>需要前置知识：2PC</li>\r\n	<li>RocketMQ4.3 起支持，原理为2PC，即两阶段提交，prepared-&gt;commit/rollback</li>\r\n	<li>生产者发送事务消息，假设该事务消息 Topic 为 Topic1-Trans，Broker 得到后首先更改该消息的 Topic 为 Topic1-Prepared，该 Topic1-Prepared 对消费者不可见。然后定时回调生产者的本地事务A执行状态，根据本地事务A执行状态，来是否将该消息修改为 Topic1-Commit 或 Topic1-Rollback，消费者就可以正常找到该事务消息或者不执行等</li>\r\n</ul>\r\n\r\n<h4><strong>RocketMQ 不使用 ZooKeeper 作为注册中心的原因，以及自制的 NameServer 优缺点？</strong></h4>\r\n\r\n<ol>\r\n	<li>ZooKeeper 作为支持顺序一致性的中间件，在某些情况下，它为了满足一致性，会丢失一定时间内的可用性，RocketMQ 需要注册中心只是为了发现组件地址，在某些情况下，RocketMQ 的注册中心可以出现数据不一致性，这同时也是 NameServer 的缺点，因为 NameServer 集群间互不通信，它们之间的注册信息可能会不一致</li>\r\n	<li>另外，当有新的服务器加入时，NameServer 并不会立马通知到 Producer，而是由 Producer 定时去请求 NameServer 获取最新的 Broker/Consumer 信息（这种情况是通过 Producer 发送消息时，负载均衡解决）</li>\r\n</ol>\r\n\r\n<p>参考：</p>\r\n\r\n<ul>\r\n	<li>《RocketMQ技术内幕》：https://blog.csdn.net/prestigeding/article/details/85233529</li>\r\n	<li>关于 RocketMQ 对 MappedByteBuffer 的一点优化：https://lishoubo.github.io/2017/09/27/MappedByteBuffer%E7%9A%84%E4%B8%80%E7%82%B9%E4%BC%98%E5%8C%96/</li>\r\n	<li>十分钟入门RocketMQ：https://developer.aliyun.com/article/66101</li>\r\n	<li>分布式事务的种类以及 RocketMQ 支持的分布式消息：https://www.infoq.cn/article/2018/08/rocketmq-4.3-release</li>\r\n	<li>滴滴出行基于RocketMQ构建企业级消息队列服务的实践：https://yq.aliyun.com/articles/664608</li>\r\n	<li>基于《RocketMQ技术内幕》源码注释：https://github.com/LiWenGu/awesome-rocketmq</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-08 18:53:30', '2023-02-08 18:53:30', 0, NULL);
INSERT INTO `blog` VALUES (132, 1, '01', 1, 'Redis 和 Memcached 的区别和共同点', '<p><strong>共同点</strong>&nbsp;：</p>\r\n\r\n<ol>\r\n	<li>都是基于内存的数据库，一般都用来当做缓存使用。</li>\r\n	<li>都有过期策略。</li>\r\n	<li>两者的性能都非常高。</li>\r\n</ol>\r\n\r\n<p><strong>区别</strong> ：</p>\r\n\r\n<ol>\r\n	<li><strong>Redis 支持更丰富的数据类型（支持更复杂的应用场景）</strong>。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。</li>\r\n	<li><strong>Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中。</strong></li>\r\n	<li><strong>Redis 有灾难恢复机制。</strong> 因为可以把缓存中的数据持久化到磁盘上。</li>\r\n	<li><strong>Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。</strong></li>\r\n	<li><strong>Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。</strong></li>\r\n	<li><strong>Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。</strong> （Redis 6.0 引入了多线程 IO ）</li>\r\n	<li><strong>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。</strong></li>\r\n	<li><strong>Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。</strong></li>\r\n</ol>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-08 19:11:29', '2023-02-08 19:11:29', 0, NULL);
INSERT INTO `blog` VALUES (133, 1, '01', 1, 'Redis 内存淘汰机制', '<p>Redis 提供 6 种数据淘汰策略：</p>\r\n\r\n<ol>\r\n	<li><strong>volatile-lru（least recently used）</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰</li>\r\n	<li><strong>volatile-ttl</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</li>\r\n	<li><strong>volatile-random</strong>：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</li>\r\n	<li><strong>allkeys-lru（least recently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）</li>\r\n	<li><strong>allkeys-random</strong>：从数据集（server.db[i].dict）中任意选择数据淘汰</li>\r\n	<li><strong>no-eviction</strong>：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！</li>\r\n</ol>\r\n\r\n<p>4.0 版本后增加以下两种：</p>\r\n\r\n<ol start=\"7\">\r\n	<li><strong>volatile-lfu（least frequently used）</strong>：从已设置过期时间的数据集（server.db[i].expires）中挑选最不经常使用的数据淘汰</li>\r\n	<li><strong>allkeys-lfu（least frequently used）</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key</li>\r\n</ol>\r\n', '', NULL, NULL, 0, '2023-02-08 19:12:10', '2023-02-08 19:12:10', 0, NULL);
INSERT INTO `blog` VALUES (134, 1, '01', 1, 'Redis 事务', '<h3><a href=\"#a1\"><strong>如何使用 Redis 事务？</strong></a></h3>\r\n\r\n<h3><a href=\"#a2\"><strong>Redis 支持原子性吗？</strong></a></h3>\r\n\r\n<h3>&nbsp;</h3>\r\n\r\n<h3><a id=\"a1\" name=\"a1\">如何使用 Redis 事务？</a></h3>\r\n\r\n<p>Redis 可以通过&nbsp;<strong><code>MULTI</code>，<code>EXEC</code>，<code>DISCARD</code>&nbsp;和&nbsp;<code>WATCH</code></strong>&nbsp;等命令来实现事务(transaction)功能。</p>\r\n\r\n<pre>\r\n<code>MULTI 命令后可以输入多个命令，Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 EXECopen in new window 命令后，再执行所有的命令。\r\n</code></pre>\r\n\r\n<p>过程:</p>\r\n\r\n<ol>\r\n	<li>开始事务（<code>MULTI</code>）；</li>\r\n	<li>命令入队(批量操作 Redis 的命令，先进先出（FIFO）的顺序执行)；</li>\r\n	<li>执行事务(<code>EXEC</code>)。</li>\r\n</ol>\r\n\r\n<p>可以通过&nbsp;<a href=\"https://redis.io/commands/discard\" rel=\"noopener noreferrer\" target=\"_blank\"><code>DISCARD</code></a>&nbsp;命令取消一个事务，它会清空事务队列中保存的所有命令</p>\r\n\r\n<p>可以通过<a href=\"https://redis.io/commands/watch\" rel=\"noopener noreferrer\" target=\"_blank\"><code>WATCH</code></a>命令监听指定的 Key，当调用 <code>EXEC</code> 命令执行事务时，如果一个被 <code>WATCH</code> 命令监视的 Key 被 <strong>其他客户端/Session</strong> 修改的话，整个事务都不会被执行。</p>\r\n\r\n<h3><a id=\"a2\" name=\"a2\">Redis 支持原子性吗？</a></h3>\r\n\r\n<p>事务具有四大特性： <strong>1. 原子性</strong>，<strong>2. 隔离性</strong>，<strong>3. 持久性</strong>，<strong>4. 一致性</strong>。</p>\r\n\r\n<ol>\r\n	<li><strong>原子性（Atomicity）：</strong> 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；</li>\r\n	<li><strong>隔离性（Isolation）：</strong> 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；</li>\r\n	<li><strong>持久性（Durability）：</strong> 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。</li>\r\n	<li><strong>一致性（Consistency）：</strong> 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；</li>\r\n</ol>\r\n\r\n<p>Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 是不支持回滚（roll back）操作的。因此，Redis 事务其实是不满足原子性的（而且不满足持久性）</p>\r\n\r\n<p><span style=\"color:#e74c3c\"><strong>理解为：Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断</strong></span></p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-08 19:17:35', '2023-02-08 19:17:35', 0, NULL);
INSERT INTO `blog` VALUES (135, 1, '01', 1, 'Redis 集群（*）', '<p><strong>Redis Sentinel</strong> ：</p>\r\n\r\n<ol>\r\n	<li>什么是 Sentinel？ 有什么用？</li>\r\n	<li>Sentinel 如何检测节点是否下线？主观下线与客观下线的区别?</li>\r\n	<li>Sentinel 是如何实现故障转移的？</li>\r\n	<li>为什么建议部署多个 sentinel 节点（哨兵集群）？</li>\r\n	<li>Sentinel 如何选择出新的 master（选举机制）?</li>\r\n	<li>如何从 Sentinel 集群中选择出 Leader ？</li>\r\n	<li>Sentinel 可以防止脑裂吗？</li>\r\n</ol>\r\n\r\n<p><strong>Redis Cluster</strong> ：</p>\r\n\r\n<ol>\r\n	<li>为什么需要 Redis Cluster？解决了什么问题？有什么优势？</li>\r\n	<li>Redis Cluster 是如何分片的？</li>\r\n	<li>为什么 Redis Cluster 的哈希槽是 16384 个?</li>\r\n	<li>如何确定给定 key 的应该分布到哪个哈希槽中？</li>\r\n	<li>Redis Cluster 支持重新分配哈希槽吗？</li>\r\n	<li>Redis Cluster 扩容缩容期间可以提供服务吗？</li>\r\n	<li>Redis Cluster 中的节点是怎么进行通信的？</li>\r\n</ol>\r\n', '', NULL, NULL, 0, '2023-02-08 19:19:27', '2023-02-08 19:19:27', 0, NULL);
INSERT INTO `blog` VALUES (136, 1, '02', 1, '微信支付', '<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/70\" target=\"_blank\">微信支付-开发前准备-选择介入模式</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/71\" target=\"_blank\">微信支付-开发前准备-参数申请</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/72\" target=\"_blank\">微信支付-开发前准备-配置API key</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/73\" target=\"_blank\">微信支付-开发前准备-下载并配置商户证书</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/74\" target=\"_blank\">微信支付-开发前准备-配置应用（小程序）</a></li>\r\n</ul>\r\n\r\n<p>没啥难点，按文档操作即可</p>\r\n', '', NULL, NULL, 0, '2023-02-08 19:49:59', '2023-02-08 19:49:59', 0, NULL);
INSERT INTO `blog` VALUES (137, 1, '02', 1, '安装记录', '<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/80\" target=\"_blank\">安装jdk</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/79\" target=\"_blank\">安装nginx</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/78\" target=\"_blank\">安装mysql</a></li>\r\n	<li>安装<a href=\"http://sunnannan.com/blog/117\" target=\"_blank\">RocketMQ</a></li>\r\n	<li>安装Redis</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-08 19:55:58', '2023-02-08 19:57:04', 0, NULL);
INSERT INTO `blog` VALUES (138, 1, '01', 1, 'MyBatis', '<p><strong>MyBatis工作流程</strong></p>\r\n\r\n<p>&nbsp;1.加载配置文件。<br />\r\n&nbsp;2.生成SqlSessionFactory。<br />\r\n&nbsp;3.建立SqlSession。<br />\r\n&nbsp;4.调用MyBatis提供的API。<br />\r\n&nbsp;5.查询Map配置文件。<br />\r\n&nbsp;6.返回结果。<br />\r\n&nbsp;7.关闭SqlSession。</p>\r\n\r\n<p>Mybatis和hibernate不同，它不完全是一个ORM框架，因为MyBatis需要程序员自己编写Sql语句，不过Mybatis可以通过XML或注解方式灵活配置要运行的sql语句，并将java对象和sql语句映射生成最终执行的sql，最后将sql执行的结果再映射生成java对象。</p>\r\n\r\n<p>Mybatis学习门槛低，简单易学，程序员直接编写原生态sql，可严格控制sql执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，例如互联网软件、企业运营类软件等，因为这类软件需求变化频繁，一但需求变化要求成果输出迅速。但是灵活的前提是Mybatis无法做到数据库无关性，如果需要实现支持多种数据库的软件则需要自定义多套sql映射文件，工作量大。</p>\r\n\r\n<p>Hibernate对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件（例如需求固定的定制化软件）如果用hibernate开发可以节省很多代码，提高效率。但是Hibernate的学习门槛高，要精通门槛更高，而且怎么设计O/R映射，在性能和对象模型之间如何权衡，以及怎样用好Hibernate需要具有很强的经验和能力才行。</p>\r\n\r\n<p>总之，按照用户的需求在有限的资源环境下只要能做出维护性、扩展性良好的软件架构都是好架构，所以框架只有适合才是最好。<br />\r\n&nbsp;</p>\r\n\r\n<p><strong>什么是控制反转、依赖注入 以及依赖注入的方式</strong></p>\r\n\r\n<p>控制反转就是本来你该做的事情，你不去做了，让系统去做。比如，你获取一个对象的时候，往往需要new出实例来，如果用了控制反转，那这件事情 就不需要你做了，你只需要在配置文件xml中配置好，系统就帮你new了。控制反转也叫依赖注入，就是把该用到的东西提前注入进去，下次直接用，而不是每次都new。</p>\r\n\r\n<p>&nbsp;依赖注入方式：构造器依赖注入和Setter方法注入。</p>\r\n\r\n<p>post请求乱码解决：在web.xml中加入CharacterEncodingFilter。代码如下。</p>\r\n', '', NULL, NULL, 0, '2023-02-08 20:01:49', '2023-02-08 20:02:05', 0, NULL);
INSERT INTO `blog` VALUES (139, 1, '01', 1, 'SpringBoot-读取配置文件', '<ol>\r\n	<li>\r\n	<p>使用 @Value 读取配置文件。</p>\r\n	&nbsp;@Value(&quot;${profile.name}&quot;)</li>\r\n	<li>\r\n	<p>使用 @<a href=\"https://so.csdn.net/so/search?q=ConfigurationProperties&amp;spm=1001.2101.3001.7020\" target=\"_blank\">ConfigurationProperties</a>&nbsp;读取配置文件。&nbsp;</p>\r\n\r\n	<p>@ConfigurationProperties 和 @Value 的使用略微不同，@Value 是读取单个配置项的，而 @ConfigurationProperties 是读取一组配置项的，我们可以使用 @ConfigurationProperties 加实体类读取一组配置项，如下代码所示：</p>\r\n	</li>\r\n	<li>\r\n	<p>使用 Environment 读取配置文件。</p>\r\n	</li>\r\n</ol>\r\n\r\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Environment 是 Spring Core 中的一个用于读取配置文件的类，将此类使用 @Autowired 注入到类中就可以使用它的 getProperty 方法来获取某个配置项的值了，如下代码所示：</p>\r\n\r\n<p>&nbsp; &nbsp; &nbsp;4、使用 @PropertySource 读取配置文件。</p>\r\n\r\n<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; @PropertySource(&quot;classpath:application.properties&quot;)</p>\r\n\r\n<p>&nbsp; &nbsp; &nbsp;5、使用原生方式读取配置文件。</p>\r\n\r\n<pre>\r\n<code>Properties props = new Properties();\r\n        try {\r\n            InputStreamReader inputStreamReader = new InputStreamReader(\r\n                    this.getClass().getClassLoader().getResourceAsStream(\"application.properties\"),\r\n                    StandardCharsets.UTF_8);\r\n            props.load(inputStreamReader);\r\n        } catch (IOException e1) {\r\n            System.out.println(e1);\r\n        }</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-08 20:04:50', '2023-02-08 20:04:50', 0, NULL);
INSERT INTO `blog` VALUES (140, 1, '01', 1, 'Nginx-服务响应速度较慢', '<pre>\r\n<code>#将gzip打开\r\n gzip  on;\r\n# 压缩级别 级别越高,压的越小,越浪费CPU计算资源\r\n gzip_comp_level 6;\r\n#对哪些类型的文件用压缩\r\n gzip_types application/json  text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png;\r\n# 开始压缩的最小长度 我这边是1000k 不建议调到很小\r\n gzip_min_length 200;\r\n#缓冲\r\n gzip_buffers 16 64k;\r\n#开始压缩的http协议版本\r\n gzip_http_version 1.1;</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-08 20:11:08', '2023-02-08 20:11:08', 0, NULL);
INSERT INTO `blog` VALUES (141, 1, '01', 1, 'Nginx-本地上传文件正常、服务器上异常413Request Entity Too Large 错误', '<p>描述：一个文件上传接口，在本地上传没问题，一到服务器就报HTTP 413错误，排除了代码有问题。</p>\r\n\r\n<p>发布服务后使用了nginx进行代理配置，例如服务端口 8082。上传链接 xxx:8082/upload 上传文件正常。nginx代理端口80，上传链接 xxx/upload 上传文件失败，提示413。</p>\r\n\r\n<p>原因：直接访问接口上传不通过nginx，文件大小不受限制。</p>\r\n\r\n<p>xxx/upload上传使用了nginx，&ldquo;请求实体过大&rdquo;。当因请求的实体过大，超出服务器的处理能力，导致服务器无法处理请求时就会返回此错误代码</p>\r\n\r\n<p>解决办法：既然是上传文件大小的设置问题，那么修改配置文件就好了，修改nginx.conf的值就可以解决了。</p>\r\n\r\n<p>添加配置后者调大参数值</p>\r\n\r\n<pre>\r\n<code>client_max_body_size 50m;</code></pre>\r\n\r\n<p>nginx.conf如下：</p>\r\n\r\n<pre>\r\n<code>http {\r\n    log_format  main  \'$remote_addr - $remote_user [$time_local] \"$request\" \'\r\n                      \'$status $body_bytes_sent \"$http_referer\" \'\r\n                      \'\"$http_user_agent\" \"$http_x_forwarded_for\"\';\r\n\r\n    access_log  /var/log/nginx/access.log  main;\r\n\r\n    sendfile            on;\r\n    tcp_nopush          on;\r\n    tcp_nodelay         on;\r\n    keepalive_timeout   65;\r\n    types_hash_max_size 4096;\r\n\r\n    client_max_body_size 50m;\r\n}</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-08 20:12:12', '2023-02-08 20:12:12', 0, NULL);
INSERT INTO `blog` VALUES (142, 1, '01', 1, 'Nginx-访问时如果找不到页面，希望不报404，进行重定向', '<p>location /{<br />\r\n&nbsp; &nbsp; &nbsp; &nbsp; root /usr/share/nginx/html/data-h5;<br />\r\n&nbsp; &nbsp; &nbsp; &nbsp; index index.html;<br />\r\n&nbsp; &nbsp; &nbsp; &nbsp; try_files $uri $uri/ /index.html;<br />\r\n}</p>\r\n', '', NULL, NULL, 0, '2023-02-08 20:12:30', '2023-02-08 20:12:30', 0, NULL);
INSERT INTO `blog` VALUES (143, 1, '02', 1, '小程序', '<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/81\" target=\"_blank\">小程序外链</a></li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-08 20:14:36', '2023-02-08 20:14:36', 0, NULL);
INSERT INTO `blog` VALUES (144, 1, '02', 2, 'Axure', '<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/28\" target=\"_blank\">初用axure</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/29\" target=\"_blank\">axure使用2</a></li>\r\n	<li><a href=\"http://sunnannan.com/blog/30\" target=\"_blank\">axure-控制面板</a></li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-08 20:18:14', '2023-02-08 20:18:14', 0, NULL);
INSERT INTO `blog` VALUES (145, 0, '01', 1, '待完成', '<p>高可用</p>\r\n\r\n<p>分布式</p>\r\n\r\n<p>系统设计</p>\r\n\r\n<p>springboot面试题</p>\r\n\r\n<p>mybatis面试题</p>\r\n\r\n<p>spring事务、设计模式、自动装配</p>\r\n\r\n<p>netty面试</p>\r\n\r\n<p>java</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-08 20:23:20', '2023-02-08 20:23:20', 0, NULL);
INSERT INTO `blog` VALUES (146, 0, '01', 1, 'Spring', '<pre>\r\n<code>Spring 官网：https://spring.io/</code></pre>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/147\" target=\"_blank\">Spring,Spring MVC,Spring Boot</a></p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-10 10:25:27', '2023-02-10 10:56:31', 0, NULL);
INSERT INTO `blog` VALUES (147, 0, '01', 1, 'Spring,Spring MVC,Spring Boot ', '<h3><strong>Spring,Spring MVC,Spring Boot 之间什么关系?</strong></h3>\r\n\r\n<p>Spring 包含了多个功能模块（上面刚刚提到过），其中最重要的是 Spring-Core（主要提供 IoC 依赖注入功能的支持） 模块， Spring 中的其他模块（比如 Spring MVC）的功能实现基本都需要依赖于该模块</p>\r\n\r\n<p>Spring MVC 是 Spring 中的一个很重要的模块，主要赋予 Spring 快速构建 MVC 架构的 Web 程序的能力。MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码。</p>\r\n\r\n<p>Spring Boot 只是简化了配置，如果你需要构建 MVC 架构的 Web 程序，你还是需要使用 Spring MVC 作为 MVC 框架，只是说 Spring Boot 帮你简化了 Spring MVC 的很多配置，真正做到开箱即用！</p>\r\n', '', NULL, NULL, 0, '2023-02-10 10:56:06', '2023-02-10 10:56:06', 0, NULL);
INSERT INTO `blog` VALUES (148, 0, '01', 1, 'Nginx-nginx: [error] open() \"/run/nginx.pid\" failed (2: No such file or directory)', '<pre>\r\n<code>nginx -c /etc/nginx/nginx.conf\r\nsudo ./nginx -s reload</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-10 12:37:31', '2023-02-10 12:37:31', 0, NULL);
INSERT INTO `blog` VALUES (149, 0, '01', 1, '映美', '<p>工作经历</p>\r\n\r\n<p>2017.04~2023.01 映美传世(北京)文化传媒有限公司 技术经理/Java 工程师</p>\r\n\r\n<pre>\r\n<code>1、后端服务架构设计，制定技术方案和开发计划，分析并解决技术难点; \r\n2、后端核心功能设计、开发，核心代码编写，设计开放 API 接口，撰写技术文档; \r\n3、后端服务部署、发布、维护和持续优化，数据库设计、创建、调优，数据自动化备份; \r\n4、负责引擎模块、通用业务框架的落地应用，支撑多条业务线的核心建设; \r\n5、完成系统的迭代升级，提升系统功能和性能，解决应用中出现的问题; \r\n6、制定开发规范和代码规范，执行单元测试和代码质量检查，代码版本管理; \r\n7、管理技术团队，分解开发任务并进行分配，跟进完成进度和质量; \r\n8、与用户、产品高效沟通协作，快速进行需求转化，推进项目进度，执行项目管控。</code></pre>\r\n\r\n<p>项目经验</p>\r\n\r\n<pre>\r\n<code>项目名称:映美办公工作流引擎\r\n技术框架:Spring Boot2 + MyBatis + MySQL + Redis + RocketMQ \r\n项目简介:自研轻量级工作流引擎，用于协同办公。应用在企业内部各项业务的决策和审批。\r\n 包含:流程定义和管理、客户端应用接口及协议、消息管理推送、管理监控。</code></pre>\r\n\r\n<pre>\r\n<code>项目名称:映美业务云平台\r\n技术框架:Spring Cloud + Spring Boot2 + MyBatis + MySQL+ Redis \r\n项目简介:公司信息化服务平台。建立了以项目为中心，包含决策、合同、预算、付款、授 权、供应商流程和台账的业务体系。\r\n提供 PC、钉钉、微信小程序终端服务。</code></pre>\r\n\r\n<pre>\r\n<code>项目名称:映美数据平台\r\n技术框架:XXL-JOB2.0 + Spring Boot2 + MyBatis + MySQL + Redis \r\n项目简介:网生内容行业数据平台。建设目的是通过采集、分析行业数据，挖掘行业数据价 值，展现行业状态和趋势，提供辅助决策。\r\n数据覆盖了爱奇艺、优酷和腾讯视频三大平台网 络电影的影片、票房、榜单和备案数据。提供 PC、微信小程序终端服务。</code></pre>\r\n\r\n<pre>\r\n<code>项目名称:映美发行平台\r\n技术框架:Spring Boot2 + MyBatis + MySQL + Redis + RocketMQ \r\n项目简介:对接广电备案系统、视频平台、版权供应商和电子合同服务商，\r\n构建项目广电备案、平台结算、分账单和电子合同业务模块。提供 PC、钉钉、微信小程序终端服务。</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-10 12:46:26', '2023-02-10 12:48:15', 0, NULL);
INSERT INTO `blog` VALUES (150, 0, '01', 1, 'Nginx-负载均衡', '<ul>\r\n	<li>轮询\r\n	<ul>\r\n		<li>指定权重</li>\r\n	</ul>\r\n	</li>\r\n	<li>ip哈希</li>\r\n	<li>最小连接数</li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-02-13 15:41:18', '2023-02-13 15:41:18', 0, NULL);
INSERT INTO `blog` VALUES (151, 0, '01', 1, 'git-配置', '<p>配置ssh</p>\r\n\r\n<pre>\r\n<code>ls -al ~/.ssh\r\n\r\nssh-keygen -t rsa -b 4096 -C \"邮箱\"\r\n\r\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQC/kI7LKe6egkhcNtIJWLxmZGk68GamyHnHjQGn6sMpuqW0NyAbeoaEkEk5sGL1NZ8J1aSC1mYNJDJXxqMk6h9DI07Rx7yIWXfI5WEzk7di0uR9j9Jy+ed17Z3d/o9ZI5fVA3Pons7botMrgjVhulN2UH0hkiA3dHInRPmgveO0sYh9xC61HM94ZlKUzUbX1z2J44ZsgFaqjg+0gIfb7cTgFM82pns5WBg64Nt5u3frabYwt9AHlX6UbfKYDQr8PBPFaqJFcX+rqk309BJmr9MxJnsqYdhdbkdE0JYEQoOnKHiExeiUnjhvFaOlite/srSl7HoID4Dsi/cKYPJIhwMMs71Vu1iOhtT+DIOstzIUZdKXZ4V6dUIU2gd8dC+tlPqm6Tbi48eD+YmhQsg+ocw96ctH5El1LB7/MIAKO14PvD7aDbB2nzfBys9wd6/o9VvnhwU70EB+oU29A7Aa2vueUvTkt2XNc7GQXMILeX0DON05oQxrxGQpbgjIFODNLLOaBmuLUxE3jFbTs9ngKchDlR2auUS2jg7k2vashr2850gwXz+B8p99z+iUQsEanGqFyN9p4xcO7ygD7jpG3bPPbdj29oFx0nQRjtj/Iv/m2T2/nhGk7NSYLUvQ9BIR6VfGBgFIwEzH+sKi9De8DS/ZBWQqxpBgCZGWckciksIuzQ== </code></pre>\r\n\r\n<p>配置user</p>\r\n\r\n<pre>\r\n<code>$ git config --global user.name ‘your_name’\r\n$ git config --global user.email ‘your_email@domain.com’\r\n\r\nlocal\r\nsystem</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<pre>\r\n<code>git log --oneline\r\ngit log -n2 --oneline\r\n\r\ngit status\r\ngit brabch\r\ngit checkout -b 分支名称\r\ngit merge a b\r\n\r\n\r\ngit remote -v\r\ngit remote add github git@github.com:NanNanMichelle/FirstRepository.git\r\n\r\n\r\ngit push github --all\r\ngit fetch github main\r\n\r\n</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-02-28 10:06:37', '2023-02-28 10:09:39', 0, NULL);
INSERT INTO `blog` VALUES (152, 0, '01', 1, '小程序登录', '<h1><strong><span style=\"font-size:16px\">小程序登录、用户信息相关接口调整说明</span></strong></h1>\r\n\r\n<p><a href=\"https://developers.weixin.qq.com/community/develop/doc/00022c683e8a80b29bed2142b56c01\">https://developers.weixin.qq.com/community/develop/doc/00022c683e8a80b29bed2142b56c01</a></p>\r\n\r\n<p>总结：</p>\r\n\r\n<p>小程序通过 wx.getUserProfile 接口将正常返回用户头像昵称，</p>\r\n\r\n<p>插件通过wx.getUserInfo接口将返回用户头像昵称</p>\r\n\r\n<p>2021年4月15日调整：<a href=\"https://developers.weixin.qq.com/community/develop/doc/000cacfa20ce88df04cb468bc52801\">https://developers.weixin.qq.com/community/develop/doc/000cacfa20ce88df04cb468bc52801</a></p>\r\n\r\n<p>总结：</p>\r\n\r\n<p>通过wx.login接口获取的登录凭证可直接换取unionID<br />\r\n回收wx.getUserInfo接口可获取用户个人信息能力<br />\r\n新增getUserProfile接口，用于获取用户的个人信息（头像，昵称，性别与地区）</p>\r\n\r\n<p><strong><span style=\"font-size:16px\">获取头像昵称</span></strong></p>\r\n\r\n<p><a href=\"https://developers.weixin.qq.com/miniprogram/dev/framework/open-ability/userProfile.html\">https://developers.weixin.qq.com/miniprogram/dev/framework/open-ability/userProfile.html</a></p>\r\n\r\n<p><strong><span style=\"font-size:16px\">小程序登录过程</span></strong></p>\r\n\r\n<p><a href=\"https://developers.weixin.qq.com/miniprogram/dev/framework/open-ability/login.html\">https://developers.weixin.qq.com/miniprogram/dev/framework/open-ability/login.html</a></p>\r\n\r\n<h1><strong><span style=\"font-size:16px\">UnionID 机制说明</span></strong></h1>\r\n\r\n<p><a href=\"https://developers.weixin.qq.com/miniprogram/dev/framework/open-ability/union-id.html\">https://developers.weixin.qq.com/miniprogram/dev/framework/open-ability/union-id.html</a></p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-03-08 12:35:07', '2023-03-08 12:38:37', 0, NULL);
INSERT INTO `blog` VALUES (153, 0, '01', 1, '支付宝小程序', '<p>调整历史： https://open.alipay.com/portal/forum/post/73101020</p>\r\n', '', NULL, NULL, 0, '2023-03-09 13:53:19', '2023-03-09 13:53:19', 0, NULL);
INSERT INTO `blog` VALUES (154, 0, '01', 1, 'JWT 实现登录认证 + Token 自动续期方案', '<p>用户管理模块会涉及到加密及认证流程</p>\r\n\r\n<p>实现认证功能：JWT或者session</p>\r\n\r\n<h3><strong>区别</strong></h3>\r\n\r\n<p>基于session和基于JWT的方式的主要区别就是用户的状态保存的位置，<strong>session是保存在服务端</strong>的，而<strong>JWT是保存在客户端</strong>的</p>\r\n\r\n<h3><strong>认证流程</strong></h3>\r\n\r\n<h4>基于session的认证流程</h4>\r\n\r\n<ul>\r\n	<li>\r\n	<p>用户在浏览器中输入用户名和密码，服务器通过密码校验后生成一个session并保存到数据库</p>\r\n	</li>\r\n	<li>\r\n	<p>服务器为用户生成一个sessionId，并将具有sesssionId的cookie放置在用户浏览器中，在后续的请求中都将带有这个cookie信息进行访问</p>\r\n	</li>\r\n	<li>\r\n	<p>服务器获取cookie，通过获取cookie中的sessionId查找数据库判断当前请求是否有效</p>\r\n	</li>\r\n</ul>\r\n\r\n<h4>基于JWT的认证流程</h4>\r\n\r\n<ul>\r\n	<li>\r\n	<p>用户在浏览器中输入用户名和密码，服务器通过密码校验后生成一个token并保存到数据库</p>\r\n	</li>\r\n	<li>\r\n	<p>前端获取到token，存储到cookie或者local storage中，在后续的请求中都将带有这个token信息进行访问</p>\r\n	</li>\r\n	<li>\r\n	<p>服务器获取token值，通过查找数据库判断当前token是否有效</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3><strong>优缺点</strong></h3>\r\n\r\n<ul>\r\n	<li>\r\n	<p>JWT保存在客户端，在分布式环境下不需要做额外工作。而session因为保存在服务端，分布式环境下需要实现多机数据共享</p>\r\n	</li>\r\n	<li>\r\n	<p>session一般需要结合Cookie实现认证，所以需要浏览器支持cookie，因此移动端无法使用session认证方案</p>\r\n	</li>\r\n</ul>\r\n\r\n<h4><strong>安全性</strong></h4>\r\n\r\n<ul>\r\n	<li>\r\n	<p>JWT的payload使用的是base64编码的，因此在<strong>JWT中不能存储敏感数据</strong>。而session的信息是存在服务端的，相对来说更安全</p>\r\n	</li>\r\n</ul>\r\n\r\n<h4><strong>性能</strong></h4>\r\n\r\n<ul>\r\n	<li>\r\n	<p>经过编码之后JWT将非常长，cookie的限制大小一般是4k，cookie很可能放不下，所以JWT一般放在local storage里面。并且用户在系统中的每一次http请求都会把JWT携带在Header里面，HTTP请求的Header可能比Body还要大。而sessionId只是很短的一个字符串，因此使用JWT的HTTP请求比使用session的开销大得多</p>\r\n	</li>\r\n</ul>\r\n\r\n<h4><strong>一次性</strong></h4>\r\n\r\n<p>无状态是JWT的特点，但也导致了这个问题，JWT是一次性的。想修改里面的内容，就必须签发一个新的JWT</p>\r\n\r\n<ul>\r\n	<li>\r\n	<p>无法废弃 一旦签发一个JWT，在到期之前就会始终有效，无法中途废弃。若想废弃，一种常用的处理手段是结合redis</p>\r\n	</li>\r\n	<li>\r\n	<p>续签 如果使用JWT做会话管理，传统的cookie续签方案一般都是框架自带的，session有效期30分钟，30分钟内如果有访问，有效期被刷新至30分钟。一样的道理，要改变JWT的有效时间，就要签发新的JWT。最简单的一种方式是每次请求刷新JWT，即每个HTTP请求都返回一个新的JWT。这个方法不仅暴力不优雅，而且每次请求都要做JWT的加密解密，会带来性能问题。另一种方法是在redis中单独为每个JWT设置过期时间，每次访问时刷新JWT的过期时间</p>\r\n	</li>\r\n</ul>\r\n\r\n<h3>选择JWT或session</h3>\r\n\r\n<p>JWT一票，JWT有很多缺点，但是在分布式环境下不需要像session一样额外实现多机数据共享，虽然seesion的多机数据共享可以通过<strong>粘性session</strong>、<strong>session共享</strong>、<strong>session复制</strong>、<strong>持久化session</strong>、<strong>terracoa实现seesion复制</strong>等多种成熟的方案来解决这个问题。但是JWT不需要额外的工作，使用JWT不香吗？且JWT一次性的缺点可以结合redis进行弥补。扬长补短，因此在实际项目中选择的是使用JWT来进行认证</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-03-14 10:18:00', '2023-03-14 10:18:00', 0, NULL);
INSERT INTO `blog` VALUES (155, 0, '01', 1, 'JWT功能实现', '<h3>JWT所需依赖</h3>\r\n\r\n<pre>\r\n<code>&lt;dependency&gt;\r\n    &lt;groupId&gt;com.auth0&lt;/groupId&gt;\r\n    &lt;artifactId&gt;java-jwt&lt;/artifactId&gt;\r\n    &lt;version&gt;3.10.3&lt;/version&gt;\r\n&lt;/dependency</code></pre>\r\n\r\n<h3>JWT工具类</h3>\r\n\r\n<pre>\r\n<code>\r\n\r\nimport io.jsonwebtoken.Claims;\r\nimport io.jsonwebtoken.Jws;\r\nimport io.jsonwebtoken.Jwts;\r\nimport io.jsonwebtoken.SignatureAlgorithm;\r\n\r\nimport javax.crypto.SecretKey;\r\nimport javax.crypto.spec.SecretKeySpec;\r\nimport java.util.Base64;\r\nimport java.util.Date;\r\nimport java.util.HashMap;\r\nimport java.util.Map;\r\n\r\npublic class JwtUtils {\r\n\r\n    /**\r\n     * 两个常量： 过期时间；秘钥\r\n     */\r\n    public static final long EXPIRE = 1000 * 60 * 60 * 24;\r\n\r\n    public static final String SECRET = \"camsdgdgdfsfsssssssssssssssssssssssssdfpus2022\";\r\n\r\n    /**\r\n     * 生成加密后的秘钥 secretKey\r\n     *\r\n     * @return\r\n     */\r\n    public static SecretKey generalKey() {\r\n        byte[] encodedKey = Base64.getDecoder().decode(JwtUtils.SECRET);\r\n        return new SecretKeySpec(encodedKey, 0, encodedKey.length, \"HmacSHA256\");\r\n    }\r\n\r\n    /**\r\n     * 生成token字符串的方法\r\n     */\r\n    public static String generateToken(Map&lt;String, String&gt; data) {\r\n        SecretKey key = generalKey();\r\n        var builder = Jwts.builder()\r\n            //JWT头信息\r\n            .setHeaderParam(\"typ\", \"JWT\")\r\n            .setHeaderParam(\"alg\", \"HS256\")\r\n            //设置分类；设置过期时间 一个当前时间，一个加上设置的过期时间常量\r\n            .setSubject(\"lin-user\")\r\n            .setIssuedAt(new Date())\r\n            .setExpiration(new Date(System.currentTimeMillis() + EXPIRE));\r\n\r\n        //设置token主体信息，存储用户信息\r\n        data.forEach(builder::claim);\r\n        builder.signWith(key, SignatureAlgorithm.HS256);\r\n\r\n        return builder.compact();\r\n    }\r\n\r\n    public static String getByKey(String token, String key) {\r\n        SecretKey secretKey = generalKey();\r\n        var builder = Jwts.parserBuilder().setSigningKey(secretKey).build();\r\n        Jws&lt;Claims&gt; claimsJws = builder.parseClaimsJws(token);\r\n        Claims body = claimsJws.getBody();\r\n        return (String) body.get(key);\r\n    }\r\n\r\n    public static Map&lt;String, String&gt; toMap(String token) {\r\n        SecretKey secretKey = generalKey();\r\n        var builder = Jwts.parserBuilder().setSigningKey(secretKey).build();\r\n        Jws&lt;Claims&gt; claimsJws = builder.parseClaimsJws(token);\r\n        Claims body = claimsJws.getBody();\r\n        var map = new HashMap&lt;String, String&gt;();\r\n        body.forEach((k, v) -&gt; map.put(k, String.valueOf(v)));\r\n        return map;\r\n    }\r\n\r\n    /**\r\n     * 验证令牌是否过期\r\n     */\r\n    public static boolean isNotValid(String token) {\r\n        try {\r\n            SecretKey secretKey = generalKey();\r\n            var builder = Jwts.parserBuilder().setSigningKey(secretKey).build();\r\n            Claims claims = builder.parseClaimsJws(token).getBody();\r\n            Date expiration = claims.getExpiration();\r\n            return expiration.before(new Date());\r\n        } catch (Exception e) {\r\n            return true;\r\n        }\r\n    }\r\n\r\n}\r\n\r\n</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-03-14 10:26:05', '2023-03-14 10:26:05', 0, NULL);
INSERT INTO `blog` VALUES (156, 0, '01', 1, '测试', '<pre>\r\n<code>@ActiveProfiles(\"test\")\r\n@Transactional\r\n@SpringBootTest(webEnvironment = WebEnvironment.MOCK)</code></pre>\r\n\r\n<p>service/mapper</p>\r\n\r\n<pre>\r\n<code>@WireMockTest(proxyMode = true)\r\n\r\n    @Test\r\n    public void getListCategoryCode() {\r\n        var content = testUtils.loadResp(\"productCategory-success\");\r\n        var data = ProductCategoryReq.of(0);\r\n        testUtils.stubRequest(\"/index.php/applet/GoodsWs/getLevelOneCategory\", data, content);\r\n        var productResp = client.getListCategoryCode(data);\r\n        assertThat(productResp.get(0).getCategoryId()).isNotNull();\r\n    }\r\n\r\n var content = testUtils.loadResp(\"productCategory-success\");\r\n返回信息是什么\r\n var data = ProductCategoryReq.of(0);\r\n传入参数是什么\r\n\r\ntestUtils.stubRequest(\"/index.php/applet/GoodsWs/getLevelOneCategory\", data, content);\r\nurl、入参、返回参数，一些参数处理可以再这里面处理\r\n    public void stubRequest(String path, Object request, String response) {\r\n        if (request instanceof DonorServiceReq req) {\r\n            req.setCustomerId(Long.valueOf(this.customerId));\r\n            req.setPlatform(platform);\r\n        }\r\n        var rawRequest = JSON.toJSONString(request, JSONWriter.Feature.FieldBased);\r\n        var encyptedRequest = CryptoUtils.encryptByAesEcb(rawRequest, privateKey);\r\n\r\n        var encyptedResponse = CryptoUtils.encryptByAesEcb(response, privateKey);\r\n        stubFor(post(path)\r\n            .withHost(equalTo(\"yfbatelm.china-xianxue.com\"))\r\n            .withRequestBody(equalTo(encyptedRequest))\r\n            .willReturn(ok(encyptedResponse)));\r\n    }</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-04-03 15:38:58', '2023-04-03 15:38:58', 0, NULL);
INSERT INTO `blog` VALUES (157, 0, '01', 1, 'JWT', '<p><a href=\"http://sunnannan.com/blog/159\" target=\"_blank\">介绍</a></p>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/160\" target=\"_blank\">JWT认证流程</a></p>\r\n\r\n<ul>\r\n</ul>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/154\" target=\"_blank\">JWT 实现登录认证 + Token 自动续期方案</a></p>\r\n\r\n<p><a href=\"http://sunnannan.com/blog/155\" target=\"_blank\">JWT功能实现</a></p>\r\n', '', NULL, NULL, 0, '2023-04-03 15:40:14', '2023-04-03 15:59:48', 0, NULL);
INSERT INTO `blog` VALUES (158, 0, '01', 1, '负载均衡', '<ul>\r\n	<li><a href=\"http://sunnannan.com/blog/150\" target=\"_blank\">Nginx-负载均衡</a></li>\r\n</ul>\r\n', '', NULL, NULL, 0, '2023-04-03 15:42:10', '2023-04-03 15:42:10', 0, NULL);
INSERT INTO `blog` VALUES (159, 0, '01', 1, '介绍', '<p>jwt全称<code>Json Web Token</code>，强行翻译过来就是<strong><code>json格式的互联网令牌</code></strong></p>\r\n\r\n<ul>\r\n	<li>它要解决的问题，就是为多种终端设备，提供<strong>统一的、安全的</strong>令牌格式</li>\r\n	<li><strong>jwt只是一个令牌格式而已，你可以把它存储到cookie，也可以存储到localstorage，没有任何限制！</strong></li>\r\n	<li><strong>对于传输，可以使用任何传输方式来传输jwt，一般来说，我们会使用消息头来传输它<br />\r\n	比如，当登录成功后，服务器可以给客户端响应一个jwt</strong></li>\r\n</ul>\r\n\r\n<pre>\r\n<code>它也可以出现在响应的多个地方，比如为了充分利用浏览器的cookie，\r\n同时为了照顾其他设备，也可以让jwt出现在set-cookie和authorization或body中，\r\n尽管这会增加额外的传输量。</code></pre>\r\n\r\n<p>虽然jwt没有明确要求应该如何附带到请求中，但通常我们会使用如下的格式：</p>\r\n\r\n<pre>\r\n<code>GET /api/resources HTTP/1.1\r\n...\r\nauthorization: bearer jwt令牌\r\n...\r\n</code></pre>\r\n\r\n<p>为了保证令牌的安全性，jwt令牌由三个部分组成，分别是：</p>\r\n\r\n<ul>\r\n	<li>header：令牌头部，记录了整个令牌的类型和签名算法</li>\r\n	<li>payload：令牌负荷，记录了保存的主体信息，比如你要保存的用户信息就可以放到这里</li>\r\n	<li>signature：令牌签名，按照头部固定的签名算法对整个令牌进行签名，该签名的作用是：保证令牌不被伪造和篡改</li>\r\n</ul>\r\n\r\n<p>它们组合而成的完整格式是：<strong><code>header.payload.signature</code></strong></p>\r\n\r\n<h2>header</h2>\r\n\r\n<p>它是令牌头部，记录了整个令牌的类型和签名算法</p>\r\n\r\n<p>它的格式是一个<code>json</code>对象，如下：</p>\r\n\r\n<pre>\r\n<code>{\r\n  \"alg\":\"HS256\",\r\n  \"typ\":\"JWT\"\r\n}\r\n</code></pre>\r\n\r\n<p>该对象记录了：</p>\r\n\r\n<p>alg：signature部分使用的签名算法，通常可以取两个值<br />\r\nHS256：一种对称加密算法，使用同一个秘钥对signature加密解密<br />\r\nRS256：一种非对称加密算法，使用私钥加密，公钥解密<br />\r\ntyp：整个令牌的类型，固定写JWT即可<br />\r\n设置好了header之后，就可以生成header部分了具体的生成方式及其简单，就是把header部分使用base64 url编码即可</p>\r\n\r\n<h2>payload</h2>\r\n\r\n<p>这部分是jwt的主体信息，它仍然是一个JSON对象，它可以包含以下内容：</p>\r\n\r\n<pre>\r\n<code>{\r\n  \"ss\"：\"发行者\",\r\n	\"iat\"：\"发布时间\",\r\n	\"exp\"：\"到期时间\",\r\n	\"sub\"：\"主题\",\r\n	\"aud\"：\"听众\",\r\n	\"nbf\"：\"在此之前不可用\",\r\n  \"jti\"：\"JWT ID\"\r\n}\r\n</code></pre>\r\n\r\n<p><strong>以上属性可以全写，也可以一个都不写，它只是一个规范</strong>。就算写了，也需要你在将来验证这个jwt令牌时手动处理才能发挥作用</p>\r\n\r\n<p>其实很简单，payload这一部分只是一个json对象而已，你可以向对象中加入任何想要加入的信息</p>\r\n\r\n<h2>signature</h2>\r\n\r\n<p>这一部分是jwt的签名，正是它的存在，保证了整个jwt不被篡改</p>\r\n\r\n<p>这部分的生成，是对前面两个部分的编码结果，按照头部指定的方式进行加密</p>\r\n\r\n<p>比如：头部指定的加密方法是HS256，前面两部分的编码结果是eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb28iOiJiYXIiLCJpYXQiOjE1ODc1NDgyMTV9</p>\r\n\r\n<p>则第三部分就是用对称加密算法HS256对字符串eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmb28iOiJiYXIiLCJpYXQiOjE1ODc1NDgyMTV9进行加密，当然你得指定一个秘钥<br />\r\n&nbsp;</p>\r\n\r\n<p>令牌在服务器组装完成后，会以任意的方式发送到客户端</p>\r\n\r\n<p>客户端会把令牌保存起来，后续的请求会将令牌发送给服务器</p>\r\n\r\n<p>而服务器需要验证令牌是否正确，如何验证呢？</p>\r\n\r\n<p>首先，服务器要验证这个令牌是否被篡改过，验证方式非常简单，就是对<strong>header+payload</strong>用同样的秘钥和加密算法进行重新加密</p>\r\n\r\n<p>然后把加密的结果和传入jwt的signature进行对比，如果完全相同，则表示前面两部分没有动过，就是自己颁发的，如果不同，肯定是被篡改过了。<br />\r\n&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-04-03 15:52:13', '2023-04-03 15:58:19', 0, NULL);
INSERT INTO `blog` VALUES (160, 0, '01', 1, 'JWT认证流程', '<h3><span style=\"font-size:20px\"><strong>登录</strong></span></h3>\r\n\r\n<p>① 用户登录时，将用户名和密码通过 POST 提交到服务端</p>\r\n\r\n<p>② 服务端接收到登录数据之后，与数据库中的用户信息进行校验</p>\r\n\r\n<p>③ 校验通过</p>\r\n\r\n<p>④ 服务端通过用户 _id，secret 等等相关数据生成 JWT 字符串</p>\r\n\r\n<p>⑤ 将 JWT 字符串和其他信息一起返回给浏览器，浏览器拿到 jwt 字符串后，缓存到本地，等待下一次请求<br />\r\n<span style=\"font-size:20px\"><strong>下一次请求</strong></span></p>\r\n\r\n<p>① 用户登录之后的每次请求，都会将 token 携带在请求头的 Authorization 中</p>\r\n\r\n<p>② 对 token 验证成功之后，我们可以拿到保存在 token 中的用户数据</p>\r\n\r\n<p>③ 进入业务处理</p>\r\n', '', NULL, NULL, 0, '2023-04-03 15:59:36', '2023-04-03 15:59:36', 0, NULL);
INSERT INTO `blog` VALUES (161, 0, '01', 1, 'OncePerRequestFilter', '<pre>\r\n<code>/**\r\n* 过滤器基类，旨在确保每个请求调度在任何servlet容器上执行一次执行。 \r\n* 它提供了一个带有HttpServletRequest和HttpServletResponse参数的{@link #doFilterInternal}方法。\r\n*/\r\npublic abstract class OncePerRequestFilter extends GenericFilterBean { ... }</code></pre>\r\n\r\n<p>道filter最主要的是doFilter方法：</p>\r\n\r\n<pre>\r\n<code>// 已过滤过的过滤器的固定后缀名\r\npublic static final String ALREADY_FILTERED_SUFFIX = \".FILTERED\";\r\n\r\n// 相当于生成已过滤的过滤器的名字（全局唯一的）\r\nprotected String getAlreadyFilteredAttributeName() {\r\n	String name = getFilterName();\r\n	if (name == null) {\r\n		name = getClass().getName();\r\n	}\r\n	return name + ALREADY_FILTERED_SUFFIX;\r\n}\r\n\r\n//判断该请求是否是异步请求（Servlet 3.0后有异步请求,Spring MVC3.2开始）\r\nprotected boolean isAsyncDispatch(HttpServletRequest request) {\r\n	return WebAsyncUtils.getAsyncManager(request).hasConcurrentResult();\r\n}\r\n\r\n//是否需要不过滤异步的请求（默认是不多次过滤异步请求的）\r\n//javadoc：javax.servlet.DispatcherType.ASYNC的请求方式意味着可能在一个请求里这个过滤器会被多个不同线程调用多次，而这里返回true，就能保证只会被调用一次\r\nprotected boolean shouldNotFilterAsyncDispatch() {\r\n	return true;\r\n}\r\n\r\n//原理基本同上\r\nprotected boolean shouldNotFilterErrorDispatch() {\r\n	return true;\r\n}\r\n\r\n//可以人工直接返回true  那这个请求就肯定不会被过滤了~~~~\r\nprotected boolean shouldNotFilter(HttpServletRequest request) throws ServletException {\r\n	return false;\r\n}\r\n\r\n//这里很清楚的记录着  需要被跳过的请求们，这种请求直接就放行了\r\nprivate boolean skipDispatch(HttpServletRequest request) {\r\n	if (isAsyncDispatch(request) &amp;&amp; shouldNotFilterAsyncDispatch()) {\r\n		return true;\r\n	}\r\n	if (request.getAttribute(WebUtils.ERROR_REQUEST_URI_ATTRIBUTE) != null &amp;&amp; shouldNotFilterErrorDispatch()) {\r\n		return true;\r\n	}\r\n	return false;\r\n}</code></pre>\r\n\r\n<pre>\r\n<code>	@Override\r\n	public final void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain)\r\n			throws ServletException, IOException {\r\n		\r\n		//只处理http请求\r\n		if (!(request instanceof HttpServletRequest) || !(response instanceof HttpServletResponse)) {\r\n			throw new ServletException(\"OncePerRequestFilter just supports HTTP requests\");\r\n		}\r\n		HttpServletRequest httpRequest = (HttpServletRequest) request;\r\n		HttpServletResponse httpResponse = (HttpServletResponse) response;\r\n\r\n		//判断这个请求是否需要执行过滤\r\n		String alreadyFilteredAttributeName = getAlreadyFilteredAttributeName();\r\n		boolean hasAlreadyFilteredAttribute = request.getAttribute(alreadyFilteredAttributeName) != null;\r\n\r\n		if (hasAlreadyFilteredAttribute || skipDispatch(httpRequest) || shouldNotFilter(httpRequest)) {\r\n\r\n			// 直接放行，不执行此过滤器的过滤操作\r\n			filterChain.doFilter(request, response);\r\n		} else {\r\n			// 执行过滤，并且向请求域设置一个值，key就是生成的全局唯一的·alreadyFilteredAttributeName·\r\n			request.setAttribute(alreadyFilteredAttributeName, Boolean.TRUE);\r\n			try {\r\n				//由子类自己去实现拦截的逻辑  注意 自己写时，filterChain.doFilter(request, response);这句代码不要忘了\r\n				doFilterInternal(httpRequest, httpResponse, filterChain);\r\n			}\r\n			finally {\r\n				// Remove the \"already filtered\" request attribute for this request.\r\n				request.removeAttribute(alreadyFilteredAttributeName);\r\n			}\r\n		}\r\n	}</code></pre>\r\n\r\n<pre>\r\n<code>// 如果在Spring应用程序上下文中初始化为bean，那么它将返回到bean工厂中定义的bean名称。\r\n// 需要注意的是，如果是以bean的形式加入了。（比如Boot环境下），此时FilterConfig还未null的，所以有这个判断\r\n@Nullable\r\nprotected String getFilterName() {\r\n	return (this.filterConfig != null ? this.filterConfig.getFilterName() : this.beanName);\r\n}</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-04-03 16:42:44', '2023-04-03 16:42:44', 0, NULL);
INSERT INTO `blog` VALUES (162, 0, '01', 1, 'redisTemplate', '<pre>\r\n<code>@Configuration\r\npublic class RedisConfiguration {\r\n\r\n    @Bean\r\n    RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory rcf) {\r\n        var template = new RedisTemplate&lt;String, Object&gt;();\r\n        template.setConnectionFactory(rcf);\r\n        template.setKeySerializer(new StringRedisSerializer());\r\n        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());\r\n\r\n        template.setHashKeySerializer(new StringRedisSerializer());\r\n        template.setHashValueSerializer(new GenericJackson2JsonRedisSerializer());\r\n\r\n        return template;\r\n    }\r\n\r\n}</code></pre>\r\n\r\n<p>StringRedisSerializer 是 Spring Data Redis 库中的一个类，用于在 Redis 中序列化和反序列化字符串。它用于将 Java 对象转换为 Redis 兼容的数据结构，反之亦然。</p>\r\n\r\n<p>当创建 StringRedisSerializer 的新实例时，它可以用于配置 RedisTemplate 实例，以使用序列化器处理字符串值。这允许 RedisTemplate 在与 Redis 交互时自动处理字符串值的序列化和反序列化。</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>GenericJackson2JsonRedisSerializer 是 Spring Data Redis 库中的一个类，用于在 Redis 中序列化和反序列化 Java 对象为 JSON 格式。它使用 Jackson 库实现 JSON 的序列化和反序列化。</p>\r\n\r\n<p>当创建 GenericJackson2JsonRedisSerializer 的新实例时，它可以用于配置 RedisTemplate 实例，以使用序列化器处理 Java 对象并将其转换为 JSON 格式。这允许 RedisTemplate 在与 Redis 交互时自动处理 Java 对象的序列化和反序列化，并将其转换为 JSON 格式。</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', NULL, NULL, 0, '2023-04-26 08:53:23', '2023-04-26 08:53:23', 0, NULL);

-- ----------------------------
-- Table structure for blog_copy
-- ----------------------------
DROP TABLE IF EXISTS `blog_copy`;
CREATE TABLE `blog_copy`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `accountId` int NOT NULL,
  `title` varchar(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `content` text CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `pic` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '' COMMENT '文章配图',
  `state` int NOT NULL COMMENT '0为草稿，1为发布',
  `seoKeywords` int NULL DEFAULT NULL,
  `seoDescription` int NULL DEFAULT NULL,
  `viewCount` int NOT NULL DEFAULT 0 COMMENT '浏览量',
  `created` datetime NOT NULL COMMENT '创建时间',
  `updated` datetime NOT NULL COMMENT '最后更新时间',
  `del` int NOT NULL DEFAULT 0,
  `status` varchar(2) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '01',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `pk_status`(`state`, `status`, `accountId`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 11 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_copy
-- ----------------------------
INSERT INTO `blog_copy` VALUES (1, 1, '基于SpringCloud Alibaba的微服务电商解决方案', '<p>电商行业</p>\r\n\r\n<p>电商微服务技术架构</p>\r\n\r\n<p>基于Nacos的微服务拆分</p>\r\n\r\n<p><strong>使用版本</strong></p>\r\n\r\n<p><strong>框架、组件</strong></p>\r\n\r\n<p style=\"margin-left:40px\">SpringCloud Alibaba：2.2.6.RELEASE<br />\r\nSpringCloud: Hoxton.SR9<br />\r\nSpring Boot:&nbsp;2.3.2.RELEASE<br />\r\nJDK： 1.8<br />\r\nNacos： 1.4.2<br />\r\nSentinel:&nbsp;1.8.1<br />\r\nRocketMQ: 4.4.0<br />\r\nDubbo: 2.7.8<br />\r\nSeata: 1.3.0</p>\r\n\r\n<p style=\"margin-left:40px\"><a href=\"https://github.com/alibaba/spring-cloud-alibaba/wiki\">https://github.com/alibaba/spring-cloud-alibaba/wiki</a></p>\r\n\r\n<p style=\"margin-left:40px\">版本选择与兼容性：<a href=\"https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E\">https://github.com/alibaba/spring-cloud-alibaba/wiki/%E7%89%88%E6%9C%AC%E8%AF%B4%E6%98%8E</a></p>\r\n\r\n<p><strong>Netflix与SpringCloud&nbsp;Alibaba对比</strong></p>\r\n\r\n<pre>\r\n<code>SpringCloud解决方案之Netflix\r\n服务注册与发现:Eureka\r\n熔断限流:hystrix\r\nREST Client: Feign\r\n客户端负载均衡:Ribbon\r\n微服务网关:zuul\r\n\r\nSpringCloud解决方案之Alibaba\r\n服务注册与发现:Nacos\r\n熔断限流:Sentienl\r\n分布式消息中间件:RocketMQ\r\n分布式事务中间件:Seata\r\nRPC服务框架:Dubbo</code></pre>\r\n\r\n<table cellspacing=\"0\" style=\"border-collapse:collapse; width:491px\">\r\n	<tbody>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:1px solid black; height:21px; vertical-align:middle; white-space:nowrap; width:71px\"><span style=\"font-size:8px\"><strong><span style=\"font-family:等线\">Netflix&nbsp;</span></strong></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:1px solid black; vertical-align:middle; white-space:nowrap; width:220px\"><span style=\"font-size:8px\"><strong><span style=\"font-family:等线\">推荐替代品&nbsp;</span></strong></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:1px solid black; vertical-align:middle; white-space:nowrap; width:200px\"><span style=\"font-size:8px\"><strong><span style=\"font-family:等线\">&nbsp;说明</span></strong></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Hystrix</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Sentinel&nbsp;</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">来自SpringCloud Alibaba</span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Eureka</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Nacos&nbsp;</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">来自SpringCloud Alibaba</span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Ribbon</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Spring Cloud Loadbalancer</span></span></td>\r\n			<td rowspan=\"2\" style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; text-align:center; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Spring</span></span></td>\r\n		</tr>\r\n		<tr>\r\n			<td style=\"border-bottom:1px solid black; border-left:1px solid black; border-right:1px solid black; border-top:none; height:21px; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Zuul</span></span></td>\r\n			<td style=\"border-bottom:1px solid black; border-left:none; border-right:1px solid black; border-top:none; vertical-align:middle; white-space:nowrap\"><span style=\"font-size:8px\"><span style=\"font-family:等线\">Spring Cloud Gateway</span></span></td>\r\n		</tr>\r\n	</tbody>\r\n</table>\r\n\r\n<p>1、Netflix：&nbsp;Eureka、Hystrix、Zuul停更不停用</p>\r\n\r\n<p>2、<span style=\"color:#e74c3c\">SpringCloud Alibaba成为业界主流的微服务解决方案</span></p>\r\n\r\n<p>&nbsp;</p>\r\n', '', 1, NULL, NULL, 0, '2022-07-18 10:59:33', '2022-07-18 17:39:33', 0, '02');
INSERT INTO `blog_copy` VALUES (6, 1, '电商行业模式与技术架构', '<ul>\r\n	<li>电商行业的技术特性</li>\r\n	<li>电商行业的模式介绍</li>\r\n</ul>\r\n\r\n<p><img alt=\"\" src=\"/blog/202207/2_20220718170212.png\" style=\"height:358px; width:600px\" /></p>\r\n\r\n<p><img alt=\"\" src=\"/upload/image/2_20220718170438.jpeg\" style=\"height:463px; width:771px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', 1, NULL, NULL, 0, '2022-07-18 11:34:52', '2022-07-19 04:03:44', 0, '01');
INSERT INTO `blog_copy` VALUES (7, 1, 'SpringCloud解决方案（一）', '<p>&nbsp;</p>\r\n\r\n<ul>\r\n	<li><strong><a href=\"#one\">SpringCloud介绍，Netflix与Alibaba的对比</a></strong></li>\r\n	<li>基于SpringCloud Alibaba的电商微服务技术架构</li>\r\n	<li>电商业务微服务拆分</li>\r\n	<li>分布式服务注册中心 Nacos整合</li>\r\n</ul>\r\n\r\n<h3><a id=\"one\" name=\"one\">一、SpringCloud介绍，Netflix与Alibaba的对比</a></h3>\r\n\r\n<p>简单来说，SpringCloud提供了一些可以让开发者快速构建微服务应用的工具，比如配置管理、服务发现、熔断、智能路由等，这些服务可以在任何分布式环境下很好的工作。</p>\r\n', '', 1, NULL, NULL, 0, '2022-07-18 13:54:44', '2022-07-18 15:54:44', 1, '01');
INSERT INTO `blog_copy` VALUES (8, 1, '微服务的设计和拆分原则', '<ul>\r\n	<li><span style=\"font-size:16px\"><strong>微服务拆分原则</strong></span></li>\r\n	<li><span style=\"font-size:16px\"><strong>前后端分离原则</strong></span></li>\r\n	<li><span style=\"font-size:16px\"><strong>Restful通信风格</strong></span></li>\r\n</ul>\r\n\r\n<p><span style=\"font-size:16px\"><strong>微服务拆分原则 </strong></span>（AKF扩展拆分要点）：</p>\r\n\r\n<ul>\r\n	<li>低耦合、高内聚：一个服务完成一个独立功能</li>\r\n	<li>按团队结构：小规模团队维护，快速迭代</li>\r\n</ul>\r\n\r\n<p><strong>x轴---水平复制</strong>：绝对平等的复制服务和数据，单体的系统运行多个实例</p>\r\n\r\n<p><strong>y轴---按服务功能拆分：</strong>用户管理服务、商品管理服务、订单管理服务。。。。。。</p>\r\n\r\n<p><strong>z轴---数据分区：</strong>基于用户独特的特性进行划分，例如：将订单管理服务进行划分（秒杀订单、优惠订单等）、将不同地区的用户进行划分（北京、上海、、、、）</p>\r\n\r\n<p><span style=\"font-size:16px\"><strong>前后端分离原则</strong></span></p>\r\n\r\n<p>不分离：后端要疯</p>\r\n\r\n<p>部分分离：重复js，数据加载慢，浪费资源等</p>\r\n\r\n<p>完全分离：各忙各的，各司其职</p>\r\n\r\n<pre>\r\n<code>无服务状态\r\n\r\n状态：如果一个数据需要被多个数据共享才能完成一笔交易，这个数据就是有状态。</code></pre>\r\n\r\n<p><img alt=\"\" src=\"http://47.104.222.156/upload/image/2_20220718172026.jpeg\" style=\"height:232px; width:710px\" /></p>\r\n\r\n<p><span style=\"font-size:16px\"><strong>Restful通信风格</strong></span></p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n', '', 1, NULL, NULL, 0, '2022-07-18 15:15:11', '2022-07-18 19:20:39', 0, '01');
INSERT INTO `blog_copy` VALUES (9, 1, '电商微服务划分', '<p><strong>用户进行一次购买流程</strong></p>\r\n\r\n<ul>\r\n	<li>登录</li>\r\n	<li>用户服务</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<ul>\r\n	<li>商品服务</li>\r\n	<li>搜索服务</li>\r\n	<li>购物车服务</li>\r\n	<li><span style=\"color:#e74c3c\">订单服务</span></li>\r\n	<li>秒杀服务（等）</li>\r\n</ul>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<ul>\r\n	<li><span style=\"color:#e74c3c\">库存服务</span></li>\r\n	<li><span style=\"color:#e74c3c\">积分服务(等其它会员类服务：京东京豆)</span></li>\r\n</ul>\r\n\r\n<p><img alt=\"\" src=\"/upload/image/2_20220718172956.jpeg\" style=\"height:248px; width:468px\" /></p>\r\n\r\n<p>&nbsp;</p>\r\n', '', 1, NULL, NULL, 0, '2022-07-18 15:27:23', '2022-07-18 17:31:42', 0, '01');
INSERT INTO `blog_copy` VALUES (10, 1, 'Nacos（一）安装部署', '<h1><strong><span style=\"font-size:16px\">概念</span></strong></h1>\r\n\r\n<p>1、Nacos 的缩写 (Dynamic Naming Configueration Service)，Na 为 naming/nameServer 即注册中心，co 为 configuration 即配置中心，service 是指该注册/配置中心都是以服务为核心。<br />\r\n2、Nacos 是什么？【<span style=\"color:#e74c3c\">Nacos = Eureka + Config +Bus</span>】：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。Nacos 就是<span style=\"color:#e74c3c\">注册中心 + 配置中心</span>的组合。<br />\r\n3、Nacos 能干嘛？<br />\r\n（1）替代 Eureka 做服务注册中心。<br />\r\n（2）替代 Config 做服务配置中心。</p>\r\n\r\n<p><span style=\"font-size:16px\"><strong>特性</strong></span></p>\r\n\r\n<ul>\r\n	<li>\r\n	<h4>服务发现：收集所有要管理的服务</h4>\r\n	</li>\r\n	<li>\r\n	<h4>服务健康监测：实时健康检查，能够阻止请求发送到不健康主机或服务实例</h4>\r\n	</li>\r\n	<li>\r\n	<h4>动态配置服务：消除了配置变更时重新部署应用和服务的需要，让配置管理变得更加高效、敏捷；配置中心化管理让实现无状态服务变得更简单，让服务按需弹性扩展变得更容易</h4>\r\n	</li>\r\n	<li>\r\n	<h4>动态 DNS 服务：实现负载均衡、流量控制以及数据中心内网的简单 DNS 解析服务</h4>\r\n	</li>\r\n	<li>\r\n	<h4>服务及其元数据管理</h4>\r\n	</li>\r\n</ul>\r\n\r\n<p><span style=\"font-size:16px\"><strong>部署方式</strong></span></p>\r\n\r\n<ul>\r\n	<li>单机模式 - 用于测试和单机试用。</li>\r\n	<li>集群模式 - 用于生产环境，确保高可用。</li>\r\n	<li>多集群模式 - 用于多数据中心场景。</li>\r\n</ul>\r\n\r\n<h1><span style=\"font-size:16px\"><strong>环境准备</strong></span></h1>\r\n\r\n<ul>\r\n	<li>安装好 JDK，需要 1.8 及其以上版本</li>\r\n	<li>建议: 2核 CPU / 4G 内存 及其以上</li>\r\n	<li>建议: 生产环境 3 个节点 及其以上</li>\r\n</ul>\r\n\r\n<p><span style=\"font-size:16px\"><strong>下载安装</strong></span></p>\r\n\r\n<h3>从 Github 上下载源码方式</h3>\r\n\r\n<pre>\r\n<code>git clone https://github.com/alibaba/nacos.git\r\ncd nacos/\r\nmvn -Prelease-nacos -Dmaven.test.skip=true clean install -U  \r\nls -al distribution/target/\r\n\r\n// change the $version to your actual path\r\ncd distribution/target/nacos-server-$version/nacos/bin\r\n</code></pre>\r\n\r\n<h3>下载编译后压缩包方式</h3>\r\n\r\n<p>从&nbsp;<a href=\"https://github.com/alibaba/nacos/releases\">https://github.com/alibaba/nacos/releases</a> 上下载最新版本</p>\r\n\r\n<pre>\r\n<code>  unzip nacos-server-$version.zip 或者 tar -xvf nacos-server-$version.tar.gz\r\n  cd nacos/bin</code></pre>\r\n\r\n<p><span style=\"font-size:16px\"><strong>启动</strong></span></p>\r\n\r\n<h3>Linux/Unix/Mac</h3>\r\n\r\n<p>启动命令(standalone代表着单机模式运行，非集群模式):</p>\r\n\r\n<pre>\r\n<code>sh startup.sh -m standalone</code></pre>\r\n\r\n<p>如果您使用的是ubuntu系统，或者运行脚本报错提示[[符号找不到，可尝试如下运行：</p>\r\n\r\n<pre>\r\n<code>bash startup.sh -m standalone</code></pre>\r\n\r\n<p><span style=\"font-size:16px\"><strong>关闭</strong></span></p>\r\n\r\n<h3>Linux/Unix/Mac</h3>\r\n\r\n<pre>\r\n<code>sh shutdown.sh</code></pre>\r\n\r\n<p><span style=\"font-size:16px\"><strong>服务注册&amp;发现和配置管理</strong></span></p>\r\n\r\n<h3>服务注册</h3>\r\n\r\n<pre>\r\n<code>curl -X POST \'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&amp;ip=20.18.7.10&amp;port=8080\'</code></pre>\r\n\r\n<h3>服务发现</h3>\r\n\r\n<pre>\r\n<code>curl -X GET \'http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=nacos.naming.serviceName\'</code></pre>\r\n\r\n<h3>发布配置</h3>\r\n\r\n<pre>\r\n<code>curl -X POST \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test&amp;content=HelloWorld\"</code></pre>\r\n\r\n<h3>获取配置</h3>\r\n\r\n<pre>\r\n<code>curl -X GET \"http://127.0.0.1:8848/nacos/v1/cs/configs?dataId=nacos.cfg.dataId&amp;group=test\"</code></pre>\r\n\r\n<p>https://nacos.io/zh-cn/docs/what-is-nacos.html</p>\r\n\r\n<p>本地路径：/Users/nn/git/nacos/bin</p>\r\n', '', 1, NULL, NULL, 0, '2022-07-18 16:42:44', '2022-07-18 18:32:39', 0, '01');
INSERT INTO `blog_copy` VALUES (11, 1, 'Nacos（二）电商微服务拆分', '<p>&nbsp;</p>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p><strong>以往多服务部署</strong></p>\r\n\r\n<p><img alt=\"\" src=\"/upload/image/2_20220718180942.jpeg\" style=\"height:254px; width:300px\" /></p>\r\n\r\n<p><strong>Nacos部署</strong></p>\r\n\r\n<p><img alt=\"\" src=\"/upload/image/2_20220718180950.jpeg\" style=\"height:226px; width:387px\" /></p>\r\n\r\n<ol>\r\n	<li>添加依赖：</li>\r\n</ol>\r\n\r\n<pre>\r\n<code>&lt;dependency&gt;\r\n    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\r\n    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\r\n    &lt;version&gt;${latest.version}&lt;/version&gt;\r\n&lt;/dependency&gt;</code></pre>\r\n\r\n<p>2. 配置服务提供者</p>\r\n\r\n<p>（1）在&nbsp;<code>application.properties</code>&nbsp;中配置 Nacos server 的地址</p>\r\n\r\n<pre>\r\n<code>server.port=8070 //服务端口\r\nspring.application.name=service-provider //服务名称\r\nspring.cloud.nacos.discovery.server-addr=127.0.0.1:8848 //nacos地址</code></pre>\r\n\r\n<p>（2）通过 Spring Cloud 原生注解&nbsp;<span style=\"color:#e74c3c\"><code>@EnableDiscoveryClient</code></span>&nbsp;开启服务注册发现功能：</p>\r\n\r\n<pre>\r\n<code>@SpringBootApplication\r\n@EnableDiscoveryClient\r\npublic class NacosProviderApplication {\r\n\r\n	public static void main(String[] args) {\r\n		SpringApplication.run(NacosProviderApplication.class, args);\r\n	}\r\n}</code></pre>\r\n\r\n<p>&nbsp;</p>\r\n\r\n<p>（3）创建controller</p>\r\n\r\n<pre>\r\n<code>@RestController\r\n	class EchoController {\r\n		@RequestMapping(value = \"/echo/{string}\", method = RequestMethod.GET)\r\n		public String echo(@PathVariable String string) {\r\n			return \"Hello Nacos Discovery \" + string;\r\n		}\r\n	}</code></pre>\r\n\r\n<p>3.配置服务消费者，从而服务消费者可以通过 Nacos 的服务注册发现功能从 Nacos server 上获取到它要调用的服务。</p>\r\n\r\n<p>（1）在&nbsp;<code>application.properties</code>&nbsp;中配置 Nacos server 的地址</p>\r\n\r\n<pre>\r\n<code>server.port=8080\r\nspring.application.name=service-consumer\r\nspring.cloud.nacos.discovery.server-addr=127.0.0.1:8848\r\n#消费者将要去访问的微服务名称（注册成功进nacos的微服务提供者）\r\nserver-url.nacos-user-service= http://service-provider</code></pre>\r\n\r\n<p>（2）通过 Spring Cloud 原生注解&nbsp;<span style=\"color:#e74c3c\"><code>@EnableDiscoveryClient</code></span>&nbsp;开启服务注册发现功能</p>\r\n\r\n<pre>\r\n<code>@SpringBootApplication\r\n@EnableDiscoveryClient\r\npublic class NacosConsumerApplication {\r\n    public static void main(String[] args) {\r\n        SpringApplication.run(NacosConsumerApplication.class, args);\r\n    }\r\n}</code></pre>\r\n\r\n<p>（3）给&nbsp;<a href=\"https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-resttemplate.html\">RestTemplate</a>&nbsp;实例化，开启&nbsp;<code>@LoadBalanced</code>&nbsp;与&nbsp;<a href=\"https://cloud.spring.io/spring-cloud-netflix/multi/multi_spring-cloud-ribbon.html\">Ribbon</a>&nbsp;的集成</p>\r\n\r\n<pre>\r\n<code>@Configuration\r\npublic class AppliationContextConfig {\r\n	@Bean\r\n	@LoadBalanced // 赋予RestTemplate负载均衡的能力\r\n	public RestTemplate getRestTemplate() {\r\n		return new RestTemplate();\r\n	}\r\n}</code></pre>\r\n\r\n<p>（4）创建controller</p>\r\n\r\n<pre>\r\n<code>@RestController\r\npublic class TestController {\r\n	@Resource\r\n	private RestTemplate restTemplate;\r\n\r\n    /*服务提供者配置文件中的地址*/\r\n	@Value(\"${server-url.nacos-user-service}\")\r\n	private String serverURL;\r\n\r\n	@RequestMapping(value = \"/echo/{str}\", method = RequestMethod.GET)\r\n    public String echo(@PathVariable String str) {\r\n            return restTemplate.getForObject(serverURL+\"/echo/\" + str, String.class);\r\n    }\r\n}\r\n</code></pre>\r\n\r\n<ol start=\"4\">\r\n	<li>启动&nbsp;<code>ProviderApplication</code>&nbsp;和&nbsp;<code>ConsumerApplication</code>&nbsp;，</li>\r\n	<li>调用&nbsp;<code>http://localhost:8080/echo/2018</code>，返回内容为&nbsp;<code>Hello Nacos Discovery 2018</code>。</li>\r\n</ol>\r\n', '', 1, NULL, NULL, 0, '2022-07-18 18:06:37', '2022-07-18 19:06:05', 0, '02');

-- ----------------------------
-- Table structure for blog_type
-- ----------------------------
DROP TABLE IF EXISTS `blog_type`;
CREATE TABLE `blog_type`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `accountId` int NOT NULL,
  `blogId` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `typeId` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `state` int NOT NULL COMMENT '0为草稿，1为发布',
  `created` datetime NOT NULL COMMENT '创建时间',
  `updated` datetime NOT NULL COMMENT '最后更新时间',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `pk_blog`(`blogId`) USING BTREE,
  INDEX `pk_type`(`typeId`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of blog_type
-- ----------------------------
INSERT INTO `blog_type` VALUES (1, 1, '1', '1', 0, '2022-07-14 18:44:42', '2022-07-14 18:44:44');
INSERT INTO `blog_type` VALUES (2, 1, '4', '2', 0, '2022-07-14 19:50:13', '2022-07-14 19:50:15');
INSERT INTO `blog_type` VALUES (3, 1, '1', '2', 0, '2022-07-14 21:27:59', '2022-07-14 21:28:01');

-- ----------------------------
-- Table structure for files
-- ----------------------------
DROP TABLE IF EXISTS `files`;
CREATE TABLE `files`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `accountId` int NOT NULL COMMENT '上传者',
  `path` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '相对于jfinal baseUploadPath 的相对路径',
  `fileName` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '文件名',
  `showName` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '显示名',
  `fileType` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `length` int NOT NULL COMMENT '文件长度',
  `created` datetime NOT NULL COMMENT '创建时间',
  `del` varchar(1) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `pk_p`(`del`, `accountId`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 105 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of files
-- ----------------------------
INSERT INTO `files` VALUES (12, 1, '/202207', '2_20220718121440.png', '2_20220718121440.png', '.png', 10573, '2022-07-18 12:14:41', '0');
INSERT INTO `files` VALUES (13, 1, '/202207', '2_20220718170212.png', '2_20220718170212.png', '.png', 39999, '2022-07-18 17:02:13', '0');
INSERT INTO `files` VALUES (14, 1, '/202207', '2_20220718170438.jpeg', '2_20220718170438.jpeg', '.jpeg', 80105, '2022-07-18 17:04:39', '0');
INSERT INTO `files` VALUES (15, 1, '/202207', '2_20220718172026.jpeg', '2_20220718172026.jpeg', '.jpeg', 28099, '2022-07-18 17:20:26', '0');
INSERT INTO `files` VALUES (16, 1, '/202207', '2_20220718172956.jpeg', '2_20220718172956.jpeg', '.jpeg', 25011, '2022-07-18 17:29:56', '0');
INSERT INTO `files` VALUES (17, 1, '/202207', '2_20220718180942.jpeg', '2_20220718180942.jpeg', '.jpeg', 34086, '2022-07-18 18:09:43', '0');
INSERT INTO `files` VALUES (18, 1, '/202207', '2_20220718180950.jpeg', '2_20220718180950.jpeg', '.jpeg', 44231, '2022-07-18 18:09:51', '0');
INSERT INTO `files` VALUES (19, 1, '/202207', '2_20220718181318.png', '2_20220718181318.png', '.png', 171500, '2022-07-18 18:13:19', '0');
INSERT INTO `files` VALUES (20, 1, '/202207', '2_20220718181328.png', '2_20220718181328.png', '.png', 170395, '2022-07-18 18:13:28', '0');
INSERT INTO `files` VALUES (26, 1, '/202207', '1_20220719040937.jpeg', '1_20220719040937.jpeg', '.jpeg', 80105, '2022-07-19 04:09:37', '0');
INSERT INTO `files` VALUES (27, 1, '/202207', '1_20220719050413.png', '1_20220719050413.png', '.png', 10672, '2022-07-19 05:04:14', '0');
INSERT INTO `files` VALUES (28, 1, '/202207', '1_20220719125703.pdf', '1_20220719125703.pdf', NULL, 13457843, '2022-07-19 12:57:03', '1');
INSERT INTO `files` VALUES (29, 1, '/202207', '1_20220719133251.xlsx', '21年物理组本科录取数据.xlsx', NULL, 3467073, '2022-07-19 13:32:52', '0');
INSERT INTO `files` VALUES (30, 1, '/202207', '1_20220719171434.pdf', '1656672328917378.pdf', NULL, 87742, '2022-07-19 17:14:34', '1');
INSERT INTO `files` VALUES (32, 1, '/202207', '1_20220719172429.pdf', '1656672328917378.pdf', NULL, 87742, '2022-07-19 17:24:30', '1');
INSERT INTO `files` VALUES (33, 1, '/202207', '1_20220719172636.pdf', 'Nacos架构与原理.pdf', NULL, 13457843, '2022-07-19 17:26:37', '1');
INSERT INTO `files` VALUES (34, 1, '/202207', '1_20220719173805.pdf', 'Nacos架构与原理.pdf', NULL, 13457843, '2022-07-19 17:38:05', '1');
INSERT INTO `files` VALUES (35, 1, '/202207', '1_20220719173820.pdf', 'Nacos架构与原理.pdf', NULL, 13457843, '2022-07-19 17:38:21', '0');
INSERT INTO `files` VALUES (36, 1, '/202207', '1_20220720145208.xlsx', '上线项目发行信息汇总-20220720.xlsx', NULL, 17740, '2022-07-20 14:52:08', '0');
INSERT INTO `files` VALUES (37, 1, '/202207', '1_20220721100449.html', '1.html', '.html', 3308, '2022-07-21 10:04:49', '0');
INSERT INTO `files` VALUES (38, 1, '/202207', '1_20220721100625.pdf', '1656672328917378.pdf', '.pdf', 87742, '2022-07-21 10:06:25', '0');
INSERT INTO `files` VALUES (39, 1, '/202207', '1_20220721171145.jpg', '“老知道人”发展方向分布.jpg', '.jpg', 88063, '2022-07-21 17:11:46', '0');
INSERT INTO `files` VALUES (40, 1, '/202207', '1_20220721174414.jpg', '管理者的支持系统——“人和”.jpg', '.jpg', 97570, '2022-07-21 17:44:14', '0');
INSERT INTO `files` VALUES (41, 1, '/202207', '1_20220721174520.jpg', '管理之路的外部因素.jpg', '.jpg', 104647, '2022-07-21 17:45:20', '0');
INSERT INTO `files` VALUES (42, 1, '/202207', '1_20220721180557.jpg', 'NLP 逻辑层次图.jpg', '.jpg', 67461, '2022-07-21 18:05:57', '0');
INSERT INTO `files` VALUES (43, 1, '/202207', '1_20220721181551.jpg', '目标的 SMART 原则.jpg', '.jpg', 115027, '2022-07-21 18:15:52', '0');
INSERT INTO `files` VALUES (44, 1, '/202207', '1_20220721182016.jpg', '组织架构图示例.jpg', '.jpg', 236235, '2022-07-21 18:20:17', '0');
INSERT INTO `files` VALUES (45, 1, '/202207', '1_20220721182309.html', '16  团队建设该从哪里入手？.html', '.html', 191394, '2022-07-21 18:23:09', '0');
INSERT INTO `files` VALUES (46, 1, '/202207', '1_20220721182342.html', '16  团队建设该从哪里入手？.html', '.html', 191394, '2022-07-21 18:23:43', '0');
INSERT INTO `files` VALUES (47, 1, '/202207', '1_20220721182408.html', '17  如何提升员工的个人能力？.html', '.html', 191738, '2022-07-21 18:24:08', '0');
INSERT INTO `files` VALUES (48, 1, '/202207', '1_20220721182444.html', '18  如何提升员工的工作意愿和积极性？.html', '.html', 204009, '2022-07-21 18:24:44', '0');
INSERT INTO `files` VALUES (49, 1, '/202207', '1_20220721182450.html', '19  如何兼顾团队分工的稳定性和灵活性？.html', '.html', 196702, '2022-07-21 18:24:51', '0');
INSERT INTO `files` VALUES (50, 1, '/202207', '1_20220721182516.html', '20 有什么方法可以有效提升团队凝聚力吗.html', '.html', 195006, '2022-07-21 18:25:17', '0');
INSERT INTO `files` VALUES (51, 1, '/202207', '1_20220721182531.html', '21  如何物色和培养核心人才？.html', '.html', 196329, '2022-07-21 18:25:32', '0');
INSERT INTO `files` VALUES (52, 1, '/202207', '1_20220721182545.html', '22  如何建设团队文化，营造团队氛围？.html', '.html', 199271, '2022-07-21 18:25:46', '0');
INSERT INTO `files` VALUES (53, 1, '/202207', '1_20220721182552.html', '23  如何和低绩效员工谈绩效？.html', '.html', 188874, '2022-07-21 18:25:52', '0');
INSERT INTO `files` VALUES (54, 1, '/202207', '1_20220721182559.html', '24  如何让团建活动不再“收效甚微”？.html', '.html', 190873, '2022-07-21 18:25:59', '0');
INSERT INTO `files` VALUES (55, 1, '/202207', '1_20220721182607.html', '25  多任务并行该如何应对？.html', '.html', 190262, '2022-07-21 18:26:08', '0');
INSERT INTO `files` VALUES (56, 1, '/202207', '1_20220721182615.html', '26  如何确保项目的有效执行？.html', '.html', 189656, '2022-07-21 18:26:15', '0');
INSERT INTO `files` VALUES (57, 1, '/202207', '1_20220721182626.html', '27  如何让流程机制得到有效的执行？.html', '.html', 190666, '2022-07-21 18:26:27', '0');
INSERT INTO `files` VALUES (58, 1, '/202207', '1_20220721182633.html', '28  管理沟通那些事儿.html', '.html', 196607, '2022-07-21 18:26:33', '0');
INSERT INTO `files` VALUES (59, 1, '/202207', '1_20220721182639.html', '29  沟通经常鸡同鸭讲，说不到一块怎么办？.html', '.html', 186436, '2022-07-21 18:26:40', '0');
INSERT INTO `files` VALUES (60, 1, '/202207', '1_20220721182646.html', '30  如何掌控自己的情绪，以及如何管理情绪化的员工？.html', '.html', 187597, '2022-07-21 18:26:47', '0');
INSERT INTO `files` VALUES (61, 1, '/202207', '1_20220721182739.html', '31  我各方面做得都很好，就是做不好向上沟通.html', '.html', 186600, '2022-07-21 18:27:40', '0');
INSERT INTO `files` VALUES (62, 1, '/202207', '1_20220721182749.html', '32  横向沟通和非职权影响力.html', '.html', 188751, '2022-07-21 18:27:49', '0');
INSERT INTO `files` VALUES (63, 1, '/202207', '1_20220721182756.html', '33  向下沟通的常见实例解析.html', '.html', 185610, '2022-07-21 18:27:57', '0');
INSERT INTO `files` VALUES (64, 1, '/202207', '1_20220721182804.html', '34  管理沟通上有哪些常见的坑儿呢？.html', '.html', 180424, '2022-07-21 18:28:05', '0');
INSERT INTO `files` VALUES (65, 1, '/202207', '1_20220721182811.html', '35  从空降谈管理方法论的积累.html', '.html', 195535, '2022-07-21 18:28:12', '0');
INSERT INTO `files` VALUES (66, 1, '/202207', '1_20220721182817.html', '36  走出自己的管理之路.html', '.html', 206676, '2022-07-21 18:28:18', '0');
INSERT INTO `files` VALUES (67, 1, '/202207', '1_20220721182825.html', '复习课（二）  管理规划.html', '.html', 172651, '2022-07-21 18:28:26', '0');
INSERT INTO `files` VALUES (68, 1, '/202207', '1_20220721182846.html', '复习课（三）  团队建设.html', '.html', 176204, '2022-07-21 18:28:47', '0');
INSERT INTO `files` VALUES (69, 1, '/202207', '1_20220721182853.html', '复习课（四）  任务管理.html', '.html', 172327, '2022-07-21 18:28:54', '0');
INSERT INTO `files` VALUES (70, 1, '/202207', '1_20220721182900.html', '复习课（五）  管理沟通.html', '.html', 178061, '2022-07-21 18:29:00', '0');
INSERT INTO `files` VALUES (71, 1, '/202207', '1_20220721182907.html', '复习课（一）  管理方法论和角色认知.html', '.html', 177461, '2022-07-21 18:29:08', '0');
INSERT INTO `files` VALUES (72, 4, '/202207', '4_20220725134658.png', 'home.png', '.png', 189463, '2022-07-25 13:46:59', '0');
INSERT INTO `files` VALUES (73, 4, '/202207', '4_20220725202931.jpg', 'ccPic20220725202914.jpg', '.jpg', 162185, '2022-07-25 20:29:31', '0');
INSERT INTO `files` VALUES (74, 4, '/202207', '4_20220727234821.jpg', '控制面板.jpg', '.jpg', 200364, '2022-07-27 23:48:21', '0');
INSERT INTO `files` VALUES (75, 4, '/202207', '4_20220728000637.jpg', '控制面板-1.jpg', '.jpg', 111937, '2022-07-28 00:06:38', '0');
INSERT INTO `files` VALUES (76, 4, '/202207', '4_20220728000703.jpg', '控制面板-2.jpg', '.jpg', 125070, '2022-07-28 00:07:04', '0');
INSERT INTO `files` VALUES (77, 4, '/202207', '4_20220728000722.jpg', '控制面板-3.jpg', '.jpg', 129486, '2022-07-28 00:07:23', '0');
INSERT INTO `files` VALUES (78, 1, '/202208', '1_20220803155817.png', '截屏2022-08-03 下午3.57.51.png', '.png', 484602, '2022-08-03 15:58:18', '0');
INSERT INTO `files` VALUES (79, 1, '/202208', '1_20220803161459.png', '截屏2022-08-03 下午4.14.37.png', '.png', 471707, '2022-08-03 16:15:00', '0');
INSERT INTO `files` VALUES (80, 1, '/202208', '1_20220803162003.png', '截屏2022-08-03 下午4.19.38.png', '.png', 717768, '2022-08-03 16:20:03', '0');
INSERT INTO `files` VALUES (81, 1, '/202208', '1_20220803164842.png', 'cd7792865f9b48d4b9a7bbe70bf7be04.png', '.png', 77750, '2022-08-03 16:48:42', '1');
INSERT INTO `files` VALUES (82, 1, '/202208', '1_20220803165012.png', '截屏2022-08-03 下午4.49.48.png', '.png', 527827, '2022-08-03 16:50:13', '0');
INSERT INTO `files` VALUES (83, 1, '/202208', '1_20220803165216.png', 'b211ebcebf16452ca012f3897699b837.png', '.png', 119914, '2022-08-03 16:52:16', '0');
INSERT INTO `files` VALUES (84, 1, '/202208', '1_20220803172231.png', '截屏2022-08-03 下午5.22.17.png', '.png', 116625, '2022-08-03 17:22:32', '0');
INSERT INTO `files` VALUES (85, 1, '/202208', '1_20220803172314.png', '截屏2022-08-03 下午5.23.00.png', '.png', 116478, '2022-08-03 17:23:15', '0');
INSERT INTO `files` VALUES (86, 1, '/202208', '1_20220803172348.png', '截屏2022-08-03 下午5.23.35.png', '.png', 134083, '2022-08-03 17:23:48', '0');
INSERT INTO `files` VALUES (87, 1, '/202208', '1_20220818143127.png', '截屏2022-08-18 下午2.30.53.png', '.png', 711330, '2022-08-18 14:31:28', '0');
INSERT INTO `files` VALUES (88, 1, '/202208', '1_20220818144627.png', '截屏2022-08-18 下午2.45.55.png', '.png', 925780, '2022-08-18 14:46:28', '0');
INSERT INTO `files` VALUES (89, 1, '/202208', '1_20220821095649.doc', '统一身份认证管理系统-需求规格说明书.doc', '.doc', 1936384, '2022-08-21 09:56:49', '0');
INSERT INTO `files` VALUES (90, 1, '/202209', '1_20220901154350.png', '截屏2022-09-01 下午3.43.24.png', '.png', 134544, '2022-09-01 15:43:50', '0');
INSERT INTO `files` VALUES (91, 1, '/202209', '1_20220901155003.png', '截屏2022-09-01 下午3.49.44.png', '.png', 364068, '2022-09-01 15:50:03', '0');
INSERT INTO `files` VALUES (92, 1, '/202209', '1_20220901155010.png', '截屏2022-09-01 下午3.49.49.png', '.png', 194044, '2022-09-01 15:50:10', '0');
INSERT INTO `files` VALUES (93, 1, '/202209', '1_20220901155308.png', '截屏2022-09-01 下午3.52.53.png', '.png', 121345, '2022-09-01 15:53:08', '0');
INSERT INTO `files` VALUES (94, 1, '/202209', '1_20220901160040.png', '截屏2022-09-01 下午4.00.30.png', '.png', 143941, '2022-09-01 16:00:40', '0');
INSERT INTO `files` VALUES (95, 1, '/202211', '1_20221108104034.rpm', 'mysql57-community-release-el7-11.noarch.rpm', '.rpm', 25680, '2022-11-08 10:40:34', '0');
INSERT INTO `files` VALUES (96, 1, '/202211', '1_20221110103435.png', 'WechatIMG9289.png', '.png', 60967, '2022-11-10 10:34:36', '0');
INSERT INTO `files` VALUES (97, 1, '/202302', '1_20230201171435.png', '20180808112156511.png', '.png', 687359, '2023-02-01 17:14:36', '0');
INSERT INTO `files` VALUES (98, 1, '/202302', '1_20230202120311.png', '5c33e18151b344ca890a6df5ec35dc6d.png', '.png', 159195, '2023-02-02 12:03:11', '0');
INSERT INTO `files` VALUES (99, 1, '/202302', '1_20230202120420.png', '6d0f00ed7469455a8dc08f7e5a4ac5d2.png', '.png', 304477, '2023-02-02 12:04:20', '0');
INSERT INTO `files` VALUES (100, 1, '/202302', '1_20230202124133.png', '6d0f00ed7469455a8dc08f7e5a4ac5d2.png', '.png', 304477, '2023-02-02 12:41:33', '0');
INSERT INTO `files` VALUES (101, 1, '/202302', '1_20230207134059.png', 'aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOS83LzIyLzE2YzFhNDI2ZWQ5YWI0OGI_aW1hZ2VWaWV3Mi8wL3cvMTI4MC9oLzk2MC9mb3JtYXQvd2VicC9pZ25vcmUtZXJyb3IvMQ.png', '.png', 40176, '2023-02-07 13:41:00', '0');
INSERT INTO `files` VALUES (102, 1, '/202302', '1_20230208181304.jpg', '16ef3834ae653469.jpg', '.jpg', 8584, '2023-02-08 18:13:05', '0');
INSERT INTO `files` VALUES (103, 1, '/202302', '1_20230208181339.jpg', '16ef3837887d9a54sds.jpg', '.jpg', 16161, '2023-02-08 18:13:40', '0');
INSERT INTO `files` VALUES (104, 1, '/202302', '1_20230208181621.jpg', '16ef383d3e8c9788.jpg', '.jpg', 45936, '2023-02-08 18:16:22', '0');
INSERT INTO `files` VALUES (105, 1, '/202302', '1_20230208184109.png', '16ef388763c25c62.png', '.png', 34906, '2023-02-08 18:41:10', '0');

-- ----------------------------
-- Table structure for files_type
-- ----------------------------
DROP TABLE IF EXISTS `files_type`;
CREATE TABLE `files_type`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `fileType` varchar(2) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `name` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '文件长度',
  `created` datetime NOT NULL COMMENT '创建时间',
  `del` varchar(1) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `pk_p`(`del`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 6 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of files_type
-- ----------------------------
INSERT INTO `files_type` VALUES (1, '1', '.png', '2022-07-21 11:52:47', '0');
INSERT INTO `files_type` VALUES (2, '2', '.pdf', '2022-07-21 11:59:27', '0');
INSERT INTO `files_type` VALUES (3, '1', '.jpg', '2022-07-21 12:13:48', '0');
INSERT INTO `files_type` VALUES (4, '1', '.bmp', '2022-07-21 12:14:02', '0');
INSERT INTO `files_type` VALUES (5, '1', '.gif ', '2022-07-21 12:14:13', '0');
INSERT INTO `files_type` VALUES (6, '1', '.jpeg', '2022-07-21 12:14:28', '0');

-- ----------------------------
-- Table structure for image1
-- ----------------------------
DROP TABLE IF EXISTS `image1`;
CREATE TABLE `image1`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `accountId` int NOT NULL COMMENT '上传者',
  `path` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '相对于jfinal baseUploadPath 的相对路径',
  `fileName` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '文件名',
  `showName` varchar(200) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT '显示名',
  `fileType` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `length` int NOT NULL COMMENT '文件长度',
  `created` datetime NOT NULL COMMENT '创建时间',
  `del` varchar(1) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `pk_p`(`del`, `accountId`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of image1
-- ----------------------------
INSERT INTO `image1` VALUES (12, 1, '/202207', '2_20220718121440.png', '2_20220718121440.png', NULL, 10573, '2022-07-18 12:14:41', '0');
INSERT INTO `image1` VALUES (13, 1, '/202207', '2_20220718170212.png', '2_20220718170212.png', NULL, 39999, '2022-07-18 17:02:13', '0');
INSERT INTO `image1` VALUES (14, 1, '/202207', '2_20220718170438.jpeg', '2_20220718170438.jpeg', NULL, 80105, '2022-07-18 17:04:39', '0');
INSERT INTO `image1` VALUES (15, 1, '/202207', '2_20220718172026.jpeg', '2_20220718172026.jpeg', NULL, 28099, '2022-07-18 17:20:26', '0');
INSERT INTO `image1` VALUES (16, 1, '/202207', '2_20220718172956.jpeg', '2_20220718172956.jpeg', NULL, 25011, '2022-07-18 17:29:56', '0');
INSERT INTO `image1` VALUES (17, 1, '/202207', '2_20220718180942.jpeg', '2_20220718180942.jpeg', NULL, 34086, '2022-07-18 18:09:43', '0');
INSERT INTO `image1` VALUES (18, 1, '/202207', '2_20220718180950.jpeg', '2_20220718180950.jpeg', NULL, 44231, '2022-07-18 18:09:51', '0');
INSERT INTO `image1` VALUES (19, 1, '/202207', '2_20220718181318.png', '2_20220718181318.png', NULL, 171500, '2022-07-18 18:13:19', '0');
INSERT INTO `image1` VALUES (20, 1, '/202207', '2_20220718181328.png', '2_20220718181328.png', NULL, 170395, '2022-07-18 18:13:28', '0');
INSERT INTO `image1` VALUES (26, 1, '/202207', '1_20220719040937.jpeg', '1_20220719040937.jpeg', NULL, 80105, '2022-07-19 04:09:37', '0');
INSERT INTO `image1` VALUES (27, 1, '/202207', '1_20220719050413.png', '1_20220719050413.png', NULL, 10672, '2022-07-19 05:04:14', '0');
INSERT INTO `image1` VALUES (28, 1, '/202207', '1_20220719125703.pdf', '1_20220719125703.pdf', NULL, 13457843, '2022-07-19 12:57:03', '1');
INSERT INTO `image1` VALUES (29, 1, '/202207', '1_20220719133251.xlsx', '21年物理组本科录取数据.xlsx', NULL, 3467073, '2022-07-19 13:32:52', '0');
INSERT INTO `image1` VALUES (30, 1, '/202207', '1_20220719171434.pdf', '1656672328917378.pdf', NULL, 87742, '2022-07-19 17:14:34', '1');
INSERT INTO `image1` VALUES (32, 1, '/202207', '1_20220719172429.pdf', '1656672328917378.pdf', NULL, 87742, '2022-07-19 17:24:30', '1');
INSERT INTO `image1` VALUES (33, 1, '/202207', '1_20220719172636.pdf', 'Nacos架构与原理.pdf', NULL, 13457843, '2022-07-19 17:26:37', '1');
INSERT INTO `image1` VALUES (34, 1, '/202207', '1_20220719173805.pdf', 'Nacos架构与原理.pdf', NULL, 13457843, '2022-07-19 17:38:05', '1');
INSERT INTO `image1` VALUES (35, 1, '/202207', '1_20220719173820.pdf', 'Nacos架构与原理.pdf', NULL, 13457843, '2022-07-19 17:38:21', '0');
INSERT INTO `image1` VALUES (36, 1, '/202207', '1_20220720145208.xlsx', '上线项目发行信息汇总-20220720.xlsx', NULL, 17740, '2022-07-20 14:52:08', '0');

-- ----------------------------
-- Table structure for jz_parent
-- ----------------------------
DROP TABLE IF EXISTS `jz_parent`;
CREATE TABLE `jz_parent`  (
  `id` int NULL DEFAULT NULL,
  `title` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `cover_url` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `total` int NULL DEFAULT NULL,
  `tag_id` int NULL DEFAULT NULL,
  `tag_value` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `default_pay_episode` int NULL DEFAULT NULL,
  `default_pay_amount` int NULL DEFAULT NULL,
  `class_name` varchar(10) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `share_title` varchar(20) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `share_cover` varchar(1024) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci COMMENT = '短剧' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of jz_parent
-- ----------------------------

-- ----------------------------
-- Table structure for jz_theaters
-- ----------------------------
DROP TABLE IF EXISTS `jz_theaters`;
CREATE TABLE `jz_theaters`  (
  `id` int NULL DEFAULT NULL,
  `parent_id` int NULL DEFAULT NULL,
  `son_title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `son_cover_url` varchar(1024) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `son_video_url` varchar(1024) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `num` int NULL DEFAULT NULL
) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci COMMENT = '剧集' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of jz_theaters
-- ----------------------------

-- ----------------------------
-- Table structure for label
-- ----------------------------
DROP TABLE IF EXISTS `label`;
CREATE TABLE `label`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `accountId` int NOT NULL,
  `title` varchar(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `content` text CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL,
  `pic` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '' COMMENT '文章配图',
  `state` int NOT NULL COMMENT '0为草稿，1为发布',
  `seoKeywords` int NULL DEFAULT NULL,
  `seoDescription` int NULL DEFAULT NULL,
  `viewCount` int NOT NULL DEFAULT 0 COMMENT '浏览量',
  `created` datetime NOT NULL COMMENT '创建时间',
  `updated` datetime NOT NULL COMMENT '最后更新时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 5 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of label
-- ----------------------------
INSERT INTO `label` VALUES (1, 1, '标签0', NULL, '', 0, NULL, NULL, 0, '2022-07-14 16:32:52', '2022-07-14 17:17:22');
INSERT INTO `label` VALUES (2, 2, '标签2', NULL, '', 0, NULL, NULL, 0, '2022-07-14 17:00:06', '2022-07-14 17:15:28');
INSERT INTO `label` VALUES (3, 2, '标签3', NULL, '', 0, NULL, NULL, 0, '2022-07-14 17:15:34', '2022-07-14 17:15:34');
INSERT INTO `label` VALUES (4, 2, '33', NULL, '', 0, NULL, NULL, 0, '2022-07-14 17:17:18', '2022-07-14 18:06:00');
INSERT INTO `label` VALUES (5, 2, '3', NULL, '', 0, NULL, NULL, 0, '2022-07-14 18:05:53', '2022-07-14 18:05:53');

-- ----------------------------
-- Table structure for login_log
-- ----------------------------
DROP TABLE IF EXISTS `login_log`;
CREATE TABLE `login_log`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `userName` varchar(50) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '' COMMENT '登录使用的账户名',
  `accountId` int NULL DEFAULT NULL COMMENT '登录成功的accountId',
  `state` int NOT NULL COMMENT '登录成功为1,否则为0',
  `ip` varchar(100) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `port` int NOT NULL,
  `created` datetime NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 117 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of login_log
-- ----------------------------
INSERT INTO `login_log` VALUES (1, 'jfinal', 1, 1, '127.0.0.1', 80, '2022-07-13 19:22:24');
INSERT INTO `login_log` VALUES (2, 'jfinal', 1, 1, '127.0.0.1', 80, '2022-07-13 19:28:54');
INSERT INTO `login_log` VALUES (3, 'jfinal', 1, 1, '49.66.18.8', 80, '2022-07-13 21:23:44');
INSERT INTO `login_log` VALUES (4, 'nannan', NULL, 0, '49.66.18.8', 80, '2022-07-13 21:32:20');
INSERT INTO `login_log` VALUES (5, 'jfinal', NULL, 0, '49.66.18.8', 80, '2022-07-13 21:32:37');
INSERT INTO `login_log` VALUES (6, 'nannan', NULL, 0, '49.66.18.8', 80, '2022-07-13 21:32:42');
INSERT INTO `login_log` VALUES (7, 'nannan', NULL, 0, '49.66.18.8', 80, '2022-07-13 21:32:47');
INSERT INTO `login_log` VALUES (8, 'nn', NULL, 0, '49.66.18.8', 80, '2022-07-13 21:33:25');
INSERT INTO `login_log` VALUES (9, 'nn', 2, 1, '49.66.18.8', 80, '2022-07-13 22:29:39');
INSERT INTO `login_log` VALUES (10, 'nn', 2, 1, '0:0:0:0:0:0:0:1', 80, '2022-07-14 15:51:08');
INSERT INTO `login_log` VALUES (11, 'nn', 2, 1, '49.66.23.233', 80, '2022-07-18 10:53:12');
INSERT INTO `login_log` VALUES (12, 'nn', 2, 1, '49.66.23.233', 80, '2022-07-18 12:14:29');
INSERT INTO `login_log` VALUES (13, 'nn', 2, 1, '127.0.0.1', 80, '2022-07-18 13:32:01');
INSERT INTO `login_log` VALUES (14, 'nn', 2, 1, '127.0.0.1', 80, '2022-07-18 13:56:28');
INSERT INTO `login_log` VALUES (15, 'nn', 2, 1, '127.0.0.1', 80, '2022-07-18 14:47:19');
INSERT INTO `login_log` VALUES (16, 'nn', 2, 1, '36.110.41.66', 80, '2022-07-18 21:16:06');
INSERT INTO `login_log` VALUES (17, 'nn', 2, 1, '49.66.18.8', 80, '2022-07-18 21:22:16');
INSERT INTO `login_log` VALUES (18, 'nn', 2, 1, '49.66.18.8', 80, '2022-07-18 21:30:49');
INSERT INTO `login_log` VALUES (19, 'nn', 2, 1, '0:0:0:0:0:0:0:1', 80, '2022-07-18 23:04:07');
INSERT INTO `login_log` VALUES (20, 'nn', 3, 1, '0:0:0:0:0:0:0:1', 80, '2022-07-18 23:24:27');
INSERT INTO `login_log` VALUES (21, 'nn', 1, 1, '0:0:0:0:0:0:0:1', 80, '2022-07-18 23:30:18');
INSERT INTO `login_log` VALUES (22, 'nn', 1, 1, '0:0:0:0:0:0:0:1', 80, '2022-07-18 23:42:24');
INSERT INTO `login_log` VALUES (23, 'nn', 1, 1, '0:0:0:0:0:0:0:1', 80, '2022-07-18 23:43:00');
INSERT INTO `login_log` VALUES (24, 'nn', 1, 1, '49.66.18.8', 8082, '2022-07-19 03:39:45');
INSERT INTO `login_log` VALUES (25, 'nn', 1, 1, '49.66.18.8', 8082, '2022-07-19 04:38:52');
INSERT INTO `login_log` VALUES (26, 'yahui', NULL, 0, '49.66.18.8', 8082, '2022-07-19 04:53:44');
INSERT INTO `login_log` VALUES (27, 'yahui', NULL, 0, '49.66.18.8', 8082, '2022-07-19 04:53:49');
INSERT INTO `login_log` VALUES (28, 'yahui', NULL, 0, '49.66.18.8', 8082, '2022-07-19 04:53:53');
INSERT INTO `login_log` VALUES (29, 'yahui', NULL, 0, '49.66.18.8', 8082, '2022-07-19 04:53:59');
INSERT INTO `login_log` VALUES (30, 'yahui', NULL, 0, '49.66.18.8', 8082, '2022-07-19 04:54:53');
INSERT INTO `login_log` VALUES (31, 'yahui', NULL, 0, '49.66.18.8', 8082, '2022-07-19 04:55:00');
INSERT INTO `login_log` VALUES (32, 'yahui', NULL, 0, '49.66.18.8', 8082, '2022-07-19 04:55:28');
INSERT INTO `login_log` VALUES (33, 'yahui', 4, 1, '49.66.18.8', 8082, '2022-07-19 04:55:52');
INSERT INTO `login_log` VALUES (34, 'nn', 1, 1, '49.66.18.8', 8082, '2022-07-19 05:04:02');
INSERT INTO `login_log` VALUES (35, 'yahui', NULL, 0, '49.66.18.8', 8082, '2022-07-19 05:05:36');
INSERT INTO `login_log` VALUES (36, 'yahui', 4, 1, '49.66.18.8', 8082, '2022-07-19 05:05:41');
INSERT INTO `login_log` VALUES (37, 'nn', 1, 1, '49.66.23.233', 80, '2022-07-19 10:15:02');
INSERT INTO `login_log` VALUES (38, 'nn', 1, 1, '49.66.23.233', 8082, '2022-07-19 13:42:19');
INSERT INTO `login_log` VALUES (39, 'nn', 1, 1, '49.66.23.233', 8082, '2022-07-19 13:44:21');
INSERT INTO `login_log` VALUES (40, 'yahui', NULL, 0, '36.110.41.66', 8082, '2022-07-19 14:10:09');
INSERT INTO `login_log` VALUES (41, 'yahui', NULL, 0, '36.110.41.66', 8082, '2022-07-19 14:10:19');
INSERT INTO `login_log` VALUES (42, 'yahui', NULL, 0, '36.110.41.66', 8082, '2022-07-19 14:11:15');
INSERT INTO `login_log` VALUES (43, 'yahui', 4, 1, '36.110.41.66', 8082, '2022-07-19 14:11:38');
INSERT INTO `login_log` VALUES (44, 'nn', 1, 1, '49.66.23.233', 8082, '2022-07-19 14:14:57');
INSERT INTO `login_log` VALUES (45, 'nn', 1, 1, '49.66.23.233', 80, '2022-07-19 14:31:11');
INSERT INTO `login_log` VALUES (46, 'nn', 1, 1, '49.66.18.8', 80, '2022-07-19 20:55:25');
INSERT INTO `login_log` VALUES (47, 'nn', 1, 1, '127.0.0.1', 8082, '2022-07-21 09:36:10');
INSERT INTO `login_log` VALUES (48, 'yahui', 4, 1, '49.66.16.244', 80, '2022-07-21 18:33:57');
INSERT INTO `login_log` VALUES (49, 'nn', 1, 1, '49.66.16.244', 80, '2022-07-21 18:34:15');
INSERT INTO `login_log` VALUES (50, 'yahui', 4, 1, '183.199.216.104', 80, '2022-07-24 13:16:01');
INSERT INTO `login_log` VALUES (51, 'yahui', NULL, 0, '36.110.41.66', 80, '2022-07-24 17:54:39');
INSERT INTO `login_log` VALUES (52, 'yahui', 4, 1, '36.110.41.66', 80, '2022-07-24 17:54:44');
INSERT INTO `login_log` VALUES (53, 'snn', NULL, 0, '183.199.216.104', 80, '2022-07-25 08:55:48');
INSERT INTO `login_log` VALUES (54, 'snn', 1, 1, '183.199.216.104', 80, '2022-07-25 08:56:25');
INSERT INTO `login_log` VALUES (55, 'yahui', 4, 1, '36.110.41.66', 80, '2022-07-25 13:36:48');
INSERT INTO `login_log` VALUES (56, 'nn', NULL, 0, '36.110.41.66', 80, '2022-07-25 21:55:23');
INSERT INTO `login_log` VALUES (57, 'nn', NULL, 0, '36.110.41.66', 80, '2022-07-25 21:55:29');
INSERT INTO `login_log` VALUES (58, 'nn', NULL, 0, '36.110.41.66', 80, '2022-07-25 21:55:39');
INSERT INTO `login_log` VALUES (59, 'yahui', 4, 1, '36.110.41.66', 80, '2022-07-25 21:55:46');
INSERT INTO `login_log` VALUES (60, 'snn', 1, 1, '183.199.216.104', 80, '2022-07-28 14:34:14');
INSERT INTO `login_log` VALUES (61, 'jfinal', NULL, 0, '120.245.130.167', 80, '2022-07-30 09:40:55');
INSERT INTO `login_log` VALUES (62, 'jfinal', NULL, 0, '120.245.130.167', 80, '2022-07-30 09:41:03');
INSERT INTO `login_log` VALUES (63, 'jfinal', NULL, 0, '120.245.130.167', 80, '2022-07-30 09:41:18');
INSERT INTO `login_log` VALUES (64, 'snn', 1, 1, '103.91.179.133', 80, '2022-08-02 17:43:40');
INSERT INTO `login_log` VALUES (65, 'snn', 1, 1, '114.250.16.124', 80, '2022-08-07 21:43:16');
INSERT INTO `login_log` VALUES (66, 'jfinal', NULL, 0, '103.91.179.133', 80, '2022-08-09 17:56:39');
INSERT INTO `login_log` VALUES (67, 'jfinal', NULL, 0, '103.91.179.133', 80, '2022-08-09 17:56:45');
INSERT INTO `login_log` VALUES (68, 'jfinal', NULL, 0, '103.91.179.133', 80, '2022-08-09 17:56:51');
INSERT INTO `login_log` VALUES (69, 'jfinal', NULL, 0, '103.91.179.133', 80, '2022-08-09 17:56:58');
INSERT INTO `login_log` VALUES (70, 'snn', 1, 1, '103.91.179.133', 80, '2022-08-18 13:59:46');
INSERT INTO `login_log` VALUES (71, 'nn', NULL, 0, '127.0.0.1', 8082, '2022-08-18 17:23:21');
INSERT INTO `login_log` VALUES (72, 'snn', 1, 1, '127.0.0.1', 8082, '2022-08-18 17:23:29');
INSERT INTO `login_log` VALUES (73, 'snn', 1, 1, '0:0:0:0:0:0:0:1', 8082, '2022-08-18 17:49:40');
INSERT INTO `login_log` VALUES (74, 'snn', 1, 1, '0:0:0:0:0:0:0:1', 8082, '2022-08-18 17:52:55');
INSERT INTO `login_log` VALUES (75, 'snn', 1, 1, '120.245.130.104', 80, '2022-08-21 09:49:35');
INSERT INTO `login_log` VALUES (76, 'snn', 1, 1, '103.91.179.133', 80, '2022-08-22 11:21:12');
INSERT INTO `login_log` VALUES (77, 'snn', 1, 1, '103.91.179.133', 80, '2022-08-25 17:02:12');
INSERT INTO `login_log` VALUES (78, 'snn', NULL, 0, '103.91.179.133', 80, '2022-09-01 15:30:43');
INSERT INTO `login_log` VALUES (79, 'snn', NULL, 0, '103.91.179.133', 80, '2022-09-01 15:30:49');
INSERT INTO `login_log` VALUES (80, 'snn', NULL, 0, '103.91.179.133', 80, '2022-09-01 15:31:30');
INSERT INTO `login_log` VALUES (81, 'snn', NULL, 0, '103.91.179.133', 80, '2022-09-01 15:31:41');
INSERT INTO `login_log` VALUES (82, 'snn', NULL, 0, '103.91.179.133', 80, '2022-09-01 15:32:45');
INSERT INTO `login_log` VALUES (83, 'snn', NULL, 0, '103.91.179.133', 80, '2022-09-01 15:33:24');
INSERT INTO `login_log` VALUES (84, 'snn', NULL, 0, '103.91.179.133', 80, '2022-09-01 15:35:53');
INSERT INTO `login_log` VALUES (85, 'snn', NULL, 0, '103.91.179.133', 80, '2022-09-01 15:37:20');
INSERT INTO `login_log` VALUES (86, 'snn', NULL, 0, '103.91.179.133', 80, '2022-09-01 15:37:30');
INSERT INTO `login_log` VALUES (87, 'snn', 1, 1, '103.91.179.133', 80, '2022-09-01 15:38:31');
INSERT INTO `login_log` VALUES (88, 'snn', NULL, 0, '117.84.218.142', 80, '2022-09-07 20:40:48');
INSERT INTO `login_log` VALUES (89, 'snn', 1, 1, '117.84.218.142', 80, '2022-09-07 20:40:54');
INSERT INTO `login_log` VALUES (90, 'snn', 1, 1, '117.84.218.142', 80, '2022-09-07 22:00:11');
INSERT INTO `login_log` VALUES (91, 'snn', NULL, 0, '127.0.0.1', 8082, '2022-09-11 13:14:03');
INSERT INTO `login_log` VALUES (92, 'snn', NULL, 0, '127.0.0.1', 8082, '2022-09-11 13:14:10');
INSERT INTO `login_log` VALUES (93, 'snn', 1, 1, '127.0.0.1', 8082, '2022-09-11 13:14:14');
INSERT INTO `login_log` VALUES (94, 'snn', 1, 1, '114.224.28.134', 80, '2022-09-14 15:34:57');
INSERT INTO `login_log` VALUES (95, 'snn', 1, 1, '117.84.28.98', 80, '2022-10-08 10:58:53');
INSERT INTO `login_log` VALUES (96, 'snn', 1, 1, '58.214.217.164', 80, '2022-10-12 11:25:35');
INSERT INTO `login_log` VALUES (97, 'yahui', 4, 1, '36.110.41.66', 80, '2022-10-24 16:04:55');
INSERT INTO `login_log` VALUES (98, 'snn', 1, 1, '114.224.18.155', 80, '2022-11-08 10:39:07');
INSERT INTO `login_log` VALUES (99, 'snn', 1, 1, '114.224.18.155', 80, '2022-11-22 16:32:06');
INSERT INTO `login_log` VALUES (100, 'snn', 1, 1, '58.214.214.66', 80, '2022-11-29 13:38:32');
INSERT INTO `login_log` VALUES (101, 'snn', 1, 1, '58.214.214.66', 80, '2022-12-05 13:56:21');
INSERT INTO `login_log` VALUES (102, 'snn', 1, 1, '117.133.49.94', 80, '2023-02-01 14:13:01');
INSERT INTO `login_log` VALUES (103, 'snn', 1, 1, '114.241.90.16', 80, '2023-02-07 11:47:01');
INSERT INTO `login_log` VALUES (104, 'snn', 1, 1, '127.0.0.1', 8082, '2023-02-10 11:27:43');
INSERT INTO `login_log` VALUES (105, 'snn', 1, 1, '114.250.20.54', 80, '2023-02-10 12:36:38');
INSERT INTO `login_log` VALUES (106, 'snn', 1, 1, '114.250.20.54', 80, '2023-02-13 15:24:26');
INSERT INTO `login_log` VALUES (107, 'snn', 1, 1, '111.197.232.180', 80, '2023-02-28 10:05:33');
INSERT INTO `login_log` VALUES (108, 'nannan', NULL, 0, '111.197.232.180', 80, '2023-03-04 13:53:16');
INSERT INTO `login_log` VALUES (109, 'nannan', NULL, 0, '111.197.232.180', 80, '2023-03-08 11:56:22');
INSERT INTO `login_log` VALUES (110, 'snn', 1, 1, '111.197.232.180', 80, '2023-03-08 11:56:43');
INSERT INTO `login_log` VALUES (111, 'snn', 1, 1, '111.197.232.180', 80, '2023-03-08 11:57:13');
INSERT INTO `login_log` VALUES (112, 'snn', 1, 1, '114.246.100.134', 80, '2023-03-14 10:08:14');
INSERT INTO `login_log` VALUES (113, 'snn', 1, 1, '123.123.111.122', 80, '2023-04-03 15:32:35');
INSERT INTO `login_log` VALUES (114, 'snn', 1, 1, '123.123.111.122', 80, '2023-04-10 09:57:57');
INSERT INTO `login_log` VALUES (115, 'snn', 1, 1, '123.123.111.122', 80, '2023-04-26 08:51:52');
INSERT INTO `login_log` VALUES (116, 'yahui', 2, 1, '36.110.41.66', 80, '2023-06-21 17:39:11');
INSERT INTO `login_log` VALUES (117, 'jfinal', NULL, 0, '139.59.66.102', 80, '2023-07-26 09:52:32');

-- ----------------------------
-- Table structure for session
-- ----------------------------
DROP TABLE IF EXISTS `session`;
CREATE TABLE `session`  (
  `id` varchar(33) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '' COMMENT 'session id',
  `accountId` int NOT NULL COMMENT '账户 id',
  `created` datetime NOT NULL COMMENT '创建时间',
  `expires` datetime NOT NULL COMMENT '过期时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of session
-- ----------------------------
INSERT INTO `session` VALUES ('02dfebb558ed481398bbae30fcbf8a7d', 1, '2023-02-10 11:27:43', '2023-02-13 11:27:43');
INSERT INTO `session` VALUES ('044e4db094234057ac6c1965c875a373', 1, '2022-07-13 21:23:44', '2022-07-16 21:23:44');
INSERT INTO `session` VALUES ('0de79c29dcff455dbbf9f839ececdc28', 1, '2022-07-18 23:43:00', '2022-07-21 23:43:00');
INSERT INTO `session` VALUES ('0ea2e422ae024a4e8481da8c513011db', 1, '2023-04-26 08:51:52', '2023-04-29 08:51:52');
INSERT INTO `session` VALUES ('12c1e429552a4b4cb961b726cc4fb054', 2, '2022-07-14 15:51:08', '2022-07-17 15:51:08');
INSERT INTO `session` VALUES ('1599306506534006b6ce3d910c8a3fbc', 1, '2022-08-18 17:23:29', '2022-08-21 17:23:29');
INSERT INTO `session` VALUES ('172e2c04322e4a6193ada550cd7092fc', 1, '2022-07-21 18:34:15', '2022-07-24 18:34:15');
INSERT INTO `session` VALUES ('1bf476f3a2d54120aaae635e71da7706', 2, '2022-07-18 13:32:00', '2022-07-21 13:32:00');
INSERT INTO `session` VALUES ('2bcc8622666f400696032e9124628efd', 1, '2023-02-10 12:36:38', '2023-02-13 12:36:38');
INSERT INTO `session` VALUES ('31323a11c2cf4e9ea2f903f6b90bc160', 1, '2022-09-07 20:40:54', '2022-09-10 20:40:54');
INSERT INTO `session` VALUES ('32cc1e70177d48ce96805f49e26cb186', 1, '2022-07-13 19:28:54', '2022-07-16 19:28:54');
INSERT INTO `session` VALUES ('3508b775077e44019b4d46f1fe286c2d', 1, '2023-02-28 10:05:33', '2023-03-03 10:05:33');
INSERT INTO `session` VALUES ('3bfd2aee3d7648c7928a7974b0147f5c', 1, '2022-08-18 17:52:55', '2022-08-21 17:52:55');
INSERT INTO `session` VALUES ('3c43339acba14b75975f37d35f3a6cbf', 1, '2022-11-22 16:32:06', '2022-11-25 16:32:06');
INSERT INTO `session` VALUES ('44aa806d0d3b418b88e4e2ce7c7779d6', 1, '2022-07-18 23:30:18', '2022-07-21 23:30:18');
INSERT INTO `session` VALUES ('45bb3b9dd41343968165bc0902d85cc8', 1, '2022-07-18 23:42:24', '2022-07-21 23:42:24');
INSERT INTO `session` VALUES ('4657131ed5d348558bcad4ef0212b185', 1, '2022-07-28 14:34:14', '2022-07-31 14:34:14');
INSERT INTO `session` VALUES ('475b468dade54aaaad9f9b7ea8b2ae4a', 1, '2023-03-08 11:56:43', '2023-03-11 11:56:43');
INSERT INTO `session` VALUES ('50256b378c4b40ba86bb5a64cd2f96cd', 1, '2022-09-01 15:38:31', '2022-09-04 15:38:31');
INSERT INTO `session` VALUES ('58c41e9daa6645308011ecb5fe112028', 1, '2022-08-18 17:49:39', '2022-08-21 17:49:39');
INSERT INTO `session` VALUES ('5921ddc9695843bf9185c429ba80e3ab', 2, '2022-07-18 21:22:16', '2022-07-21 21:22:16');
INSERT INTO `session` VALUES ('5ebf109f8f6b4abdab743bd5ad30ee8b', 1, '2022-07-19 14:14:57', '2022-07-22 14:14:57');
INSERT INTO `session` VALUES ('632bdc5d92824f1484aa2ce75a5f9594', 4, '2022-10-24 16:04:55', '2022-10-27 16:04:55');
INSERT INTO `session` VALUES ('6dc29a695d22486887ddc42fd60bd2c6', 1, '2022-08-25 17:02:12', '2022-08-28 17:02:12');
INSERT INTO `session` VALUES ('6e1681c28d8a4fa2a086c6b595e9a7c2', 2, '2022-07-13 22:29:39', '2022-07-16 22:29:39');
INSERT INTO `session` VALUES ('77cce5d5ba0b448eabe2c79245cd51c0', 1, '2022-07-19 20:55:25', '2022-07-22 20:55:25');
INSERT INTO `session` VALUES ('80081dfab03842cdb9a81fc8415623e9', 4, '2022-07-24 13:16:01', '2022-07-27 13:16:01');
INSERT INTO `session` VALUES ('8378e6795a0c4ebfbf632990243a7cc9', 1, '2022-08-18 13:59:46', '2022-08-21 13:59:46');
INSERT INTO `session` VALUES ('8fb767cdbef44f1eb23233cbbef52c92', 1, '2023-02-07 11:47:01', '2023-02-10 11:47:01');
INSERT INTO `session` VALUES ('9be913f6dbb74e5f8cf8e3572e1deb61', 1, '2022-10-08 10:58:53', '2022-10-11 10:58:53');
INSERT INTO `session` VALUES ('9d78012aeaf14398870aa4ec3479507b', 1, '2023-04-03 15:32:35', '2023-04-06 15:32:35');
INSERT INTO `session` VALUES ('9eaf07febf604f44b8f127e7cb34fc14', 1, '2022-07-19 13:44:21', '2022-07-22 13:44:21');
INSERT INTO `session` VALUES ('a36123f4b463473bb578c30e04d6b0a5', 1, '2022-07-19 03:39:45', '2022-07-22 03:39:45');
INSERT INTO `session` VALUES ('a598e98d99fb455d9b873809b9612aa8', 1, '2022-07-25 08:56:25', '2022-07-28 08:56:25');
INSERT INTO `session` VALUES ('a86bf35b5400471d8367f7494f892830', 1, '2022-07-19 13:42:19', '2022-07-22 13:42:19');
INSERT INTO `session` VALUES ('aea70e88183b431ba148e9a60f5e4459', 1, '2023-03-14 10:08:14', '2023-03-17 10:08:14');
INSERT INTO `session` VALUES ('aec6957a42174f69b3c98621274b50e8', 4, '2022-07-19 14:11:38', '2022-07-22 14:11:38');
INSERT INTO `session` VALUES ('b1f16fb554e3441a875dde3497448dce', 1, '2022-08-02 17:43:40', '2022-08-05 17:43:40');
INSERT INTO `session` VALUES ('b2eddd511eb04c2dab897afe84c9106c', 1, '2022-07-21 09:36:10', '2022-07-24 09:36:10');
INSERT INTO `session` VALUES ('b5c2427301e045a9b9a48f2a9f22393c', 1, '2023-02-01 14:13:01', '2023-02-04 14:13:01');
INSERT INTO `session` VALUES ('bf0303ad6c104df4886ea46558562d08', 1, '2022-09-14 15:34:57', '2022-09-17 15:34:57');
INSERT INTO `session` VALUES ('c41eec6660c14d3a9e4a46f7aa2129e8', 1, '2023-02-13 15:24:26', '2023-02-16 15:24:26');
INSERT INTO `session` VALUES ('cacf21d6e46441089a9a9ea338ca3c85', 1, '2022-09-07 22:00:11', '2022-09-10 22:00:11');
INSERT INTO `session` VALUES ('cb5ff35e500644d9aed55dde11ed5671', 1, '2022-10-12 11:25:35', '2022-10-15 11:25:35');
INSERT INTO `session` VALUES ('cca883e435534bf1bc9ecf593f1d083d', 1, '2022-08-22 11:21:12', '2022-08-25 11:21:12');
INSERT INTO `session` VALUES ('cf8483a38af640b2b04b3afdf37c2234', 1, '2022-08-07 21:43:15', '2022-08-10 21:43:15');
INSERT INTO `session` VALUES ('e26a29a799654cf3b6e35e4c35099223', 1, '2022-12-05 13:56:21', '2022-12-08 13:56:21');
INSERT INTO `session` VALUES ('e350db7825a045e7bdbb095175c0524d', 1, '2022-08-21 09:49:35', '2022-08-24 09:49:35');
INSERT INTO `session` VALUES ('e651aaba53af467387f178c1a5036905', 1, '2022-09-11 13:14:14', '2022-09-14 13:14:14');
INSERT INTO `session` VALUES ('e81ee3fd5b1b4d1994b193c6a935a06e', 4, '2022-07-25 21:55:46', '2022-07-28 21:55:46');
INSERT INTO `session` VALUES ('e9f0c1bb39e841278f0968db4f073cc3', 1, '2022-11-08 10:39:07', '2022-11-11 10:39:07');
INSERT INTO `session` VALUES ('eb3746c29b3c4da4910983f437da2caa', 1, '2023-04-10 09:57:57', '2023-04-13 09:57:57');
INSERT INTO `session` VALUES ('eb7bd975852243d489e33707c69dc7eb', 1, '2023-03-08 11:57:13', '2023-03-11 11:57:13');
INSERT INTO `session` VALUES ('effb0e4f4a78406d924fb00c6db7cfe9', 2, '2023-06-21 17:39:11', '2023-06-24 17:39:11');
INSERT INTO `session` VALUES ('f484dee732eb4d3aa5fe2adc6aeb4c75', 1, '2022-11-29 13:38:32', '2022-12-02 13:38:32');

-- ----------------------------
-- Table structure for type
-- ----------------------------
DROP TABLE IF EXISTS `type`;
CREATE TABLE `type`  (
  `id` int NOT NULL AUTO_INCREMENT,
  `accountId` int NOT NULL,
  `title` varchar(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `content` text CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL,
  `pic` varchar(128) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL DEFAULT '' COMMENT '文章配图',
  `state` int NOT NULL COMMENT '0为草稿，1为发布',
  `seoKeywords` int NULL DEFAULT NULL,
  `seoDescription` int NULL DEFAULT NULL,
  `viewCount` int NOT NULL DEFAULT 0 COMMENT '浏览量',
  `created` datetime NOT NULL COMMENT '创建时间',
  `updated` datetime NOT NULL COMMENT '最后更新时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of type
-- ----------------------------
INSERT INTO `type` VALUES (1, 1, '技术', NULL, '', 0, NULL, NULL, 0, '2022-07-14 16:32:52', '2022-07-14 17:00:33');
INSERT INTO `type` VALUES (2, 2, '分类2', NULL, '', 0, NULL, NULL, 0, '2022-07-14 17:00:06', '2022-07-14 17:54:20');
INSERT INTO `type` VALUES (3, 2, '分类3', NULL, '', 0, NULL, NULL, 0, '2022-07-14 17:54:26', '2022-07-14 17:54:26');

SET FOREIGN_KEY_CHECKS = 1;
